{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08d7d7c-4387-4140-aa2f-f1d7aca7ce7e",
   "metadata": {},
   "source": [
    "# EDA & 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d548d44e-fdab-403f-9a35-7d982e1b4039",
   "metadata": {},
   "source": [
    "## 데이터 분석 프로세스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9c0d4b-1705-464a-8ef7-4e632c596c83",
   "metadata": {},
   "source": [
    "1. 데이터 수집\n",
    "   \n",
    "2. 데이터 탐색 (EDA)\n",
    "- 데이터를 여러 가지 방식으로 파악\n",
    "- 독립된 하나의 단계라기 보다는, 데이터 분석 전과정에서 수행됨\n",
    "\n",
    "3. 데이터 전처리\n",
    "- 데이터 분석 (모델링)을 위해 데이터를 적절한 방식으로 손질하는 과정\n",
    "- 결측치와 이상치 처리\n",
    "\n",
    "4. 데이터 모델링\n",
    "- 유용한 정보를 추출하기 위한 모델 구축\n",
    "- 예측, 분류, 군집 등 목적에 맞는 모델 선택 및 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c44965-08c3-4077-bffb-1a106a601abe",
   "metadata": {},
   "source": [
    "## EDA의 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112abe11-1ca7-4b45-aa9d-abfd41191ba6",
   "metadata": {},
   "source": [
    "EDA: 데이터 분석(모델링)을 위해 데이터를 여러가지 방식으로 파악하는 전 과정\n",
    "- 시각화를 통한 패턴 발견\n",
    "- 데이터의 특이성 확인\n",
    "- 통계와 그래프로 가설 검정\\\n",
    "-> 다양한 방식으로 데이터를 탐색하며 주어진 데이터에 대해 알아보는 것\n",
    "\n",
    "- 데이터를 분석해 결과를 내는 과정에서 데이터에 대한 '탐색과 이해'는 기본/필수적\n",
    "- EDA 과정에서 데이터를 잘못 해석하고, 문제를 잘못 정의하면 향후 분석 과정/결과에 오류 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32183fe2-e51e-4474-b48e-08506fb5cb15",
   "metadata": {},
   "source": [
    "EDA의 대상\n",
    "1. 일변량 (Univariate):\n",
    "- 한 번에 파악하려는 변수가 한 개\n",
    "- 특정 변수 안에 존재하는 '패턴'을 확인\n",
    "\n",
    "2. 다변량 (Multi-variate):\n",
    "- 한 번에 파악하려는 변수가 여러 개\n",
    "- 여러 변수들 간의 '관계' 확인\n",
    "\n",
    "-> 다변량 이전에 일변량 데이터 탐색을 먼저 진행하는 것이 오류에 대처하기 용이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773c11bf-76e7-4e46-85de-9132a7c08b74",
   "metadata": {},
   "source": [
    "EDA의 종류\n",
    "1. 시각화(Graphic)\n",
    "- 차트 혹은 그림 등을 이용해 데이터 확인 \n",
    "- 데이터의 대략적 형태를 한 눈에 파악 가능\n",
    "\n",
    "2. 비시각화(Non-Graphic)\n",
    "- Summary Statistics(요약통계량)를 통해 데이터를 확인\n",
    "- 정확한 값이 필요한 경우 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c7344-ae60-462e-98ea-b5475bf3ddc3",
   "metadata": {},
   "source": [
    "EDA의 유형 (대상과 종류에 따른 구분)\n",
    "1. 일변량 비시각화\n",
    "- 주어진 데이터의 분포(Distribution) 확인이 주목적\n",
    "- 빈도표, 기술통계량\n",
    "\n",
    "2. 일변량 시각화\n",
    "- 주어진 데이터를 전체적으로 살펴보는 것이 주목적\n",
    "- 파이차트, 막대그래프, 히스토그램, 박스플롯\n",
    "  \n",
    "3. 다변량 비시각화\n",
    "- 주어진 여러 변수 간 관계를 확인하는 것이 주목적\n",
    "- 교차표, 상관계수\n",
    "\n",
    "4. 다변량 시각화\n",
    "- 주어진 여러 변수 간 관계를 전체적으로 살펴보는 것이 주목적\n",
    "- 모자이크플롯, 박스플롯, 평행좌표, 산점도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f312df16-6e4b-4524-b25f-843e3a33d163",
   "metadata": {},
   "source": [
    "## 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae7e961-9155-43ff-bb7c-73897acec13c",
   "metadata": {},
   "source": [
    "데이터 읽기/쓰기\n",
    "- 읽기: 작업공간에 데이터를 불러오는 것\n",
    "- 쓰기: 새로운 데이터를 만드는 것\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15973ed7-9d07-4bd1-9590-341109ea6ec1",
   "metadata": {},
   "source": [
    "절대경로와 상대경로\n",
    "1. 절대경로\n",
    "- 처음(root파일)부터 시작해 목적지까지 전체적인 경로(URL)\n",
    "- 해당 파일까지의 모든 경로\n",
    "\n",
    "2. 상대경로\n",
    "- 현재 작업하고 있는 디렉터리 기준으로 상하위 디렉터리와 같이 상대적으로 표현되는 경로\n",
    "- ./: 현재 디렉터리\n",
    "- ../: 상위 디렉터리\n",
    "- /: 최상위(root) 디렉터리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57507ef3-427d-4e65-b0ce-e4c84f29faae",
   "metadata": {},
   "source": [
    "데이터 입출력\n",
    "- 데이터 파일의 형식에 따라 데이터를 읽고(Reader) 쓰는(Writer) 함수가 다름\n",
    "\n",
    "- **CSV: read_csv / to_csv*\n",
    "- **MS EXCEL: read_excel / to_excel*\n",
    "- JSON: read_json / to_json\n",
    "- HTML: read_html / to_html\n",
    "- SQL: read_sql / to_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fac32b1-5bef-45bc-a292-0acc161a04ff",
   "metadata": {},
   "source": [
    "CSV와 EXCEL\n",
    "1. CSV 파일: Comma Seperated Value\n",
    "- 데이터를 쉼표로 구분하고 있는 텍스트 파일\n",
    "- 데이터 크기가 작고 압축에 용이\n",
    "- 가장 널리 사용되는 데이터 형식\n",
    "\n",
    "2. EXCEL 파일: 행과 열이 데이터프레임의 행, 열로 일대일 대응\n",
    "- 여러 개의 시트로 구성된 데이터를 읽을 때 불러올 특정 시트 설정 가능\\\n",
    "ex. pd.read_excel('파일경로/파일이름.xlsx',sheet_name='Sheet2')\n",
    "- 여러 sheet를 불러올 때는 list 활용\\\n",
    "ex. pd.read_excel('파일경로/파일이름.xlsx',sheet_name=['Sheet1','Sheet2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ebfbae-a9af-45c1-9478-177af3353eee",
   "metadata": {},
   "source": [
    "데이터셋 파악하기\n",
    "\n",
    "1. 데이터 프레임 확인\n",
    "- .head(n): 데이터 프레임 상위 n개 데이터 확인\n",
    "\n",
    "2. 데이터 변수 확인\n",
    "- 변수=Column=feature\n",
    "- 변수 정의: 어떤 정보를 가지는 변수인지 확인\n",
    "- 변수 유형: 질적/범주형(Categorical Data)과 양적/수치형(Numerical Data)으로 구분\n",
    "- 변수 데이터 형식(자료형) 확인: 날짜, 수치, 텍스트, 이미지 등의 구분 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092110d-b0db-42ed-a1a4-e71b86130208",
   "metadata": {},
   "source": [
    "데이터의 종류\n",
    "\n",
    "1. 범주형 (Categorical): 몇 개의 범주로 나눠진 데이터\n",
    "   1. 명목형(Nominal): 순서 없이 단순 분류된 자료\n",
    "      ex. 성별, 성공여부, 혈액형 \n",
    "   2.  순서형(Ordinal): 범주형 데이터 중 순서 관계가 존재하는 자료\n",
    "      ex. 승객 등급\n",
    "\n",
    "\n",
    "2. 수치형 (Numerical): 숫자로 표현되는 데이터\n",
    "   1. 이산형(Discrete): 이산적인 값으로, 정수 단위로 떨어져 셀 수 있는 데이터\n",
    "      ex. 부모 및 자녀의 수, 가족구성원의 수\n",
    "   2. 연속형(Continuous): 연속적인 값을 갖는 데이터\n",
    "      ex. 신장, 체중\n",
    "\n",
    "정수면 이산형, 소수면 연속형? X\n",
    "- ex. 개설교과목 학점: 1학점, 1.5학점, 2학점, 3학점\\\n",
    "  -> 1.5라는 소수가 있지만, 연속적이지 않고 구간이 나누어져 있음\\\n",
    "  -> 이산형\n",
    "- 숫자가 의미하는 바가 특정 점(point)의 의미인지, 연속적 범위로서의 의미인지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02db2e6b-8157-492c-8cf3-80b8e705c87c",
   "metadata": {},
   "source": [
    "판다스 자료형 종류\n",
    "1. int64 정수형 데이터 (파이썬 자료형: int)\n",
    "2. float64: 실수형 데이터 (파이썬 자료형: float)\n",
    "3. object: 문자열 데이터 (파이썬 자료형: string)\n",
    "4. datetime64, timedelta64: 시간 데이터 (파이썬 자료형: 없음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e52aa9-38d9-4de3-b35b-0f3988db3f49",
   "metadata": {},
   "source": [
    "데이터 분포 확인\n",
    "- 산포도, 박스플롯, 히스토그램 등의 그래프를 통해 데이터 분포 확인 가능\n",
    "- 원시 데이터(raw data)의 평균값, 최빈값, 중간값 등 변수들의 요약통계량 확인\n",
    "- 원시 데이터의 분포를 확인하면서 전처리 아이디어를 얻을 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce1803-a403-404f-8693-cbf78a9b2c1a",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d12f1-87db-46dd-a4e1-30de767fb3e3",
   "metadata": {},
   "source": [
    "데이터 전처리: 데이터 분석(Modeling)을 위해 데이터를 적절한 방식으로 손질하는 과정\n",
    "- 데이터 분석의 정확도는 데이터의 품질에 의해 좌우됨\n",
    "- 데이터 품질을 높이기 위해 오류를 수정하고 분석 목적에 맞게 변형하는 과정 필요\n",
    "- 실제로 데이터 분석 업무 시간 중 80%정도를 데이터 수집 및 전처리 과정에 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da5a3c2-3a53-46e1-b66d-87e873f0eb6c",
   "metadata": {},
   "source": [
    "전처리의 여러 기술\n",
    "1. 데이터 정제 (Cleansing)\n",
    "   - 데이터에서 누락된 결측값 보완,이상값 제거를 통해 데이터를 깨끗이 청소\n",
    "2. 데이터 변환 (Transformation)\n",
    "   - 데이터의 일관성 확보, 데이터 중복 최소화를 통해 데이터 분석 시간 절약\n",
    "3. 데이터 필터링 (Filtering)\n",
    "   - 데이터의 오류 발견, 삭제 및 보정을 통해 데이터 품질 향상\n",
    "4. 데이터 통합 (Integration)\n",
    "   - 데이터 분석을 수월하게 하기 위해 유사한 성질의 데이터 연계, 데이터 통합 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e70eb70-4a04-4644-bb2d-85e9680759e1",
   "metadata": {},
   "source": [
    "결측값 처리\n",
    "- 결측값: 데이터 수집 과정에서 측정되지 않거나 누락된 데이터\n",
    "\n",
    "1. 결측값 확인:\n",
    "   - 데이터 프레임 상 NaN,?,0 등의 값으로 나타나는 결측값\n",
    "   - 0의 경우, 0이 측정치인지 결측치인지 확인 필요\n",
    "\n",
    "   - 결측값 관련 다양한 pandas function\n",
    "     1. .info(): 데이터 프레임의 요약 정보 출력 -> 각 열에 속하는 유요한 값(non-null 개수)\n",
    "     2. .value_counts(dropna=False): 각 열의 결측값을 포함한 전체 데이터 확인\n",
    "     3. .isnull(): 누락 데이터면 True, 유효 데이터면 False 변환\n",
    "     4. .notnull.sum(): 유효 데이터면 True, 누락 데이터면 False 변환\n",
    "     5. .isnull/notnull.sum(): 각 변수별 누락 데이터/유효 데이터의 수 확인\n",
    "     6. .replace(): 결측값이 '0'이나'?'등으로 입력된 값들을 NaN으로 변환\n",
    "2. 결측값 처리\n",
    "   1. 삭제: 데이터가 있는 행 또는 열 삭제\n",
    "      - .dropna(axis=,how=,subset=,inplace=)\n",
    "      - axis=0 (행 삭제 -default) / axis=1 (열 삭제)\n",
    "      - how='any' (하나라도 결측값이 있으면 삭제 -default) / how='all' (모든 값이 결측값일 때 삭제)\n",
    "      - subset=['Column1','Column2'] (axis=0일 때만 적용 가능 - 특정 column 기준으로 삭제)\n",
    "      - inplace=True or False - 원본 데이터 변경 여부\n",
    "      - 삭제시 주의할 점: 결측값이 *무작위*로 발생한 경우에 사용\n",
    "   2. 대체: 결측값을 다른 값으로 대체\n",
    "      - 평균값, 최빈값 등을 활용\n",
    "      - 일괄 대체: 모든 변수들을 일괄적으로 같은 값으로 대체\\\n",
    "        ex. a = df[\"열1\"].mean(axis=0)\\\n",
    "        df[\"열1\"].fillna(a, inplace=True)\n",
    "      - 유사 유형 대체: 범주형 변수들을 활용해 유사한 범주에 따라 다른 값으로 대체\\\n",
    "        ex. category_means = df.groupby('Category')['Value'].mean()\\\n",
    "        df['Value'] = df.groupby('Category')['Value'].apply(lambda x: x.fillna(x.mean()))\n",
    "      - 서로 이웃하고 있는 값으로 치환\n",
    "        - 바로 직전 행 값: df[\"열2\"].fillna(method=\"ffill\", inplace=True)\n",
    "        - 바로 직후 행 값: df[\"열3\"].fillna(method=\"bfill\", inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1391bb5d-2c2e-4490-8c64-a71bc722312d",
   "metadata": {},
   "source": [
    "이상치 처리\n",
    "- 이상치: 관측된 데이터의 범위에서 많이 벗어난 값\n",
    "\n",
    "1. 이상치 확인\n",
    "    1. 요약통계량 확인: describe()\n",
    "    2. 시각화 확인: Boxplot\n",
    "    3. Z-score를 통해 확인:\n",
    "       - 데이터를 평균(0)과 표준편차(1)로 정규화해, 평균으로부터 얼마나 떨어져 있는지 나타냄\n",
    "       - 평균에 가까울수록 0에 가깝고 멀어질수록 Z-score 커짐\n",
    "       - Z-score가 특정 기준값(일반적으로 2~3)을 넘어 가는 데이터 = 이상치\n",
    "    4. Tukey Fences을 통해 확인: like Boxplot\n",
    "       - 사분위 범위(IQR: Interquartile Range)를 기반으로 두 가지 경우에 이상치라고 판단\n",
    "       - (Q1-IQR * 1.5 미만) & (Q3+IQR * 1.5 초과)\n",
    "2. 이상치 제거\n",
    "   1. 전체 삭제\n",
    "      - 이상값이 Human error에 의해 발생한 경우, 해당 관측치 삭제\n",
    "      - 단순 오타, 주관식 설문 등의 비현실적 응답, 데이터 처리 과정에서의 오류 등의 상황에서 사용\n",
    "    2. 다른 값 대체\n",
    "       - 절대적인 관측치 숫자가 작은 경우, 단순 삭제는 관측치의 절대량이 작아져 신뢰성 문제 발생\n",
    "       - 평균 값 등의 적절한 값으로 대체\n",
    "       - 다른 변수들을 사용해 예측 모델을 만들고, 이상값을 예측치로 대체\n",
    "    3. 변수화\n",
    "       - 이상값이 자연 발생한 경우, 단순 삭제나 대체의 방법을 통해 수립된 모델은 오류가 있을 수 있음\n",
    "       - 자연발생적 이상값은 해당 이상값에 대해 신중하게 파악 필요\n",
    "       - ex. 의사 등 전문직 종사자들의 연봉 상승치는 이상치지만 자연발생적\\\n",
    "         -> 전문직 종사 여부를 Yes-No로 변수화하면 이상값을 삭제하지 않고 모델에 포함 가능\n",
    "    4. 리샘플링\n",
    "       - 이상값을 분리해서 모델 형성\n",
    "       - 변수화를 적용하는 상황과의 다른 점:\n",
    "         - 변수화: 독립 변수, 종속 변수 중 하나의 변수만 예측치를 벗어남\n",
    "         - 리샘플링: 독립 변수, 종속 변수 두 개의 변수 모두 예측치를 벗어남\n",
    "        - 이상값을 포함한 모델과 제외한 모델을 모두 만들고 각각의 모델에 대한 설명 추가\\\n",
    "       -> 자연발생한 이상값에 별다른 특이점이 발견되지 않는다면, 단순 제외보다 케이스 분리 분석 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170ee81f-d189-42ab-9764-9749fce9b35b",
   "metadata": {},
   "source": [
    "피처 엔지니어링 (변수 가공)\n",
    "- 해결하고자 하는 문제를 컴퓨터가 잘 이해할 수 있도록 변수(feature)들의 형태를 변형하거나 적절하게 처리\n",
    "- 피처(feature)=입력 변수=column\n",
    "- 도메인 지식과 기존 변수를 사용해 기존 데이터에 정보를 추가하는 일련의 과정\n",
    "- 데이터 전처리의 마지막 단계 \n",
    "- 새로운 데이터, 변수의 추가 없이 기존의 데이터를 보다 유용하게 만드는 방법\n",
    "- 도메인 지식 여부에 따라 변수 가공의 결과와 유의성이 달라짐\n",
    "\n",
    "1. 레이블 인코딩: 텍스트로 주어지는 값을 숫자로 바꾸는 작업\n",
    "- Label Encoding: 범주형 변수를 0~N-1까지의 숫자로 변환\n",
    "- One-Hot Encoding: 범주형 변수를 이진 벡터(0과 1)로 변환\\\n",
    "pd.get_dummies(데이터프레임,columns=[컬럼 리스트])\n",
    "\n",
    "2. 구간화 (binning)\n",
    "- 연속 데이터를 일정한 구간으로 나눠서 분석 (데이터 분석의 효율화)\n",
    "- 분석 목적과 방법 등 필요한 영역에 따라 분석가의 도메인 지식 최대한 활용해 수행\n",
    "- pd.cut(데이터프레임[컬럼명],bins=[나누는 기준 리스트],labels=[지정할 label])\n",
    "\n",
    "3. 변환\n",
    "- 기존의 피처를 다른 피처로 변환해 변수 추가\n",
    "- 기존 데이터의 특성/다른 정보를 이용해 다른 데이터로 변환 및 분석\n",
    "- 분석가의 데이터 특성에 대한 이해도에 따라 다양한 데이터 생성 가능\n",
    "\n",
    "4. 스케일링\n",
    "- 서로 다른 변수 값 범위를 일정한 수준으로 맞추는 작업\n",
    "- 숫자의 상대적 크기 차이로 인한 결과의 왜곡 방지\n",
    "- 각 열에 속하는 데이터 값을 동일한 크기 기준으로 나눈 비율로 나타내는 정규화 작업(normalization)\n",
    "- 모든 스케일러는 이상치에 민감하기 때문에 이상치 제거 선행 필수\n",
    "- 변수 변환: 변수의 단위 변경/변수 분포 편향 조정/변수 간 관계 모호 등의 상황에서 사용\n",
    "  - 가장 자주 사용하는 방법: Log 변환 (좀 덜 사용되지만 제곱근 변환(sqrt)도 활용)\n",
    "  - 라이브러리 임포트: from sklearn.preprocessing import [StandardScaler, MinMaxScaler, QuantileTransformer, RobustScaler]\n",
    "1. StandardScaler() (표준화)\n",
    "   - 각 feature 평균을 0, 분산 1로 표준 정규분포화\\\n",
    "     -> 정규분포를 따른다고 가정하는 기술에 적합\n",
    "2. MinMaxScaler()\n",
    "   - 모든 feature가 0과 1 사이에 위치\n",
    "   - 데이터가 2차원일 경우, 모든 데이터는 x, y축 0~1사이에 위치\n",
    "   - 데이터가 서로 다른 비율의 속성으로 구성되어 있을 때, 같은 비율로 속성 통일\n",
    "   - 연산 속도 높이기, 알고리즘 최적화에 효과적"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2877e2-11cf-4937-881e-e309da4191e4",
   "metadata": {},
   "source": [
    "## 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df50d987-36d1-4053-959b-aa93d03e5a6c",
   "metadata": {},
   "source": [
    "시각화: 데이터와 정보를 시각적 형태로 표현하는 과정/결과물\n",
    "- 숫자, 텍스트로 표현되는 정보를 그래프, 차트, 그림, 도표 등 시각적 요소로 변환\n",
    "- 데이터의 패턴, 관계, 추세 등 쉽게 파악 가능\n",
    "- Matplotlib: Python 프로그래밍 언어 및 수학적 확장 numpy 라이브러리를 활용한 플로팅 라이브러리\n",
    "  - import matplotlib.pyplot as plt\n",
    "- Seaborn: matplotlib을 기반으로 만들어져 통계 데이터 시각화에 최적화된 인기 라이브러리\n",
    "  - import seaborn as sns\n",
    "- 시각화 시작 전, 범주형/수치형 데이터 유형 파악 + 결측값 및 이상치 확인 필요\n",
    "- 데이터를 어떻게 탐색할지에 따라 다양한 시각화 툴 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c188b-8285-425c-bb15-8821791483c9",
   "metadata": {},
   "source": [
    "파라미터\n",
    "- 컴퓨터 프로그래밍에서 프로그래밍된 함수의 입력값\n",
    "- 함수를 내가 원하는 조건에 맞춰 이용하기 위해 '파라미터=인자' 형식을 전달\\\n",
    "  ex. data=df, x='Survived'\\\n",
    "  -> data,x = 파라미터 / df, 'Survived'는 인자\\\n",
    "  -> df라는 데이터셋 내의 'Survived' 변수를 함수에 적용 \n",
    "     - 다른 형태:\\\n",
    "       def 함수이름(파라미터1, 파라미터2)\\\n",
    "       print(파라미터1, 파라미터2)\\\n",
    "       \\\n",
    "       함수이름(\"인자1\",\"인자2\")\n",
    "       \n",
    "- 파라미터와 인자 개념은 모든 함수에서 사용됨\n",
    "- 'hue': 범주형 변수를 인자로 활용해, 내가 원하는 변수를 기준을 데이터를 구분해 그래프에 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338a8305-9877-4fb7-a3cb-54b2e3c217d2",
   "metadata": {},
   "source": [
    "다양한 그래프\n",
    "1. Boxplot (상자 수염 그림)\n",
    "   - 사분위수와 이상치를 보여주는 그래프\n",
    "   - 요소: 최소값, Q1, 중앙값, Q3, 최대값, 수염, 이상점, 극단점\n",
    "   - sns.boxplot(data=data,x='변수명1',y='변수명2')\n",
    "\n",
    "2. countplot\n",
    "    - 범주형 변수의 빈도수를 확인하는 그래프\n",
    "    - sns.countplot(data=data,x='변수명1',hue='변수명2')\n",
    "\n",
    "3. histplot\n",
    "    - 수치형 변수의 구간별 빈도수를 확인하는 그래프\n",
    "    - 도수분포표를 그래프로 나타낸 것\n",
    "    - sns.histplot(data=data,x='변수명1',hue='변수명2')\n",
    "\n",
    "4. displot, kdeplot (커널밀도추정 그래프)\n",
    "   - 히스토그램을 연속적인 곡선으로 연결한 그래프\n",
    "   - sns.displot(data['변수명'],kde=True)\n",
    "     - kde 파라미터에 True를 전달해 곡선 표현\n",
    "   - sns.kdeplot(data['변수명'])\n",
    "\n",
    "5. barplot\n",
    "   - 범주형 데이터 값 x에 따른 수치형 데이터 값 y의 평균 값 제공\n",
    "   - Seaborn barplot()의 검은 선 = 신뢰구간 (Confidence Interval, CI)\n",
    "     - 신뢰구간: 막대의 평균 값이 얼마나 신뢰할 수 있는지를 나타내는 구간 (default: 95%)\n",
    "     - ci 파라미터를 활용해서 n% 신뢰구간 표시 가능\n",
    "    - sns.barplot(data=data,x='변수명1',y='변수명2',hue='변수명3')\n",
    "\n",
    "6. pointplot\n",
    "   - 막대 그래프와 동일한 정보 제공\n",
    "   - sns.pointplot(data=data,x='변수명1',y='변수명2',hue='변수명3')\n",
    "\n",
    "7. scatterplot (산점도 그래프)\n",
    "   - 두 변수 간 관계를 시각화\n",
    "   - 각각의 데이터 포인트는 두 변수으 값\n",
    "   - x축과 y축에 데이터 포인트를 분산해 그림\n",
    "   - 변수 간 패턴, 상관관계, 분포 파악 가능\n",
    "   - sns.scatterplot(data=data,x=\"변수명1\",y=\"변수명2\",hue=\"변수명3\",size='변수명4',sizes=(x,y))\n",
    "\n",
    "8. regplot\n",
    "   - 두 개의 연속 변수 사이의 산점도 + 회귀선\n",
    "   - fit_reg 파라미터에 False를 전달하면 회귀선 X\n",
    "   - sns.regplot(x='변수명1',y='변수명2',data=data,ax=1, fit_reg=False)\n",
    "\n",
    "9. catplot (categoryplot)\n",
    "    - 수치형 데이터와 범주형 데이터의 관계\n",
    "    - sns.catplot(x='범주형 변수', y='수치형 변수', hue='기준이 될 변수', data=data)\n",
    "\n",
    "10. pieplot\n",
    "    - 데이터의 부분과 전체 간 비율 표현 그래프\n",
    "    - 비율을 강조하기 위해 사용\n",
    "    - 모든 데이터가 합쳐서 전체를 이루는 경우 효과적 (모두 합쳐서 1 or 100%)\n",
    "    - plt.pie (data, labels=라벨 리스트, autopct=라벨에 표시되는 퍼센트)\n",
    "\n",
    "11. heatmap\n",
    "     - 변수간 상관계수를 직관적으로 볼 수 있는 그래프\n",
    "     - corr() 메소드로 변수 간 상관계수를 구하고, 히트맵에 표현 가능\n",
    "        - 상관계수: 두 수치형 변수 사이의 상관 관계의 방향과 정도를 수치적으로 나타낸 계수\n",
    "        - -1에 가까울 수록 음의 상관관계\n",
    "        - 1에 가까울 수록 양의 상관관계\n",
    "        - 0에 가까울 수록 상관관계 X\n",
    "    - sns.heatmap(df.corr(),annot=True)\n",
    "       - annot 파라미터는 상관계수 표시 여부\n",
    "\n",
    "12. violinplot\n",
    "    - 박스그림 + 커널밀도추정 그래프\n",
    "    - sns.violinplot(x='변수1',y='변수2',hue='변수3',data=data,split=True)\n",
    "    - 특정 변수에 따른 분포를 추가적으로 살펴볼 때\\\n",
    "      -> hue='변수명', split=True 추가\n",
    "\n",
    "13. subplot\n",
    "    - f, ax = plt.subplot(1,2,figsize=(12,4))\\\n",
    "      sns.countplot(x='변수1',data=data,ax=ax[0])\n",
    "      sns.barplot(data=data,x='변수1',y='변수2',hue='변수3',ax=ax[1])\n",
    "    - 1행 2열의 (12,4)사이즈의 서브플롯 생성\\\n",
    "      -> 그 후에 각 그래프를 ax[i]에 할당해 원하는 위치에 출력\n",
    "\n",
    "14. pairplot\n",
    "    - 여러변수 간의 산점도를 한 번에 보여주는 그래프\n",
    "    - sns.pairplot (data=data, hue=\"변수\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f93c67-76d1-46e8-9b26-63f5fb502655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "600a8b26-06f4-48ac-af04-0c70a380948d",
   "metadata": {},
   "source": [
    "# 분류 (Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7b67d8-e07a-4deb-bc8b-21454f8ebc13",
   "metadata": {},
   "source": [
    "## 분류란?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c9095a-218f-4a02-ab3c-6d807d812d8d",
   "metadata": {},
   "source": [
    "### 머신러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ffdc37-eaf0-4cc4-938f-64ffd722d163",
   "metadata": {},
   "source": [
    "머신러닝\n",
    "- 컴퓨터가 스스로 어떠한 판단이나 예측을 할 수 있게 하는 학습 알고리즘이나 기술을 개발하는 인공지능의 분야\n",
    "- 프로세스\n",
    "  1. 알고리즘을 이용한 데이터 분석\n",
    "  2. 분석 결과 스스로 학습\n",
    "  3. 학습 결과를 기반으로 판단 / 예측 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c078f9-f341-417e-8d86-a08279541e76",
   "metadata": {},
   "source": [
    "### 지도학습과 비지도 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1d8d00-a863-4da3-bbe3-f0b6cb0d7778",
   "metadata": {},
   "source": [
    "1. 지도 학습 (Supervised Learning)\n",
    "- 정답이 있는 데이터 사용 (labeled data: 독립변수와 종속변수가 모두 존재하는 데이터)\\\n",
    "  *독립변수 (feature): 예측에 사용되는 입력 변수\\\n",
    "   *종속변수 (target/label) : 예측하고자 하는 대상 변수\n",
    "- 예측값을 이미 만들어둔 정답과 같아지도록 기계를 학습시키는 것\n",
    "- 회귀, 분류\n",
    "\n",
    "2. 비지도 학습 (Unsupervised Learning)\n",
    "- 정답이 없는 데이터 사용 (target/label 없이 feature만 있는 데이터)\n",
    "- 데이터 속의 패턴 또는 각 데이터 간의 유사도를 기계가 학습하도록 하는 것\n",
    "- 군집화, 밀도 추정, 차원 축소\n",
    "\n",
    "3. 강화학습\n",
    "- 시행착오를 반복해 정답을 찾는 과정\n",
    "- 알파고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214cfb38-3e5d-4a49-96d3-c00a3cd28949",
   "metadata": {},
   "source": [
    "### 지도 학습: 회귀와 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc466553-aefe-4c5e-afbb-e86115841747",
   "metadata": {},
   "source": [
    "- 회귀: 연속형 변수의 예측\n",
    "- 분류: 범주형 변수의 예측\n",
    "\n",
    "- 사용 결정 기준: 예측하고자 하는 값(=종속변수, Target, Label)의 데이터 유형 (연속형/범주형)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e1a238-3ffe-408e-a730-2c1362ed4fe6",
   "metadata": {},
   "source": [
    "### 이진 분류와 다중 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c53417-a619-4e60-8874-93aa4c28c8e8",
   "metadata": {},
   "source": [
    "- 이진 분류\\\n",
    "  예측하고자 하는 변수 어떤 기준에 대해 참(True, 1)/거짓(False, 0)의 값만 가짐\n",
    "\n",
    "- 다중 분류\\\n",
    "예측하고자 하는 변수가 가질 수 있는 값이 3개 이상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a45761-c1e6-463d-83f6-208d2e638d4c",
   "metadata": {},
   "source": [
    "## 분류 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddd3a77-b53d-4184-9d11-297b61bfc36f",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀 (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3da53-b4d6-4ec8-b03e-cd372c84fa7c",
   "metadata": {},
   "source": [
    "- 이진 분류 문제 활용\n",
    "- 목표: 샘플이 특정 클래스에 속할 확률 추정\n",
    "- 독립 변수의 선형 조합(선형 회귀)에 로지스틱 함수를 적용해, 출력값을 0~1 사이로 변환\n",
    "\n",
    "- 형태: 시그모이드 함수(Sigmoid Function)\n",
    "  - 1 / 1+e^(-(wx+b))\n",
    "  - 출력이 0~1 사이의 값을 가지면서 S자 형태\n",
    "  - 입력값이 커지면 1에 수렴, 입력값이 작아지면 0에 수렴\n",
    "  - 출력값이 특정값 이상이면 1(True), 이하면 0(False)로 설정\n",
    "  - 코드\n",
    "    - def sigmoid(x):\\\n",
    "      return 1/(1+np.exp(-x))\n",
    "  - 인공지능의 역할: 주어진 데이터에 적합한 시그모이드 함수의 가중치 w와 b 구하기\n",
    "    - w: 그래프의 기울기 변화\n",
    "    - b: 그래프의 위치 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48348f5d-466c-48ab-9dfe-494c6e807f67",
   "metadata": {},
   "source": [
    "### 오즈 (Odds, 승산)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2b36d-2358-430d-82a9-9759e16555ec",
   "metadata": {},
   "source": [
    "- 특정 사건 발생 확률 / 발생하지 않을 확률\n",
    "- 로지스틱 회귀에서 승산을 사용하는 이유\n",
    "  - 해석을 더 직관적으로 하기 위해\n",
    "  - 비선형적 결과를 선형 결과로 변환하기 위해\n",
    "\n",
    "- 로지스틱 회귀는 선형 회귀 모델에 시그모이드 함수를 적용해 비선형성을 준 모델\n",
    "  - 가중치 w,b가 증가할 때 어떤 결과가 나오는지 직관적 파악이 어려움\n",
    "  - 오즈를 활용하면 모델의 결과를 선형적으로 해석할 수 있게 됨\n",
    "\n",
    "- logit(p) = log (p(A)/1-p(A))\n",
    "  - 오즈의 로그변환\n",
    "  - p(A) = 1 / 1+e^(-(wx+b))\n",
    "    - 양 변에 logit 함수를 적용하면\n",
    "    - logit(p) = wx+b\n",
    "      - 선형 관계로 변환됨\n",
    "\n",
    "- 로그를 사용하는 이유\n",
    "  - 단순히 오즈로 변환하면, 불균형성을 가짐 (온전한 선형 관계 X)\n",
    "  - 로그를 취해주면 확률이 0.5일 때를 기준으로 점대칭 함수가 됨\n",
    "    - 더 직관적인 가중치 해석 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1313bf83-8038-4baf-a376-0f42edfe2edb",
   "metadata": {},
   "source": [
    "### 결정 나무 (Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221aed99-e78f-442e-b836-7530a81c7cf2",
   "metadata": {},
   "source": [
    "- 조건에 따라 데이터를  분류해서, 최종적으로 데이터가 순수한 label의 집합으로 구성될 때까지 분류를 반복하는 모델\n",
    "- 단어 정리\n",
    "    - Root Node: Decision Tree의 시작이 되는 노드\n",
    "    - Edge: 노드와 노드를 연결하는 길목 (가지)\n",
    "    - Leaf Nodes: Tree의 가장 마지막 노드로, 모델에서 label에 해당\n",
    "    - Height(depth): Tree의 깊이로, 클수록 tree의 구조는 복잡해짐\n",
    "    - Level: 노드의 절대적 위계, Root node의 level = 0, leaf node의 level = height - 1\n",
    "    - Parent: 상대적으로 높은 위계의 노드\n",
    "    - Child: 상대적으로 낮은 위계의 노드\n",
    "        - Binary Tree(이진 트리): Tree 중에서 children이 최대 2개인 tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6e1dff-9d27-4a07-9e83-ba3ca669afa2",
   "metadata": {},
   "source": [
    "CART (Classification And Regression Tree)\n",
    "- 가장 대표적인 결정 나무 알고리즘\n",
    "- 데이터셋을 임계값 기준으로 두 child로 나누는 알고리즘\n",
    "  - 임계값의 설정 기준: 불순도(지니계수)가 낮아지는 방향\n",
    "    - 분류하려는 데이터 집합에서 서로 다른 클래스(범주)가 섞여 있는 정도\n",
    "    - CART 알고리즘에서 사용하는 불순도 확인 기준 = 지니 계수\n",
    "      - 통계적 분산 정도를 0~1 사이 값으로 정량화해서 표현한 값\n",
    "      - Gini 최소값 : 0, 데이터가 한 개의 class에만 속하는 경우\n",
    "      - Gini 최대값 : 모든 class가 동일한 비율로 존재하는 경우 (class 2 = 0.5, class 3 = 0.33...)\n",
    "- 프로세스\n",
    "  1. 임의의 임계값 설정\n",
    "  2. 불순도(지니 계수) 감소 알고리즘\n",
    "     - Greedy Algorithm\n",
    "     - CART 알고리즘이 당장의 지니계수를 낮추는 판단만 해 가장 최적의 대안을 제시할 수 없는 문제\n",
    "     - like Local Minima\n",
    "     - Tree의 Height 고려 없이, 당장의 Level에서만 최적 선택\n",
    "- 학습시 고려 사항\n",
    "  1. Parameter 설정\n",
    "     1. min_sample_split: 분할되기 의해 노드가 가져야 하는 최소 샘플(데이터) 수\n",
    "     2. min_sample_leaf: 리프 노드가 가지고 있어야 하는 최소 샘플 수\n",
    "     3. min_weight_fraction_leaf: min_sample_leaf와 동일, But 가중치가 부여된 전체 샘플 수에서의 비율\n",
    "     4. max_leaf_nodes: 리프 노드의 최대 개수\n",
    "     5. max_features: 각 노드에서 분할에 사용할 특성(feature)의 최대 수\n",
    "  2. 시각화\n",
    "     - 과적합 여부 눈으로 직관적인 확인\n",
    "  3. Prunning(가지치기)\n",
    "     - 불필요한 노드 지우기\n",
    "     - 과적합을 방지하기 위한 절차\n",
    "     - 하부 트리를 제거해 일반화 성능 높이기\n",
    "     - 깊이(Height), 결과 개수(Leaf Nodes) 감소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a29dcf6-3b2d-4b01-933a-f7866827a5b1",
   "metadata": {},
   "source": [
    "### 서포트 벡터 머신 (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713f8e1c-a6fb-42dc-a1f3-89146ac13eb7",
   "metadata": {},
   "source": [
    "- 클래스를 분류할 수 있는 다양한 경계선 중 최적의 라인을 찾아내는 알고리즘\n",
    "- 명확하게 분류할 수 있는 데이터 집단 + 고차원 공간(다수 Feature)에서 효과적\n",
    "\n",
    "- 구성\n",
    "  1. Support Vector\n",
    "     - 구분하는 선과 가장가까운 포인트\n",
    "  2. Decision Boundary(결정 경계)\n",
    "     - 집단을 구분하는 선\n",
    "  3. Margin\n",
    "     - 선과 각 점의 거리\n",
    "\n",
    "- 결정 경계의 선택 기준(최적의 분류 선)\n",
    "  - Margin(거리)가 가장 큰 경우 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e356a-e774-48e5-848b-30f04e7f0ead",
   "metadata": {},
   "source": [
    "### KNN (K=Nearest Neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceded0ec-3aff-4960-83a0-0a91ca73764e",
   "metadata": {},
   "source": [
    "- 비슷한 특성을 가진 데이터끼리 서로 가까이 있다는 점을 이용한 분류 알고리즘 (유유상종)\n",
    "- 데이터로부터 거리가 가까운 k개의 다른 데이터 레이블을 참조해 분류하는 알고리즘\n",
    "\n",
    "- 프로세스\n",
    "  1. 데이터 준비\n",
    "     - 데이터 구성: 특징 벡터(위치 정보) + 레이블(Class, 범주)\n",
    "  2. K 값 설정\n",
    "     - 가장 가까운 이웃의 개수\n",
    "     - 보통 홀수 개로 설정 (짝수 설정 시의 동점 발생 문제)\n",
    "  3. 거리 계산\n",
    "     - 새로운 데이터가 주어지면, 이 값과 기존 모든 데이터 간의 거리 계산\n",
    "     - 유클리드 거리, 맨해튼 거리 등 사용\n",
    "  4. 가장 가까운 K개의 이웃 선택\n",
    "     - 계산된 거리 중 가장 작은 값을 가진 K 개의 데이터 선택\n",
    "  5. 분류하기\n",
    "     - K개 이웃 중 가장 많이 등장하는 클래스 = 예측 결과\n",
    "    \n",
    "- 장점\n",
    "  1. 훈련 필요 없음\n",
    "     - 별도의 모델 없이 기존 데이터만을 이용해서 새로운 데이터 분류 가능\n",
    "  2. 정보 손실 없음\n",
    "- 단점\n",
    "  1. 쿼리를 처리하는 데 시간이 오래 걸림\n",
    "     - 모든 기존 데이터에 대한 신규 데이터의 거리 계산 (데이터 수가 많아질수록, 오래 걸릴 수밖에)\n",
    "  2. 이상치에 큰 영향을 받음 (Not Robust)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5f77f5-cd66-4e0a-96f6-5b6ef9c34eb5",
   "metadata": {},
   "source": [
    "### 앙상블 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7fc606-73fd-4ba6-8d3e-04ea1b919bef",
   "metadata": {},
   "source": [
    "- 여러 개의 개별 분류 모델들을 결합해 하나의 분류 모델보다 더 좋은 성능을 내는 머신러닝 기법\n",
    "\n",
    "1. 보팅 (Voting)\n",
    "   - 다른 알고리즘의 모델을 병렬로 사용\n",
    "  \n",
    "2. 배깅 (Bagging)\n",
    "   - 동일 알고르짐의 모델을 병렬로 사용\n",
    "3. 부스팅 (Boosting)\n",
    "   - 동일 알고리즘의 모델을 직렬로(순차적으로) 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ea4e30-2ec1-4230-8487-253c19349e6c",
   "metadata": {},
   "source": [
    "## 분류 평가 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b434720c-7bd8-4de0-9555-9c2430e5b388",
   "metadata": {},
   "source": [
    "### 혼동 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a882c17b-6b8a-4860-b030-cbe7c0637288",
   "metadata": {},
   "source": [
    "- 분류 모델의 예측 결과를 정확한 예측과 잘못된 예측으로 구분해 나타낸 매트릭스 표\n",
    "- 총 4가지 경우의 수 (예측 성공 여부(T/F), 예측값(P/N)으로 구분)\n",
    "  1. True Positive(TP)\n",
    "  2. True Negative(TN)\n",
    "  3. False Positive(FP) - 위양성 (1종 오류, 알파)\n",
    "  4. False Negative(FN) - 위음성 (2종 오류, 베타)\n",
    "- 혼돈행렬을 이용한 분류 모델 평가 지표 (0~1의 값)\n",
    "  1. 정확도 (Accuracy)\n",
    "     - 모든 예측 중 참인 비율\n",
    "     - 모델이 입력된 데이터에 대해 얼마나 정확하게 예측하는지 나타냄\n",
    "     - TP + TN / 전체\n",
    "     - 단점: 정답 레이블의 비율이 불균형하면, 모델의 정확도 신뢰 불가능\n",
    "       - 하나의 레이블이 95%의 비율을 가지고 있다면, 100%로 예측해도 95%의 정확도가 나옴\n",
    "  2. 정밀도 (Precision)\n",
    "     - 참이라고 예측한 경우 중 실제 참의 비율\n",
    "     - 정밀도가 높을수록, 거짓을 참으로 예측하는 정도(FP - 위양성)가 낮음\n",
    "     - TP / TP + *FP*\n",
    "  3. 재현도 (Recall)\n",
    "     - 실제로 참인 경우 중 참으로 예측하는 비율\n",
    "     - 재현도가 높을수록, 참을 거짓으로 예측한 정도(FN - 위음성)가 낮음 \n",
    "     - TP / TP + *FN*\n",
    "  - 모델의 종류와 역할에 따라 특정 평가 지표의 중요도 달라짐\n",
    "  - 정밀도와 재현도는 서로 Trade-Off 관계\n",
    "    - 분류를 할 때, 확률 기반의 Threshold를 설정 (Treshold 이상이면 Positive, 이하면 Negative 예측)\n",
    "      - Threshold 높아지면 -> 정밀도 증가 (재현도 감소)\n",
    "      - Threshold 낮아지면 -> 재현도 증가 (정밀도 감소)\n",
    "    - 정밀도 & 재현도 그래프가 Threshold 결정에 도움 가능\n",
    "      - 모든 임계값에 대해 모델이 해당 임계값에서 가지는 정밀도와 재현도 값을 점으로 표현(->선)\n",
    "      - 두 값이 만나는 지점을 임계값으로 정할 때, 예측 오류 최소화 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6af03a-3d82-4d73-8d2c-a3e1c490cae2",
   "metadata": {},
   "source": [
    "### F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce9b67-fd32-4f74-a28e-3f2a4e381ca0",
   "metadata": {},
   "source": [
    "- 정밀도와 재현율의 조화 평균\n",
    "- 2*Precision*Recall / Precision + Recall\n",
    "- 정밀도와 재현율 간 균형을 효과적으로 평가하기 위해서 고안된 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ce7bd2-7e03-47ac-aa60-a136007ae1a4",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ca9845-a3a9-4785-9504-7d64beb0790f",
   "metadata": {},
   "source": [
    "- 얼마나 분류가 잘 되었는가를 보여주는 지표\n",
    "- 좌상단으로 붙어있는 ROC 커브일 수록 더 좋은 분류\n",
    "- x축: True Positive Rate(TPR)\n",
    "  - 참인 것들 중 참이라고 예측한 비율 (=Recall)\n",
    "  - TP / TP + NF\n",
    "- y축: False Positive Rate(FPR)\n",
    "  - 거짓인 것들 중에 참이라고 잘못 예측한 비율\n",
    "  - FP / TN + NP\n",
    "- 완벽한 분류기를 만들기는 어려움\n",
    "  - 현실적인 한계 (비용, 시간 등)을 고려해 적절히 타협한 최선의 ROC Curve 도출 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6974bd1a-00b1-4911-a237-5566c99aac7d",
   "metadata": {},
   "source": [
    "### AUC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63443c81-f624-4e35-9139-bec22ab98e68",
   "metadata": {},
   "source": [
    "- ROC와 x축 사이의 면적 (적분값)\n",
    "- 모델의 성능을 숫자로 나타낼 수 있음\n",
    "- 0~1사이의 값을 가지며, 1에 가까울수록 분류 성능 좋은 것으로 해석\n",
    "- 두 모델의 성능에 대한 수치적 비교 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a55b1e-669f-431e-80b2-831767d76347",
   "metadata": {},
   "source": [
    "### 다중 분류 평가 지표(참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a2a398-2812-489a-a9ac-71c0b61d3532",
   "metadata": {},
   "source": [
    "- 이진 분류 평가지표를 사용해서 클래스별로 점수를 구한 뒤, 이를 적절히 평균 내리는 것\n",
    "1. Macro Average\n",
    "   - 클래스별로 구한 평가 지표 평균\n",
    "   - 모든 라벨이 유사한 중요도를 가질 때\n",
    "2. Weighted Average\n",
    "   - 클래스별로 구한 평가 지표 가중평균\n",
    "   - 샘플이 많은 라벨에 중요도를 두고 싶을 때 (특정 클래스의 데이터 수가 많을 때)\n",
    "3. Micro Average\n",
    "   - 모든 클래스의 예측 결과를 더해, 전체적인 성능을 평가하는 지표\n",
    "   - 라벨에 상관없이 전체적인 성능을 평가하고 싶을 때"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338b7544-e8c2-4af1-96c9-a385bc0b2073",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df7fc6-ba1a-401d-a1e4-71ae31dd58f9",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8681db10-1be1-4054-ba0d-c0a848ef730c",
   "metadata": {},
   "source": [
    "- 하이퍼파라미터 (Hyperparameter)\n",
    "  - 모델 학습 과정에 반영되는 값\n",
    "  - 학습 시작 전에 사용자가 직접 설정하는 변수\n",
    "- 하이퍼파라미터 최적화 (Hyperparameter Optimization)\n",
    "  - Tuning을 거쳐, 적절한 하이퍼파라미터를 찾음으로써 Model 성능을 향상시키는 것\n",
    "\n",
    "- Optuna 라이브러리를 통해 하이퍼파라미터 최적화 자동화 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91027b32-bf9a-41a2-a4c1-28f21c4c4604",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 최적화 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df2cae-6f83-4596-91cb-6e39699f1d51",
   "metadata": {},
   "source": [
    "1. 하이퍼파라미터 탐색 범위 설정\n",
    "2. 평가 지표 계산 함수 (성능 평가 함수) 정의\n",
    "   - 탐색하려는 하이퍼파라미터를 인수로 사용\n",
    "3. 1단계에서 샘플링한 하이퍼파라미터 값을 사용해 검증 데이터로 정확도 평가\n",
    "4. 1~3단계를 특정 횟수 반복, 정확도 결과를 보고 하이퍼파라미터 범위 좁히기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efce8fe8-7ab1-4f71-ab7b-7d5adab0dd6a",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 최적화 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223489b2-053c-4329-8f84-3d431ba3c1c4",
   "metadata": {},
   "source": [
    "1. Grid Search\n",
    "   - 정해진 범위에서 하이퍼파라미터를 모두 순회해, 가장 좋은 성능을 내는 값 탐색\n",
    "   - 장점\n",
    "     - 범위가 넓고 step이 작을수록 꼼꼼하게 전 범위를 탐색해 최적해를 정확히 찾을 수 있음\n",
    "   - 단점\n",
    "     - 시간이 오래 걸림\n",
    "   - 적용\n",
    "     - 넓은 범위, 큰 step을 활용해 범위를 좁히기\n",
    "\n",
    "2. Random Search\n",
    "   - 정해진 범위에서 하이퍼파라미터를 무작위로 탐색해, 가장 좋은 성능을 내는 값 탐색\n",
    "   - 장점\n",
    "     - 속도가 Grid Search보다 빠름\n",
    "   - 단점\n",
    "     - 무작위라는 한계, 정확도 떨어짐\n",
    "3. Bayesian Optimization\n",
    "   - 사전 정보를 바탕으로 최적 하이퍼파라미터 값을 확률적으로 추정해 탐색\n",
    "   - 'Gausain Process'라는 통계학을 기반으로 만들어진 모델로, 여러 개의 하이퍼 파라미터들에 대해 'Aquisition Function\"을 적용했을 때, \"가장 큰 값\"이 나올 확률이 높은 지점을 찾아냄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184f17c6-629d-4477-8b21-03c1b44db4a5",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 최적화 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8192399-78c5-4322-9efb-1696b9f6e40a",
   "metadata": {},
   "source": [
    "- 3가지의 데이터 구성\n",
    "  1. 훈련 데이터 (Train): 매개변수(가중치와 편향) 학습에 이용\n",
    "  2. 검증 데이터 (Valid): 하이퍼파라미터 성능을 평가하는 데 이용\n",
    "  3. 테스트 데이터 (Test): 신경망의 범용 성능을 평가하는 데 이용 (모델의 최종 성능 평가)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadfa738-ed8b-416b-ae5b-a8924ea793fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

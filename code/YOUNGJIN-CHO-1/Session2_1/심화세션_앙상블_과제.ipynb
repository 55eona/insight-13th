{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b9a401",
   "metadata": {},
   "source": [
    "### 분석에 필요한 패키지 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5a2870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 코드의 주석을 해제하고 패키지를 설치해주세요.\n",
    "!pip install xgboost lightgbm catboost scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eda398fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42 # random state 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ea2fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    VotingClassifier,\n",
    "    RandomForestClassifier, AdaBoostClassifier,\n",
    "    GradientBoostingClassifier, StackingClassifier\n",
    ")\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d0584e",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2901d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df라는 변수에 'Employee.csv' 파일을 읽어와 저장합니다.\n",
    "df = pd.read_csv('Employee.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91bda9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2017</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2014</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2017</td>\n",
       "      <td>Pune</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n",
       "0  Bachelors         2017  Bangalore            3   34    Male          No   \n",
       "1  Bachelors         2013       Pune            1   28  Female          No   \n",
       "2  Bachelors         2014  New Delhi            3   38  Female          No   \n",
       "3    Masters         2016  Bangalore            3   27    Male          No   \n",
       "4    Masters         2017       Pune            3   24    Male         Yes   \n",
       "\n",
       "   ExperienceInCurrentDomain  LeaveOrNot  \n",
       "0                          0           0  \n",
       "1                          3           1  \n",
       "2                          2           0  \n",
       "3                          5           1  \n",
       "4                          2           1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "799252f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'LeaveOrNot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2381f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = target, axis =) # target 컬럼을 제외한 데이터를 X에 저장합니다.\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f7bf0b",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00bfe160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4653 entries, 0 to 4652\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   Education                  4653 non-null   object\n",
      " 1   JoiningYear                4653 non-null   int64 \n",
      " 2   City                       4653 non-null   object\n",
      " 3   PaymentTier                4653 non-null   int64 \n",
      " 4   Age                        4653 non-null   int64 \n",
      " 5   Gender                     4653 non-null   object\n",
      " 6   EverBenched                4653 non-null   object\n",
      " 7   ExperienceInCurrentDomain  4653 non-null   int64 \n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 290.9+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99bf5972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2017</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2014</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2017</td>\n",
       "      <td>Pune</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n",
       "0  Bachelors         2017  Bangalore            3   34    Male          No   \n",
       "1  Bachelors         2013       Pune            1   28  Female          No   \n",
       "2  Bachelors         2014  New Delhi            3   38  Female          No   \n",
       "3    Masters         2016  Bangalore            3   27    Male          No   \n",
       "4    Masters         2017       Pune            3   24    Male         Yes   \n",
       "\n",
       "   ExperienceInCurrentDomain  \n",
       "0                          0  \n",
       "1                          3  \n",
       "2                          2  \n",
       "3                          5  \n",
       "4                          2  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수 전처리\n",
    "# 일괄적으로 인코딩을 진행하겠습니다.\n",
    "\n",
    "cat_cols = [\n",
    "    'Education',\n",
    "    'City',\n",
    "    'Gender',\n",
    "    'EverBenched'\n",
    "]\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # 각 범주형 변수(col)에 대해 인코딩을 수행합니다.\n",
    "    X[col] = le.fit(X[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af3844cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6379985",
   "metadata": {},
   "source": [
    "#### 훈련용 / 테스트용 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3171db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_scaled와 y를 훈련용과 테스트용 데이터로 분할합니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled,\n",
    "    y, \n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3240612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3489, 8)\n",
      "(3489,)\n",
      "(1164, 8)\n",
      "(1164,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d28ce",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9aab5",
   "metadata": {},
   "source": [
    "주어진 데이터셋에 대해 단일 모델과 앙상블 기법을 각각 적용해보고 결과를 비교해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184edc81",
   "metadata": {},
   "source": [
    "### 단일 모델 적용\n",
    "\n",
    "앙상블 기법을 적용하기 전에, 이전에 배웠던 단일 분류 모델들을 적용해봅시다!\n",
    "\n",
    "(분류 기초 세션 복습 🤓)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45aede8",
   "metadata": {},
   "source": [
    "#### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e43b59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 불러와 훈련시킵니다.\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40a1ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 통해 예측을 수행합니다.\n",
    "y_lr_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fca08d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.7242268041237113\n",
      "Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.89      0.81       775\n",
      "           1       0.64      0.40      0.49       389\n",
      "\n",
      "    accuracy                           0.72      1164\n",
      "   macro avg       0.69      0.64      0.65      1164\n",
      "weighted avg       0.71      0.72      0.70      1164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 계산된 예측값에 대해 정확도를 계산합니다.\n",
    "lr_accuracy = accuracy_score(y_test, y_lr_pred)\n",
    "lr_report = classification_report(y_test, y_lr_pred)\n",
    "\n",
    "print(f\"Accuracy score : {lr_accuracy}\")\n",
    "print(f\"Report :\\n{lr_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d024eb45",
   "metadata": {},
   "source": [
    "#### 2. 의사결정나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2df359ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=SEED)\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f4d31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tree_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f264053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8359106529209622\n",
      "Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       775\n",
      "           1       0.78      0.71      0.74       389\n",
      "\n",
      "    accuracy                           0.84      1164\n",
      "   macro avg       0.82      0.81      0.81      1164\n",
      "weighted avg       0.83      0.84      0.83      1164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_accuracy = accuracy_score(y_test, y_tree_pred)\n",
    "tree_report = classification_report(y_test, y_tree_pred)\n",
    "\n",
    "print(f\"Accuracy score : {tree_accuracy}\")\n",
    "print(f\"Report :\\n{tree_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e05af77",
   "metadata": {},
   "source": [
    "#### 3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12aa8aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(random_state=42)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(random_state=SEED)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ca97791",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_svm_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66673638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8548109965635738\n",
      "Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90       775\n",
      "           1       0.91      0.63      0.74       389\n",
      "\n",
      "    accuracy                           0.85      1164\n",
      "   macro avg       0.87      0.80      0.82      1164\n",
      "weighted avg       0.86      0.85      0.85      1164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_accuracy = accuracy_score(y_test, y_svm_pred)\n",
    "svm_report = classification_report(y_test, y_svm_pred)\n",
    "\n",
    "print(f\"Accuracy score : {svm_accuracy}\")\n",
    "print(f\"Report :\\n{svm_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84783dc",
   "metadata": {},
   "source": [
    "#### 4. kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "401853ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be7558ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_knn_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c82d5a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8298969072164949\n",
      "Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       775\n",
      "           1       0.82      0.63      0.71       389\n",
      "\n",
      "    accuracy                           0.83      1164\n",
      "   macro avg       0.83      0.78      0.80      1164\n",
      "weighted avg       0.83      0.83      0.82      1164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_accuracy = accuracy_score(y_test, y_knn_pred)\n",
    "knn_report = classification_report(y_test, y_knn_pred)\n",
    "\n",
    "print(f\"Accuracy score : {knn_accuracy}\")\n",
    "print(f\"Report :\\n{knn_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ea81d0",
   "metadata": {},
   "source": [
    "#### 네 가지 단일 모델의 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2df9432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = ['Logistic Regression', 'Decision Tree', 'SVM', 'kNN']\n",
    "accuracy_scores = [lr_accuracy, tree_accuracy, svm_accuracy, knn_accuracy]\n",
    "\n",
    "plt.figure(figsize=(15, 2.5))\n",
    "bars = plt.barh(model_name[::-1], accuracy_scores[::-1])\n",
    "\n",
    "for bar, accuracy in zip(bars, accuracy_scores[::-1]):\n",
    "    plt.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height() / 2, f'{accuracy:.4f}', va='center')\n",
    "\n",
    "plt.title(\"Classifier Accuracy Score\")\n",
    "plt.xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a01c163",
   "metadata": {},
   "source": [
    "## 앙상블 (Ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d5f72",
   "metadata": {},
   "source": [
    "### 1. Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe07c11d",
   "metadata": {},
   "source": [
    "`VotingClassifier`\n",
    "\n",
    "- **estimators**: 사용할 기본 분류기 리스트 (이름, 모델) 형태로 지정\n",
    "- **voting**: 'hard' 또는 'soft' (기본값: 'hard')\n",
    "- **weights**: 각 분류기별 가중치\n",
    "- **n_jobs**: 병렬 처리 수\n",
    "\n",
    "[Docs](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e7fa1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimators 인자로 들어갈 분류기 리스트를 지정합니다.\n",
    "models = [\n",
    "    ('lr', LogisticRegression(random_state=SEED)), \n",
    "    ('dt', DecisionTreeClassifier(random_state=SEED)),\n",
    "    ('rf', RandomForestClassifier(random_state=SEED))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aacf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Accuracy: 0.8505\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "# estimators는 models로, voting은 'hard'로 설정합니다.\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators= models, \n",
    "    voting= 'hard'\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_voting_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# 정확도 출력\n",
    "print(f\"Voting Accuracy: {accuracy_score(y_test, y_voting_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af2965d",
   "metadata": {},
   "source": [
    "### 2. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea9ab5",
   "metadata": {},
   "source": [
    "`RandomForestClassifier`\n",
    "\n",
    "- **n_estimators**: 트리 개수\n",
    "- **max_depth**: 트리 최대 깊이\n",
    "- **max_features**: 노드 분할 시 고려할 특성 수\n",
    "- **min_samples_split**: 노드 분할에 필요한 최소 샘플 수\n",
    "- **bootstrap**: 부트스트랩 여부 (기본값: True)\n",
    "\n",
    "[Docs](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8828bf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging (Random Forest) Accuracy: 0.8540\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "rf_clf = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "# 모델 훈련\n",
    "rf_clf.fit(X_train, y_train) \n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_rf_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# 정확도 출력\n",
    "print(f\"Bagging (Random Forest) Accuracy: {accuracy_score(y_test, y_rf_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae33967",
   "metadata": {},
   "source": [
    "### 3. Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc5f1c4",
   "metadata": {},
   "source": [
    "#### 3.1 AdaBoost\n",
    "\n",
    "`AdaBoostClassifier`\n",
    "\n",
    "- **estimator**: 기본 약한 학습기\n",
    "- **n_estimators**: 학습기 개수\n",
    "- **learning_rate**: 학습률\n",
    "\n",
    "[Docs](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f3c534c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.8239\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "adaboost = AdaBoostClassifier(random_state=SEED)\n",
    "\n",
    "# 모델 훈련\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_ada_pred = adaboost.predict(X_test)\n",
    "\n",
    "# 정확도 출력\n",
    "print(f\"AdaBoost Accuracy: {accuracy_score(y_test, y_ada_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234ec831",
   "metadata": {},
   "source": [
    "#### 3.2 GBM\n",
    "\n",
    "`GradientBoostingClassifier`\n",
    "\n",
    "- **n_estimators**: 부스팅 단계 수\n",
    "- **learning_rate**: 각 단계의 기여도\n",
    "- **max_depth**: 개별 트리의 최대 깊이\n",
    "- **subsample**: 학습 데이터 샘플 비율\n",
    "- **min_samples_split**: 노드 분할 최소 샘플 수\n",
    "- **loss**: 손실 함수 ('log_loss', 'exponential')\n",
    "\n",
    "[Docs](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10f7afdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM Accuracy: 0.8660\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "gbm = GradientBoostingClassifier(random_state=SEED)\n",
    "\n",
    "# 모델 훈련\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_gbm_pred = gbm.predict(X_test)\n",
    "\n",
    "# 정확도 출력\n",
    "print(f\"GBM Accuracy: {accuracy_score(y_test, y_gbm_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f609ec2",
   "metadata": {},
   "source": [
    "#### 3.3 XGBoost\n",
    "\n",
    "`XGBClassifier`\n",
    "\n",
    "- **n_estimators**: 부스팅 반복 횟수\n",
    "- **learning_rate**: 학습률\n",
    "- **max_depth**: 트리 깊이\n",
    "- **subsample**: 샘플 비율\n",
    "- **colsample_bytree**: 트리당 특성 샘플 비율\n",
    "- **gamma**: 분할 최소 손실 감소\n",
    "- **objective**: 목적 함수 ('multi:softprob', 'binary:logistic' 등)\n",
    "- **eval_metric**: 평가 지표 ('mlogloss', 'logloss', 'error' 등)\n",
    "\n",
    "[Docs](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88449e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8608\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "xgboost = xgb.XGBClassifier(random_state=SEED)\n",
    "\n",
    "# 모델 훈련\n",
    "xgboost.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_xgb_pred = xgboost.predict(X_test)\n",
    "\n",
    "# 정확도 출력\n",
    "print(f\"XGBoost Accuracy: {accuracy_score(y_test, y_xgb_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12baf03e",
   "metadata": {},
   "source": [
    "#### 3.4 LightGBM\n",
    "\n",
    "`LGBMClassifier`\n",
    "\n",
    "- **n_estimators**: 트리 개수\n",
    "- **learning_rate**: 학습률\n",
    "- **max_depth**: 최대 깊이 (기본: -1 → 제한 없음)\n",
    "- **num_leaves**: 리프 노드 수\n",
    "- **subsample**: 데이터 샘플 비율\n",
    "- **colsample_bytree**: 트리당 특성 샘플 비율\n",
    "- **min_child_samples**: 리프 노드의 최소 샘플 수\n",
    "- **objective**: 'binary', 'multiclass' 등\n",
    "\n",
    "[Docs](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab685010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-56 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\owner\\anaconda3\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\owner\\anaconda3\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\owner\\anaconda3\\Lib\\subprocess.py\", line 1597, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"<frozen codecs>\", line 322, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc1 in position 24: invalid start byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Accuracy: 0.8582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"c:\\Users\\owner\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 202, in _count_physical_cores\n",
      "    cpu_info = cpu_info.stdout.splitlines()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성 (LGBMClassifier)\n",
    "lgbm = lgb.LGBMClassifier(random_state=SEED, verbose=-1)\n",
    "\n",
    "# 모델 훈련\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_lgbm_pred = lgbm.predict(X_test)\n",
    "\n",
    "# 정확도 출력\n",
    "print(f\"LightGBM Accuracy: {accuracy_score(y_test, y_lgbm_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40babf6",
   "metadata": {},
   "source": [
    "#### 3.5 CatBoost\n",
    "\n",
    "`CatBoostClassifier`\n",
    "\n",
    "- **iterations**: 부스팅 반복 횟수\n",
    "- **learning_rate**: 학습률\n",
    "- **depth**: 트리 깊이\n",
    "- **l2_leaf_reg**: L2 정규화 계수\n",
    "- **loss_function**: 손실 함수 (예: 'Logloss', 'MultiClass')\n",
    "- **random_state**: 랜덤 시드\n",
    "- **verbose**: 출력 제어 (0: 진행 메시지 표시하지 않음, 100: 진행률 표시)\n",
    "\n",
    "[Docs](https://catboost.ai/en/docs/concepts/python-reference_catboostclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0bfd22e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Accuracy: 0.8600\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "cb = CatBoostClassifier(random_state=SEED, depth=10, verbose=0)\n",
    "\n",
    "# 모델 훈련\n",
    "cb.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_cb_pred = cb.predict(X_test)\n",
    "\n",
    "# 정확도 출력\n",
    "print(f\"CatBoost Accuracy: {accuracy_score(y_test, y_cb_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d59c855",
   "metadata": {},
   "source": [
    "### 4. Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e9c2e2",
   "metadata": {},
   "source": [
    "`StackingClassifier`\n",
    "\n",
    "- **estimators**: 기본 모델 목록 (이름, 모델) 쌍의 리스트\n",
    "- **final_estimator**: 최종 분류기 (기본값: LogisticRegression)\n",
    "- **cv**: 교차 검증 폴드 수 (기본값: 5)\n",
    "- **passthrough**: 원본 특성을 메타 모델에 전달 여부 (기본값: False)\n",
    "- **n_jobs**: 병렬 처리 수\n",
    "\n",
    "[Docs](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81b7b01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Accuracy: 0.8565\n"
     ]
    }
   ],
   "source": [
    "base_learners = [\n",
    "    ('lr', LogisticRegression(random_state=SEED)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=SEED)),\n",
    "    ('rf', RandomForestClassifier(random_state=SEED))\n",
    "]\n",
    "\n",
    "stack_clf = StackingClassifier(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=LogisticRegression(random_state=SEED), # 최종 분류기를 LogisticRegression(random_state=SEED) 로 지정해주세요\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "stack_clf.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_stk_pred = stack_clf.predict(X_test)\n",
    "\n",
    "# 정확도 출력\n",
    "print(f\"Stacking Accuracy: {accuracy_score(y_test, y_stk_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699012ff",
   "metadata": {},
   "source": [
    "## [과제] 모델 성능을 높여봅시다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8bb03e",
   "metadata": {},
   "source": [
    "이제 직접 다른 전처리 기법, 피쳐 엔지니어링, 앙상블 기법, 추가 하이퍼파라미터 튜닝 등등.. 을 수행해서 더 높은 정확도를 가지는 모델을 만들어보세요.\\\n",
    "다양한 방법을 수행해보고, 비교한 후 결과를 정리해서 마크다운으로 남겨주시면 되겠습니다! 이때 각 단계별로 어떤 방법을 수행했는지에 대한 설명을 꼭 달아주세요.\n",
    "\n",
    "- 정확도는 소수점 자릿수 제한 없이 모두 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3bbf16f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2017</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2014</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2017</td>\n",
       "      <td>Pune</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n",
       "0  Bachelors         2017  Bangalore            3   34    Male          No   \n",
       "1  Bachelors         2013       Pune            1   28  Female          No   \n",
       "2  Bachelors         2014  New Delhi            3   38  Female          No   \n",
       "3    Masters         2016  Bangalore            3   27    Male          No   \n",
       "4    Masters         2017       Pune            3   24    Male         Yes   \n",
       "\n",
       "   ExperienceInCurrentDomain  LeaveOrNot  \n",
       "0                          0           0  \n",
       "1                          3           1  \n",
       "2                          2           0  \n",
       "3                          5           1  \n",
       "4                          2           1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Employee.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de38df61",
   "metadata": {},
   "source": [
    "Target 변수는 'LeaveOrNot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10803506",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'LeaveOrNot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f508983",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = target, axis = 1) # target 컬럼을 제외한 데이터를 X에 저장합니다.\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9460b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수 전처리\n",
    "# 일괄적으로 인코딩을 진행하겠습니다.\n",
    "\n",
    "cat_cols = [\n",
    "    'Education',\n",
    "    'City',\n",
    "    'Gender',\n",
    "    'EverBenched'\n",
    "]\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # 각 범주형 변수(col)에 대해 인코딩을 수행합니다.\n",
    "    X[col] = le.fit_transform(X[col].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df867420",
   "metadata": {},
   "source": [
    "StandardScaler 대신 MinMaxScaler 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b6646a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1735be56",
   "metadata": {},
   "source": [
    "훈련용, 테스트용 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8c009900",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd348945",
   "metadata": {},
   "source": [
    "Voting 모델 다양화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "28932540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Accuracy: 0.8754\n"
     ]
    }
   ],
   "source": [
    "# estimators 인자로 들어갈 분류기 리스트를 지정합니다.\n",
    "models = [\n",
    "    ('lr', LogisticRegression(random_state=SEED)), \n",
    "    ('rf', RandomForestClassifier(random_state=SEED)),\n",
    "    ('xgboost', xgb.XGBClassifier(random_state=SEED)),\n",
    "    ('lgbm', lgb.LGBMClassifier(random_state=SEED, verbose=-1)),\n",
    "    ('catboost', CatBoostClassifier(random_state=SEED, depth=10, verbose=0)),\n",
    "    ('svm', SVC(random_state=SEED, probability=True)), # SVC 모델에 probability=True 추가\n",
    "    ('gbm', GradientBoostingClassifier(random_state=SEED)),\n",
    "]\n",
    "\n",
    "# 모델 생성\n",
    "# estimators는 models로, voting은 'hard'로 설정합니다.\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators= models, \n",
    "    voting= 'soft' # soft voting으로 변경합니다.\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_voting_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# 정확도 출력\n",
    "print(f\"Voting Accuracy: {accuracy_score(y_test, y_voting_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0af2d67",
   "metadata": {},
   "source": [
    "트리 기반 모델만 사용하는 경우 스케일링 적용 안 하는 것이 좋을 수도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "67872a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed90b75",
   "metadata": {},
   "source": [
    "개별 모델 최적화 (GridSearchCV, optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "68fbe736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 16:45:31,556] A new study created in memory with name: no-name-112de434-9d7f-4544-8dec-2fde5c8aa26c\n",
      "[I 2025-05-06 16:45:32,122] Trial 0 finished with value: 0.8303239836713218 and parameters: {'n_estimators': 376, 'learning_rate': 0.005468998853709292, 'max_depth': 4, 'num_leaves': 126, 'min_child_samples': 17}. Best is trial 0 with value: 0.8303239836713218.\n",
      "[I 2025-05-06 16:45:33,098] Trial 1 finished with value: 0.8360554648863529 and parameters: {'n_estimators': 182, 'learning_rate': 0.04660867381463824, 'max_depth': 9, 'num_leaves': 92, 'min_child_samples': 29}. Best is trial 1 with value: 0.8360554648863529.\n",
      "[I 2025-05-06 16:45:34,515] Trial 2 finished with value: 0.8334758461355051 and parameters: {'n_estimators': 871, 'learning_rate': 0.027387481116709262, 'max_depth': 4, 'num_leaves': 76, 'min_child_samples': 5}. Best is trial 1 with value: 0.8360554648863529.\n",
      "[I 2025-05-06 16:45:37,738] Trial 3 finished with value: 0.8134123731259224 and parameters: {'n_estimators': 797, 'learning_rate': 0.050067125138752645, 'max_depth': 8, 'num_leaves': 148, 'min_child_samples': 19}. Best is trial 1 with value: 0.8360554648863529.\n",
      "[I 2025-05-06 16:45:40,267] Trial 4 finished with value: 0.8096878558537819 and parameters: {'n_estimators': 440, 'learning_rate': 0.12507122040605712, 'max_depth': 11, 'num_leaves': 55, 'min_child_samples': 8}. Best is trial 1 with value: 0.8360554648863529.\n",
      "[I 2025-05-06 16:45:45,405] Trial 5 finished with value: 0.8194324427653514 and parameters: {'n_estimators': 704, 'learning_rate': 0.023170652626222595, 'max_depth': 15, 'num_leaves': 122, 'min_child_samples': 22}. Best is trial 1 with value: 0.8360554648863529.\n",
      "[I 2025-05-06 16:45:46,178] Trial 6 finished with value: 0.8403534591556939 and parameters: {'n_estimators': 216, 'learning_rate': 0.005229551685654398, 'max_depth': 9, 'num_leaves': 30, 'min_child_samples': 15}. Best is trial 6 with value: 0.8403534591556939.\n",
      "[I 2025-05-06 16:45:46,853] Trial 7 finished with value: 0.8243039140318927 and parameters: {'n_estimators': 135, 'learning_rate': 0.1171721995035654, 'max_depth': 15, 'num_leaves': 48, 'min_child_samples': 11}. Best is trial 6 with value: 0.8403534591556939.\n",
      "[I 2025-05-06 16:45:48,384] Trial 8 finished with value: 0.8102580440940091 and parameters: {'n_estimators': 803, 'learning_rate': 0.1281970421245487, 'max_depth': 5, 'num_leaves': 89, 'min_child_samples': 26}. Best is trial 6 with value: 0.8403534591556939.\n",
      "[I 2025-05-06 16:45:49,966] Trial 9 finished with value: 0.8380599622615137 and parameters: {'n_estimators': 258, 'learning_rate': 0.0228205236709946, 'max_depth': 10, 'num_leaves': 126, 'min_child_samples': 23}. Best is trial 6 with value: 0.8403534591556939.\n",
      "[I 2025-05-06 16:45:51,872] Trial 10 finished with value: 0.8446539199927645 and parameters: {'n_estimators': 618, 'learning_rate': 0.005225219756637173, 'max_depth': 12, 'num_leaves': 27, 'min_child_samples': 14}. Best is trial 10 with value: 0.8446539199927645.\n",
      "[I 2025-05-06 16:45:53,626] Trial 11 finished with value: 0.8455143410358762 and parameters: {'n_estimators': 612, 'learning_rate': 0.005413490691094665, 'max_depth': 12, 'num_leaves': 24, 'min_child_samples': 14}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:45:55,252] Trial 12 finished with value: 0.8426473671444956 and parameters: {'n_estimators': 588, 'learning_rate': 0.010525783489113946, 'max_depth': 12, 'num_leaves': 20, 'min_child_samples': 12}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:45:57,732] Trial 13 finished with value: 0.8386317948802275 and parameters: {'n_estimators': 589, 'learning_rate': 0.011169125324137644, 'max_depth': 13, 'num_leaves': 41, 'min_child_samples': 13}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:02,860] Trial 14 finished with value: 0.8300362174361673 and parameters: {'n_estimators': 991, 'learning_rate': 0.009982595606933984, 'max_depth': 13, 'num_leaves': 55, 'min_child_samples': 18}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:04,517] Trial 15 finished with value: 0.8048143291141322 and parameters: {'n_estimators': 476, 'learning_rate': 0.2700497878171052, 'max_depth': 6, 'num_leaves': 73, 'min_child_samples': 9}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:06,225] Trial 16 finished with value: 0.8440800319009426 and parameters: {'n_estimators': 633, 'learning_rate': 0.007740978695585286, 'max_depth': 13, 'num_leaves': 20, 'min_child_samples': 15}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:08,421] Trial 17 finished with value: 0.8377742514994677 and parameters: {'n_estimators': 705, 'learning_rate': 0.015468248556854074, 'max_depth': 7, 'num_leaves': 38, 'min_child_samples': 20}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:10,843] Trial 18 finished with value: 0.8440792097116994 and parameters: {'n_estimators': 327, 'learning_rate': 0.005116773522404619, 'max_depth': 11, 'num_leaves': 68, 'min_child_samples': 5}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:12,692] Trial 19 finished with value: 0.8386334392587141 and parameters: {'n_estimators': 497, 'learning_rate': 0.01397938860979755, 'max_depth': 14, 'num_leaves': 32, 'min_child_samples': 15}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:18,739] Trial 20 finished with value: 0.8085404907647593 and parameters: {'n_estimators': 682, 'learning_rate': 0.07084690094714886, 'max_depth': 11, 'num_leaves': 103, 'min_child_samples': 9}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:20,421] Trial 21 finished with value: 0.8429334890011635 and parameters: {'n_estimators': 623, 'learning_rate': 0.007479137066503773, 'max_depth': 13, 'num_leaves': 21, 'min_child_samples': 15}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:21,698] Trial 22 finished with value: 0.8440804429955643 and parameters: {'n_estimators': 525, 'learning_rate': 0.007907108979496376, 'max_depth': 12, 'num_leaves': 21, 'min_child_samples': 13}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:24,676] Trial 23 finished with value: 0.8406404032016048 and parameters: {'n_estimators': 503, 'learning_rate': 0.007405408907336683, 'max_depth': 10, 'num_leaves': 60, 'min_child_samples': 11}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:26,531] Trial 24 finished with value: 0.8386317948802275 and parameters: {'n_estimators': 394, 'learning_rate': 0.0172784212215429, 'max_depth': 12, 'num_leaves': 43, 'min_child_samples': 13}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:28,548] Trial 25 finished with value: 0.8409277583421375 and parameters: {'n_estimators': 543, 'learning_rate': 0.007842266904592046, 'max_depth': 12, 'num_leaves': 34, 'min_child_samples': 17}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:30,959] Trial 26 finished with value: 0.8406408142962267 and parameters: {'n_estimators': 771, 'learning_rate': 0.006926152787693439, 'max_depth': 14, 'num_leaves': 27, 'min_child_samples': 7}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:35,229] Trial 27 finished with value: 0.8303202838197269 and parameters: {'n_estimators': 887, 'learning_rate': 0.010849384002395476, 'max_depth': 10, 'num_leaves': 50, 'min_child_samples': 10}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:38,713] Trial 28 finished with value: 0.8423616563824495 and parameters: {'n_estimators': 545, 'learning_rate': 0.005217985417837083, 'max_depth': 14, 'num_leaves': 65, 'min_child_samples': 21}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:41,366] Trial 29 finished with value: 0.8400677483936476 and parameters: {'n_estimators': 371, 'learning_rate': 0.006745788737722692, 'max_depth': 9, 'num_leaves': 101, 'min_child_samples': 17}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:41,783] Trial 30 finished with value: 0.8400665151097828 and parameters: {'n_estimators': 421, 'learning_rate': 0.03130096724632692, 'max_depth': 3, 'num_leaves': 28, 'min_child_samples': 16}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:43,660] Trial 31 finished with value: 0.84293266681192 and parameters: {'n_estimators': 645, 'learning_rate': 0.009515872275142114, 'max_depth': 12, 'num_leaves': 24, 'min_child_samples': 13}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:46,298] Trial 32 finished with value: 0.8389203833046253 and parameters: {'n_estimators': 651, 'learning_rate': 0.006404373197452843, 'max_depth': 13, 'num_leaves': 38, 'min_child_samples': 14}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:48,210] Trial 33 finished with value: 0.8386350836372009 and parameters: {'n_estimators': 736, 'learning_rate': 0.013818843150926227, 'max_depth': 11, 'num_leaves': 20, 'min_child_samples': 18}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:50,780] Trial 34 finished with value: 0.8397808043477367 and parameters: {'n_estimators': 558, 'learning_rate': 0.0087100223560186, 'max_depth': 14, 'num_leaves': 44, 'min_child_samples': 12}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:46:52,872] Trial 35 finished with value: 0.8329011358544396 and parameters: {'n_estimators': 610, 'learning_rate': 0.018093955117181905, 'max_depth': 12, 'num_leaves': 34, 'min_child_samples': 16}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:47:00,097] Trial 36 finished with value: 0.8265982331153161 and parameters: {'n_estimators': 834, 'learning_rate': 0.012441879666964766, 'max_depth': 15, 'num_leaves': 141, 'min_child_samples': 19}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:47:02,373] Trial 37 finished with value: 0.8435086103768503 and parameters: {'n_estimators': 749, 'learning_rate': 0.005737228078646795, 'max_depth': 8, 'num_leaves': 28, 'min_child_samples': 24}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:47:04,755] Trial 38 finished with value: 0.8168528240145034 and parameters: {'n_estimators': 460, 'learning_rate': 0.05040596151388048, 'max_depth': 10, 'num_leaves': 50, 'min_child_samples': 14}. Best is trial 11 with value: 0.8455143410358762.\n",
      "[I 2025-05-06 16:47:05,979] Trial 39 finished with value: 0.8463727066058795 and parameters: {'n_estimators': 326, 'learning_rate': 0.008665156965562705, 'max_depth': 13, 'num_leaves': 35, 'min_child_samples': 7}. Best is trial 39 with value: 0.8463727066058795.\n",
      "[I 2025-05-06 16:47:09,138] Trial 40 finished with value: 0.8409265250582727 and parameters: {'n_estimators': 321, 'learning_rate': 0.005029762323933646, 'max_depth': 9, 'num_leaves': 115, 'min_child_samples': 7}. Best is trial 39 with value: 0.8463727066058795.\n",
      "[I 2025-05-06 16:47:14,551] Trial 41 finished with value: 0.8317541818600388 and parameters: {'n_estimators': 681, 'learning_rate': 0.008711972318390456, 'max_depth': 13, 'num_leaves': 80, 'min_child_samples': 11}. Best is trial 39 with value: 0.8463727066058795.\n",
      "[I 2025-05-06 16:47:15,503] Trial 42 finished with value: 0.8403530480610722 and parameters: {'n_estimators': 245, 'learning_rate': 0.006299377219129752, 'max_depth': 11, 'num_leaves': 32, 'min_child_samples': 29}. Best is trial 39 with value: 0.8463727066058795.\n",
      "[I 2025-05-06 16:47:16,981] Trial 43 finished with value: 0.842933900095785 and parameters: {'n_estimators': 525, 'learning_rate': 0.008656772714190466, 'max_depth': 14, 'num_leaves': 25, 'min_child_samples': 6}. Best is trial 39 with value: 0.8463727066058795.\n",
      "[I 2025-05-06 16:47:17,819] Trial 44 finished with value: 0.8417857128175192 and parameters: {'n_estimators': 192, 'learning_rate': 0.021765977035199304, 'max_depth': 12, 'num_leaves': 37, 'min_child_samples': 9}. Best is trial 39 with value: 0.8463727066058795.\n",
      "[I 2025-05-06 16:47:18,184] Trial 45 finished with value: 0.8237320814131788 and parameters: {'n_estimators': 121, 'learning_rate': 0.006079683677982988, 'max_depth': 15, 'num_leaves': 21, 'min_child_samples': 16}. Best is trial 39 with value: 0.8463727066058795.\n",
      "[I 2025-05-06 16:47:21,520] Trial 46 finished with value: 0.8360525872240012 and parameters: {'n_estimators': 587, 'learning_rate': 0.011515645792095058, 'max_depth': 13, 'num_leaves': 45, 'min_child_samples': 14}. Best is trial 39 with value: 0.8463727066058795.\n",
      "[I 2025-05-06 16:47:22,611] Trial 47 finished with value: 0.843219610857831 and parameters: {'n_estimators': 299, 'learning_rate': 0.00773910606172393, 'max_depth': 13, 'num_leaves': 29, 'min_child_samples': 12}. Best is trial 39 with value: 0.8463727066058795.\n",
      "[I 2025-05-06 16:47:26,870] Trial 48 finished with value: 0.8340460343757321 and parameters: {'n_estimators': 714, 'learning_rate': 0.009607712114099366, 'max_depth': 11, 'num_leaves': 58, 'min_child_samples': 10}. Best is trial 39 with value: 0.8463727066058795.\n",
      "[I 2025-05-06 16:47:29,390] Trial 49 finished with value: 0.821151229378466 and parameters: {'n_estimators': 655, 'learning_rate': 0.03875832817807204, 'max_depth': 12, 'num_leaves': 38, 'min_child_samples': 19}. Best is trial 39 with value: 0.8463727066058795.\n",
      "[I 2025-05-06 16:47:29,788] A new study created in memory with name: no-name-097883da-91b5-405e-a9b7-5a2c870fbd4f\n",
      "[I 2025-05-06 16:47:30,248] Trial 0 finished with value: 0.8349097441758169 and parameters: {'n_estimators': 651, 'learning_rate': 0.02958459449865753, 'max_depth': 6, 'subsample': 0.5435951396228513, 'colsample_bytree': 0.6779907881030275}. Best is trial 0 with value: 0.8349097441758169.\n",
      "[I 2025-05-06 16:47:31,196] Trial 1 finished with value: 0.8389212054938685 and parameters: {'n_estimators': 888, 'learning_rate': 0.006638519461174915, 'max_depth': 14, 'subsample': 0.6369300409939695, 'colsample_bytree': 0.8141640891922566}. Best is trial 1 with value: 0.8389212054938685.\n",
      "[I 2025-05-06 16:47:31,317] Trial 2 finished with value: 0.8202928638084629 and parameters: {'n_estimators': 119, 'learning_rate': 0.18702222397257323, 'max_depth': 9, 'subsample': 0.6105870784306625, 'colsample_bytree': 0.9876766116571642}. Best is trial 1 with value: 0.8389212054938685.\n",
      "[I 2025-05-06 16:47:31,710] Trial 3 finished with value: 0.8271696546394084 and parameters: {'n_estimators': 465, 'learning_rate': 0.005254800639632603, 'max_depth': 14, 'subsample': 0.6356451913467465, 'colsample_bytree': 0.5446990361201978}. Best is trial 1 with value: 0.8389212054938685.\n",
      "[I 2025-05-06 16:47:31,963] Trial 4 finished with value: 0.8323297143303474 and parameters: {'n_estimators': 375, 'learning_rate': 0.008579665719045138, 'max_depth': 7, 'subsample': 0.8185548556502062, 'colsample_bytree': 0.6181966083184862}. Best is trial 1 with value: 0.8389212054938685.\n",
      "[I 2025-05-06 16:47:32,352] Trial 5 finished with value: 0.8125515409881892 and parameters: {'n_estimators': 387, 'learning_rate': 0.09895286441557088, 'max_depth': 12, 'subsample': 0.8542209455387153, 'colsample_bytree': 0.6540582214512491}. Best is trial 1 with value: 0.8389212054938685.\n",
      "[I 2025-05-06 16:47:32,453] Trial 6 finished with value: 0.8392081495397795 and parameters: {'n_estimators': 168, 'learning_rate': 0.09959010509221529, 'max_depth': 4, 'subsample': 0.7702216781507978, 'colsample_bytree': 0.6667843890021989}. Best is trial 6 with value: 0.8392081495397795.\n",
      "[I 2025-05-06 16:47:32,546] Trial 7 finished with value: 0.8417881793852491 and parameters: {'n_estimators': 137, 'learning_rate': 0.11111296561322796, 'max_depth': 5, 'subsample': 0.9798245680865418, 'colsample_bytree': 0.5438193631868685}. Best is trial 7 with value: 0.8417881793852491.\n",
      "[I 2025-05-06 16:47:32,883] Trial 8 finished with value: 0.8311827603359465 and parameters: {'n_estimators': 410, 'learning_rate': 0.03048222957961388, 'max_depth': 10, 'subsample': 0.8152221477570074, 'colsample_bytree': 0.6039868837694762}. Best is trial 7 with value: 0.8417881793852491.\n",
      "[I 2025-05-06 16:47:33,312] Trial 9 finished with value: 0.8082535467188482 and parameters: {'n_estimators': 488, 'learning_rate': 0.15155141215836923, 'max_depth': 13, 'subsample': 0.9565764689501488, 'colsample_bytree': 0.7199333045789733}. Best is trial 7 with value: 0.8417881793852491.\n",
      "[I 2025-05-06 16:47:33,596] Trial 10 finished with value: 0.8263071781231887 and parameters: {'n_estimators': 710, 'learning_rate': 0.2897058524838208, 'max_depth': 3, 'subsample': 0.997551339266442, 'colsample_bytree': 0.5059210903290942}. Best is trial 7 with value: 0.8417881793852491.\n",
      "[I 2025-05-06 16:47:33,674] Trial 11 finished with value: 0.8263117001640268 and parameters: {'n_estimators': 113, 'learning_rate': 0.06874139101381213, 'max_depth': 3, 'subsample': 0.7282636376656275, 'colsample_bytree': 0.8079147191459098}. Best is trial 7 with value: 0.8417881793852491.\n",
      "[I 2025-05-06 16:47:33,824] Trial 12 finished with value: 0.8415016464339595 and parameters: {'n_estimators': 243, 'learning_rate': 0.05645216601889759, 'max_depth': 5, 'subsample': 0.9099062763603626, 'colsample_bytree': 0.5701921361041365}. Best is trial 7 with value: 0.8417881793852491.\n",
      "[I 2025-05-06 16:47:34,029] Trial 13 finished with value: 0.8386346725425792 and parameters: {'n_estimators': 301, 'learning_rate': 0.05250584241082055, 'max_depth': 6, 'subsample': 0.9163881949233015, 'colsample_bytree': 0.5649191942987386}. Best is trial 7 with value: 0.8417881793852491.\n",
      "[I 2025-05-06 16:47:34,188] Trial 14 finished with value: 0.8449408640386759 and parameters: {'n_estimators': 260, 'learning_rate': 0.01614636128784384, 'max_depth': 5, 'subsample': 0.8951344326103776, 'colsample_bytree': 0.7728264295379326}. Best is trial 14 with value: 0.8449408640386759.\n",
      "[I 2025-05-06 16:47:34,417] Trial 15 finished with value: 0.8397795710638718 and parameters: {'n_estimators': 248, 'learning_rate': 0.014981513380591954, 'max_depth': 8, 'subsample': 0.9985841813019672, 'colsample_bytree': 0.8650377177382473}. Best is trial 14 with value: 0.8449408640386759.\n",
      "[I 2025-05-06 16:47:35,036] Trial 16 finished with value: 0.8260227006450075 and parameters: {'n_estimators': 610, 'learning_rate': 0.015569226692178454, 'max_depth': 11, 'subsample': 0.8826448259076843, 'colsample_bytree': 0.9186555442804389}. Best is trial 14 with value: 0.8449408640386759.\n",
      "[I 2025-05-06 16:47:35,519] Trial 17 finished with value: 0.8397824487262232 and parameters: {'n_estimators': 966, 'learning_rate': 0.01639217755863626, 'max_depth': 5, 'subsample': 0.948312739608907, 'colsample_bytree': 0.7580163672771691}. Best is trial 14 with value: 0.8449408640386759.\n",
      "[I 2025-05-06 16:47:35,729] Trial 18 finished with value: 0.8414991798662298 and parameters: {'n_estimators': 227, 'learning_rate': 0.0247920417715087, 'max_depth': 8, 'subsample': 0.7123570468993209, 'colsample_bytree': 0.7390695684003421}. Best is trial 14 with value: 0.8449408640386759.\n",
      "[I 2025-05-06 16:47:35,925] Trial 19 finished with value: 0.8463739398897443 and parameters: {'n_estimators': 301, 'learning_rate': 0.010551146998799122, 'max_depth': 5, 'subsample': 0.8419916729174367, 'colsample_bytree': 0.7911493940892036}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:36,224] Trial 20 finished with value: 0.8406395810123616 and parameters: {'n_estimators': 328, 'learning_rate': 0.011276817253799896, 'max_depth': 8, 'subsample': 0.7822167178401482, 'colsample_bytree': 0.876866663106088}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:36,352] Trial 21 finished with value: 0.8443677981360971 and parameters: {'n_estimators': 191, 'learning_rate': 0.02332308078396228, 'max_depth': 5, 'subsample': 0.8548265374799675, 'colsample_bytree': 0.7843606967113426}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:36,507] Trial 22 finished with value: 0.8377763069725759 and parameters: {'n_estimators': 279, 'learning_rate': 0.010741113870762384, 'max_depth': 4, 'subsample': 0.8450637792782363, 'colsample_bytree': 0.7994768198009488}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:36,664] Trial 23 finished with value: 0.8412151134826702 and parameters: {'n_estimators': 206, 'learning_rate': 0.020364354778322075, 'max_depth': 6, 'subsample': 0.8887131039135195, 'colsample_bytree': 0.7826971914056475}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:36,842] Trial 24 finished with value: 0.84293513337965 and parameters: {'n_estimators': 338, 'learning_rate': 0.04220245368853229, 'max_depth': 4, 'subsample': 0.8018610405557954, 'colsample_bytree': 0.8580064948265747}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:37,190] Trial 25 finished with value: 0.840354281344937 and parameters: {'n_estimators': 479, 'learning_rate': 0.008517121473434728, 'max_depth': 7, 'subsample': 0.8579041995374649, 'colsample_bytree': 0.7101104694300493}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:37,432] Trial 26 finished with value: 0.8369142415509778 and parameters: {'n_estimators': 555, 'learning_rate': 0.023048012516510032, 'max_depth': 3, 'subsample': 0.7413280359710588, 'colsample_bytree': 0.9029167850200905}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:37,953] Trial 27 finished with value: 0.8394950935856906 and parameters: {'n_estimators': 767, 'learning_rate': 0.012212763547851927, 'max_depth': 7, 'subsample': 0.6929734325905159, 'colsample_bytree': 0.7591022491129102}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:38,071] Trial 28 finished with value: 0.843506965998364 and parameters: {'n_estimators': 167, 'learning_rate': 0.037331062737169164, 'max_depth': 5, 'subsample': 0.9304355031879389, 'colsample_bytree': 0.843231157514708}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:38,349] Trial 29 finished with value: 0.836629352978175 and parameters: {'n_estimators': 440, 'learning_rate': 0.031110457718346706, 'max_depth': 6, 'subsample': 0.888622779447009, 'colsample_bytree': 0.6989580272508468}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:38,553] Trial 30 finished with value: 0.8374864852643134 and parameters: {'n_estimators': 198, 'learning_rate': 0.019138927487149904, 'max_depth': 9, 'subsample': 0.8343255008205642, 'colsample_bytree': 0.9476892620823897}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:38,670] Trial 31 finished with value: 0.8426473671444956 and parameters: {'n_estimators': 167, 'learning_rate': 0.03734606055003373, 'max_depth': 5, 'subsample': 0.9263536346053628, 'colsample_bytree': 0.8333662357288736}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:38,832] Trial 32 finished with value: 0.8383485506859113 and parameters: {'n_estimators': 299, 'learning_rate': 0.008051811491503347, 'max_depth': 4, 'subsample': 0.937661932614389, 'colsample_bytree': 0.840870536635625}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:38,926] Trial 33 finished with value: 0.8423628896663145 and parameters: {'n_estimators': 106, 'learning_rate': 0.027464605193947174, 'max_depth': 6, 'subsample': 0.8707340757388022, 'colsample_bytree': 0.7834108537046021}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:39,046] Trial 34 finished with value: 0.8286047859635852 and parameters: {'n_estimators': 178, 'learning_rate': 0.0057392722379807195, 'max_depth': 5, 'subsample': 0.9003725917889542, 'colsample_bytree': 0.8250748256936873}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:39,420] Trial 35 finished with value: 0.8248769799344714 and parameters: {'n_estimators': 272, 'learning_rate': 0.038175536718756134, 'max_depth': 15, 'subsample': 0.9681874589924933, 'colsample_bytree': 0.7731894063674786}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:39,707] Trial 36 finished with value: 0.8420743012419167 and parameters: {'n_estimators': 387, 'learning_rate': 0.01341154944418483, 'max_depth': 7, 'subsample': 0.5312059706467496, 'colsample_bytree': 0.7371629832487823}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:39,813] Trial 37 finished with value: 0.8019518772635899 and parameters: {'n_estimators': 153, 'learning_rate': 0.007079656411228183, 'max_depth': 4, 'subsample': 0.7846559992435428, 'colsample_bytree': 0.6844932995919066}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:40,066] Trial 38 finished with value: 0.8320448257575446 and parameters: {'n_estimators': 533, 'learning_rate': 0.018568204444496795, 'max_depth': 3, 'subsample': 0.5744444644380191, 'colsample_bytree': 0.9656969746879613}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:40,289] Trial 39 finished with value: 0.8294635626282101 and parameters: {'n_estimators': 319, 'learning_rate': 0.07523386507355903, 'max_depth': 6, 'subsample': 0.8298159357869593, 'colsample_bytree': 0.8080156059910774}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:40,513] Trial 40 finished with value: 0.8403526369664507 and parameters: {'n_estimators': 201, 'learning_rate': 0.010030667430912256, 'max_depth': 10, 'subsample': 0.7623561967015817, 'colsample_bytree': 0.9082430531423765}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:40,692] Trial 41 finished with value: 0.8409281694367593 and parameters: {'n_estimators': 334, 'learning_rate': 0.05120369894796267, 'max_depth': 4, 'subsample': 0.8098262224025675, 'colsample_bytree': 0.859849763538573}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:40,877] Trial 42 finished with value: 0.8403546924395588 and parameters: {'n_estimators': 354, 'learning_rate': 0.04054046283369267, 'max_depth': 4, 'subsample': 0.8088699381375792, 'colsample_bytree': 0.8787893152198781}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:41,033] Trial 43 finished with value: 0.8435077881876071 and parameters: {'n_estimators': 248, 'learning_rate': 0.031297384182904724, 'max_depth': 5, 'subsample': 0.865552920856921, 'colsample_bytree': 0.8545676391523117}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:41,193] Trial 44 finished with value: 0.8449404529440541 and parameters: {'n_estimators': 243, 'learning_rate': 0.022805634095916714, 'max_depth': 5, 'subsample': 0.8646302520194984, 'colsample_bytree': 0.8353164124712935}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:41,540] Trial 45 finished with value: 0.8366285307889317 and parameters: {'n_estimators': 424, 'learning_rate': 0.029947743239018342, 'max_depth': 7, 'subsample': 0.8566256377402369, 'colsample_bytree': 0.7947493900703745}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:41,719] Trial 46 finished with value: 0.8400677483936476 and parameters: {'n_estimators': 255, 'learning_rate': 0.02077792982576289, 'max_depth': 6, 'subsample': 0.6665985330869951, 'colsample_bytree': 0.6433934782173663}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:41,870] Trial 47 finished with value: 0.8374893629266648 and parameters: {'n_estimators': 227, 'learning_rate': 0.013649348612546405, 'max_depth': 5, 'subsample': 0.8684651629955772, 'colsample_bytree': 0.7289069494050421}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:42,056] Trial 48 finished with value: 0.8314705265711009 and parameters: {'n_estimators': 377, 'learning_rate': 0.02572266226928256, 'max_depth': 3, 'subsample': 0.5029817420343354, 'colsample_bytree': 0.8164320633263338}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:42,191] Trial 49 finished with value: 0.8420734790526737 and parameters: {'n_estimators': 128, 'learning_rate': 0.017214841412201306, 'max_depth': 8, 'subsample': 0.834069361749079, 'colsample_bytree': 0.7602998034682891}. Best is trial 19 with value: 0.8463739398897443.\n",
      "[I 2025-05-06 16:47:42,307] A new study created in memory with name: no-name-70cc250b-0db1-4fba-a3cc-59f1fc04ef01\n",
      "[I 2025-05-06 16:47:44,289] Trial 0 finished with value: 0.8415008242447165 and parameters: {'n_estimators': 540, 'learning_rate': 0.011767126163301772, 'depth': 9, 'l2_leaf_reg': 6.900785547298437}. Best is trial 0 with value: 0.8415008242447165.\n",
      "[I 2025-05-06 16:47:45,983] Trial 1 finished with value: 0.8397816265369802 and parameters: {'n_estimators': 724, 'learning_rate': 0.03210440039022023, 'depth': 4, 'l2_leaf_reg': 0.7867736257916643}. Best is trial 0 with value: 0.8415008242447165.\n",
      "[I 2025-05-06 16:47:47,029] Trial 2 finished with value: 0.838348961780533 and parameters: {'n_estimators': 322, 'learning_rate': 0.017247945817031114, 'depth': 6, 'l2_leaf_reg': 0.004862394358461192}. Best is trial 0 with value: 0.8415008242447165.\n",
      "[I 2025-05-06 16:47:48,255] Trial 3 finished with value: 0.8406428697693349 and parameters: {'n_estimators': 336, 'learning_rate': 0.019600816989256194, 'depth': 8, 'l2_leaf_reg': 0.5952591418589315}. Best is trial 0 with value: 0.8415008242447165.\n",
      "[I 2025-05-06 16:47:48,933] Trial 4 finished with value: 0.8386367280156873 and parameters: {'n_estimators': 296, 'learning_rate': 0.0480154766120886, 'depth': 4, 'l2_leaf_reg': 0.05025999306278643}. Best is trial 0 with value: 0.8415008242447165.\n",
      "[I 2025-05-06 16:47:51,105] Trial 5 finished with value: 0.81140499808841 and parameters: {'n_estimators': 466, 'learning_rate': 0.13883263370919266, 'depth': 10, 'l2_leaf_reg': 0.6441714916509926}. Best is trial 0 with value: 0.8415008242447165.\n",
      "[I 2025-05-06 16:47:54,404] Trial 6 finished with value: 0.8114074646561399 and parameters: {'n_estimators': 878, 'learning_rate': 0.0851076646640192, 'depth': 9, 'l2_leaf_reg': 0.05496222204011618}. Best is trial 0 with value: 0.8415008242447165.\n",
      "[I 2025-05-06 16:47:55,875] Trial 7 finished with value: 0.8274565986853194 and parameters: {'n_estimators': 534, 'learning_rate': 0.08577921089262905, 'depth': 4, 'l2_leaf_reg': 0.0012583077636699007}. Best is trial 0 with value: 0.8415008242447165.\n",
      "[I 2025-05-06 16:47:57,832] Trial 8 finished with value: 0.838637139110309 and parameters: {'n_estimators': 761, 'learning_rate': 0.02975059186304835, 'depth': 5, 'l2_leaf_reg': 0.3917549673414567}. Best is trial 0 with value: 0.8415008242447165.\n",
      "[I 2025-05-06 16:47:58,984] Trial 9 finished with value: 0.8048147402087539 and parameters: {'n_estimators': 292, 'learning_rate': 0.24126384845131596, 'depth': 9, 'l2_leaf_reg': 0.011038702976571191}. Best is trial 0 with value: 0.8415008242447165.\n",
      "[I 2025-05-06 16:47:59,372] Trial 10 finished with value: 0.8257394564506914 and parameters: {'n_estimators': 130, 'learning_rate': 0.005028033421137849, 'depth': 7, 'l2_leaf_reg': 9.621473159908387}. Best is trial 0 with value: 0.8415008242447165.\n",
      "[I 2025-05-06 16:48:01,514] Trial 11 finished with value: 0.8412147023880486 and parameters: {'n_estimators': 643, 'learning_rate': 0.01008015004401473, 'depth': 8, 'l2_leaf_reg': 8.004002316074404}. Best is trial 0 with value: 0.8415008242447165.\n",
      "[I 2025-05-06 16:48:03,976] Trial 12 finished with value: 0.8435081992822286 and parameters: {'n_estimators': 700, 'learning_rate': 0.006686638088642345, 'depth': 8, 'l2_leaf_reg': 9.472176662073817}. Best is trial 12 with value: 0.8435081992822286.\n",
      "[I 2025-05-06 16:48:07,733] Trial 13 finished with value: 0.8403555146288021 and parameters: {'n_estimators': 903, 'learning_rate': 0.005343252306751921, 'depth': 10, 'l2_leaf_reg': 3.1414608942409425}. Best is trial 12 with value: 0.8435081992822286.\n",
      "[I 2025-05-06 16:48:09,695] Trial 14 finished with value: 0.8403551035341806 and parameters: {'n_estimators': 571, 'learning_rate': 0.01024868955966639, 'depth': 8, 'l2_leaf_reg': 2.4654349428358304}. Best is trial 12 with value: 0.8435081992822286.\n",
      "[I 2025-05-06 16:48:12,982] Trial 15 finished with value: 0.8412155245772919 and parameters: {'n_estimators': 992, 'learning_rate': 0.008153010899945579, 'depth': 7, 'l2_leaf_reg': 2.018333543074989}. Best is trial 12 with value: 0.8435081992822286.\n",
      "[I 2025-05-06 16:48:14,530] Trial 16 finished with value: 0.8409285805313809 and parameters: {'n_estimators': 455, 'learning_rate': 0.01581091775086838, 'depth': 9, 'l2_leaf_reg': 0.15206239818934586}. Best is trial 12 with value: 0.8435081992822286.\n",
      "[I 2025-05-06 16:48:16,727] Trial 17 finished with value: 0.8449425084171625 and parameters: {'n_estimators': 751, 'learning_rate': 0.008090346770357384, 'depth': 6, 'l2_leaf_reg': 3.8009484684891444}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:18,971] Trial 18 finished with value: 0.8409281694367593 and parameters: {'n_estimators': 763, 'learning_rate': 0.006774279154082151, 'depth': 6, 'l2_leaf_reg': 0.18089130705170733}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:20,961] Trial 19 finished with value: 0.8383489617805331 and parameters: {'n_estimators': 672, 'learning_rate': 0.02054243551956904, 'depth': 6, 'l2_leaf_reg': 1.5819343350095976}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:23,372] Trial 20 finished with value: 0.8297484512010129 and parameters: {'n_estimators': 834, 'learning_rate': 0.056412464122203416, 'depth': 5, 'l2_leaf_reg': 4.618423149668227}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:25,670] Trial 21 finished with value: 0.8409277583421376 and parameters: {'n_estimators': 629, 'learning_rate': 0.012425244860085905, 'depth': 8, 'l2_leaf_reg': 9.284837696951742}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:28,291] Trial 22 finished with value: 0.8449416862279191 and parameters: {'n_estimators': 564, 'learning_rate': 0.007341565462494772, 'depth': 7, 'l2_leaf_reg': 4.082340100131278}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:31,235] Trial 23 finished with value: 0.84293513337965 and parameters: {'n_estimators': 811, 'learning_rate': 0.007845106116908576, 'depth': 7, 'l2_leaf_reg': 1.3681093261134796}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:33,527] Trial 24 finished with value: 0.843222077425561 and parameters: {'n_estimators': 696, 'learning_rate': 0.006489554668292072, 'depth': 7, 'l2_leaf_reg': 4.187130476149583}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:34,920] Trial 25 finished with value: 0.841501235339338 and parameters: {'n_estimators': 421, 'learning_rate': 0.008620113108002186, 'depth': 6, 'l2_leaf_reg': 0.27682832798442697}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:38,453] Trial 26 finished with value: 0.8363419978376422 and parameters: {'n_estimators': 954, 'learning_rate': 0.02484030720515792, 'depth': 5, 'l2_leaf_reg': 1.107945843492883}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:40,709] Trial 27 finished with value: 0.8409285805313809 and parameters: {'n_estimators': 588, 'learning_rate': 0.013919707188392146, 'depth': 7, 'l2_leaf_reg': 3.830409327212937}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:43,372] Trial 28 finished with value: 0.8383489617805331 and parameters: {'n_estimators': 790, 'learning_rate': 0.0062568879683902985, 'depth': 6, 'l2_leaf_reg': 0.018158522286022747}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:45,546] Trial 29 finished with value: 0.842074301241917 and parameters: {'n_estimators': 524, 'learning_rate': 0.012396667507750044, 'depth': 8, 'l2_leaf_reg': 5.5791275490448715}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:48,059] Trial 30 finished with value: 0.841789412669114 and parameters: {'n_estimators': 717, 'learning_rate': 0.010644198425168198, 'depth': 5, 'l2_leaf_reg': 2.4998894151128104}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:50,739] Trial 31 finished with value: 0.8440820873740508 and parameters: {'n_estimators': 671, 'learning_rate': 0.00652933772503321, 'depth': 7, 'l2_leaf_reg': 4.9720562213537685}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:52,979] Trial 32 finished with value: 0.8403559257234237 and parameters: {'n_estimators': 599, 'learning_rate': 0.005118619771230644, 'depth': 7, 'l2_leaf_reg': 5.488616674612295}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:55,535] Trial 33 finished with value: 0.8417885904798708 and parameters: {'n_estimators': 693, 'learning_rate': 0.008235715255813148, 'depth': 7, 'l2_leaf_reg': 0.9110453574465831}. Best is trial 17 with value: 0.8449425084171625.\n",
      "[I 2025-05-06 16:48:58,293] Trial 34 finished with value: 0.844942919511784 and parameters: {'n_estimators': 855, 'learning_rate': 0.0063554087349386185, 'depth': 6, 'l2_leaf_reg': 9.879903533005999}. Best is trial 34 with value: 0.844942919511784.\n",
      "[I 2025-05-06 16:49:01,247] Trial 35 finished with value: 0.839494682491069 and parameters: {'n_estimators': 856, 'learning_rate': 0.01745206829883631, 'depth': 6, 'l2_leaf_reg': 1.8668799694907239}. Best is trial 34 with value: 0.844942919511784.\n",
      "[I 2025-05-06 16:49:04,376] Trial 36 finished with value: 0.8412151134826702 and parameters: {'n_estimators': 918, 'learning_rate': 0.010443027814172324, 'depth': 6, 'l2_leaf_reg': 0.4705082557757792}. Best is trial 34 with value: 0.844942919511784.\n",
      "[I 2025-05-06 16:49:06,856] Trial 37 finished with value: 0.8394950935856906 and parameters: {'n_estimators': 766, 'learning_rate': 0.02330403051865872, 'depth': 5, 'l2_leaf_reg': 3.541956061993107}. Best is trial 34 with value: 0.844942919511784.\n",
      "[I 2025-05-06 16:49:08,642] Trial 38 finished with value: 0.838060784450757 and parameters: {'n_estimators': 503, 'learning_rate': 0.03825384951684255, 'depth': 6, 'l2_leaf_reg': 0.9415634365908554}. Best is trial 34 with value: 0.844942919511784.\n",
      "[I 2025-05-06 16:49:10,207] Trial 39 finished with value: 0.8380640732077301 and parameters: {'n_estimators': 370, 'learning_rate': 0.01510966955745274, 'depth': 7, 'l2_leaf_reg': 0.0017556139567567674}. Best is trial 34 with value: 0.844942919511784.\n",
      "[I 2025-05-06 16:49:11,985] Trial 40 finished with value: 0.8116907088504561 and parameters: {'n_estimators': 638, 'learning_rate': 0.28330931393778963, 'depth': 4, 'l2_leaf_reg': 0.07716952346553273}. Best is trial 34 with value: 0.844942919511784.\n",
      "[I 2025-05-06 16:49:15,151] Trial 41 finished with value: 0.8423624785716928 and parameters: {'n_estimators': 745, 'learning_rate': 0.006482422902818437, 'depth': 8, 'l2_leaf_reg': 5.991839813334227}. Best is trial 34 with value: 0.844942919511784.\n",
      "[I 2025-05-06 16:49:18,812] Trial 42 finished with value: 0.8429347222850282 and parameters: {'n_estimators': 818, 'learning_rate': 0.007479510050971176, 'depth': 7, 'l2_leaf_reg': 9.715989308447341}. Best is trial 34 with value: 0.844942919511784.\n",
      "[I 2025-05-06 16:49:21,535] Trial 43 finished with value: 0.843222077425561 and parameters: {'n_estimators': 667, 'learning_rate': 0.005861923629507044, 'depth': 8, 'l2_leaf_reg': 6.353189727258051}. Best is trial 34 with value: 0.844942919511784.\n",
      "[I 2025-05-06 16:49:25,617] Trial 44 finished with value: 0.8420755345257817 and parameters: {'n_estimators': 886, 'learning_rate': 0.008648672135230023, 'depth': 8, 'l2_leaf_reg': 3.241305757048483}. Best is trial 34 with value: 0.844942919511784.\n",
      "[I 2025-05-06 16:49:29,020] Trial 45 finished with value: 0.843222077425561 and parameters: {'n_estimators': 722, 'learning_rate': 0.00503682450290221, 'depth': 9, 'l2_leaf_reg': 7.032973381732526}. Best is trial 34 with value: 0.844942919511784.\n",
      "[I 2025-05-06 16:49:31,154] Trial 46 finished with value: 0.8409285805313809 and parameters: {'n_estimators': 614, 'learning_rate': 0.00947784174316223, 'depth': 7, 'l2_leaf_reg': 0.02755996601135737}. Best is trial 34 with value: 0.844942919511784.\n",
      "[I 2025-05-06 16:49:32,357] Trial 47 finished with value: 0.8366281196943101 and parameters: {'n_estimators': 252, 'learning_rate': 0.11169004480094413, 'depth': 6, 'l2_leaf_reg': 2.4174044049080297}. Best is trial 34 with value: 0.844942919511784.\n",
      "[I 2025-05-06 16:49:34,110] Trial 48 finished with value: 0.8383485506859113 and parameters: {'n_estimators': 472, 'learning_rate': 0.007247891033353136, 'depth': 5, 'l2_leaf_reg': 0.6527769997533153}. Best is trial 34 with value: 0.844942919511784.\n",
      "[I 2025-05-06 16:49:37,134] Trial 49 finished with value: 0.8400677483936476 and parameters: {'n_estimators': 565, 'learning_rate': 0.01246166243670004, 'depth': 10, 'l2_leaf_reg': 9.990300896718672}. Best is trial 34 with value: 0.844942919511784.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1f2b55ca710>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# 1. RandomForest - GridSearch\n",
    "rf_param = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_param, cv=5, n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_best = rf_grid.best_estimator_\n",
    "\n",
    "# 2. GradientBoosting - GridSearch\n",
    "gbm_param = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "gbm_grid = GridSearchCV(GradientBoostingClassifier(random_state=42), gbm_param, cv=5, n_jobs=-1)\n",
    "gbm_grid.fit(X_train, y_train)\n",
    "gbm_best = gbm_grid.best_estimator_\n",
    "\n",
    "# 3. LightGBM - Optuna with cross_val_score\n",
    "def lgbm_objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 30)\n",
    "    }\n",
    "    model = lgb.LGBMClassifier(**params, random_state=42, verbose=-1)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    return score.mean()\n",
    "\n",
    "study_lgbm = optuna.create_study(direction='maximize')\n",
    "study_lgbm.optimize(lgbm_objective, n_trials=50)\n",
    "lgbm_best = lgb.LGBMClassifier(**study_lgbm.best_params, random_state=42, verbose=-1)\n",
    "lgbm_best.fit(X_train, y_train)\n",
    "\n",
    "# 4. XGBoost - Optuna with CV\n",
    "def xgb_objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**params, random_state=42)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    return score.mean()\n",
    "\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(xgb_objective, n_trials=50)\n",
    "xgb_best = xgb.XGBClassifier(**study_xgb.best_params, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_best.fit(X_train, y_train)\n",
    "\n",
    "# 5. CatBoost - Optuna with CV\n",
    "def catboost_objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 10.0, log=True),\n",
    "        'verbose': 0\n",
    "    }\n",
    "    model = CatBoostClassifier(**params, random_state=42)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    return score.mean()\n",
    "\n",
    "study_cat = optuna.create_study(direction='maximize')\n",
    "study_cat.optimize(catboost_objective, n_trials=50)\n",
    "cat_best = CatBoostClassifier(**study_cat.best_params, random_state=42, verbose=0)\n",
    "cat_best.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc6733",
   "metadata": {},
   "source": [
    "위에서 찾은 최적 하이퍼파라미터 조합을 통해 보팅 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4f2f4708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8754295532646048"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Soft Voting 앙상블 구성\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_best),\n",
    "        ('gbm', gbm_best),\n",
    "        ('lgbm', lgbm_best),\n",
    "        ('xgb', xgb_best),\n",
    "        ('cat', cat_best)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af40b3b",
   "metadata": {},
   "source": [
    "위에서 찾은 최적 하이퍼파라미터 조합을 통해 스태킹 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e1921e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Accuracy: 0.8840\n"
     ]
    }
   ],
   "source": [
    "base_learners = [\n",
    "        ('rf', rf_best),\n",
    "        ('gbm', gbm_best),\n",
    "        ('lgbm', lgbm_best),\n",
    "        ('xgb', xgb_best),\n",
    "        ('cat', cat_best)\n",
    "]\n",
    "\n",
    "stack_clf = StackingClassifier(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=LogisticRegression(random_state=SEED), # 최종 분류기를 LogisticRegression(random_state=SEED) 로 지정해주세요\n",
    "    passthrough=True,\n",
    "    n_jobs=-1,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "stack_clf.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_stk_pred = stack_clf.predict(X_test)\n",
    "\n",
    "# 정확도 출력\n",
    "print(f\"Stacking Accuracy: {accuracy_score(y_test, y_stk_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17065b9",
   "metadata": {},
   "source": [
    "트리 기반 모델(XGBoost, LGBM 등)과 다른 모델 (Logistic, SVM 등)을 함께 사용할 땐 스케일링하는 것이 성능이 더 좋았음\n",
    "\n",
    "트리 기반 모델만을 사용하여 최적 하이퍼 파라미터를 그리드서치, optuna를 통해 찾음\n",
    "\n",
    "개별 모델을 최적 하이퍼 파라미터로 조정한 이후 보팅, 스태킹 방식으로 결합한 결과 스태킹이 더 좋은 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1745d29d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

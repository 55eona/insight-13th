{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사전과제\n",
    "### 1. 지도 학습과 비지도 학습의 차이에 대해 설명해주세요.\n",
    "* **지도 학습(Supervised Learning)** 은 모델에게 정답을 알려주고 정답(label)과 예측값(prediction)이 최대한 같아지도록 학습하는 것이다. 주어진 데이터(X)를 기반으로 정답(Y)를 잘 맞추도록 하는 회귀(Regression) 문제나, 어떤 데이터가 무슨 label에 속하는지 판별하는 분류(Classification) 문제 등을 다룰 때 주로 사용한다.\n",
    "* **비지도 학습(Unsupervised Learning)** 은 모델에게 정답을 알려주지 않고 데이터 속의 패턴이나 유사도를 모델이 파악하여 학습하도록 하는 것이다. 정답이 없는 데이터의 특성을 모델이 스스로 파악하여 비슷한 것끼리 분류하는 문제를 다룰 때 주로 사용한다. 비슷한 데이터를 묶어 큰 단위로 만드는 군집화(Clustering), 데이터 분포를 예측하는 밀도 추정(Density Estimation), 데이터 차원을 간추리는 차원 축소(Dimensionality Reduction)가 해당한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 회귀와 분류의 차이에 대해 설명해주세요.\n",
    "* **회귀(Regression)** 는 연속형 변수를 예측하기 위해 사용된다. 즉, 예측하고자 하는 값(종속 변수)가 연속형이면 회귀를 사용한다.\n",
    "* **분류(Classification)** 는 범주형 변수를 예측하기 위해 사용된다. 즉, 예측하고자 하는 값(독립 변수)가 범주형이면 분류를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 분류 모델의 네 가지 종류와, 각 모델이 무엇인지 간단하게 정리해주세요.\n",
    "#### (1) **로지스틱 회귀(Logistic Regression)**\n",
    "* 독립변수와 종속변수의 선형 관계성에 기반해 분류하는 알고리즘. 샘플이 **특정 클래스에 속할 확률을 추정**하는 것을 목표로 한다. **이진 분류(binary classification)** 를 해결하는 데 적합하다. 예를 들어 학생들의 시험 성적(x)에 따른 합격/불합격 결과(y) 데이터가 있다고 할 때, 특정 점수를 얻었을 때 합격/불합격인지 판정하는 모델을 만들 수 있다. 이때 합격(1)과 불합격(0)을 가르는 특정 점수대가 있을 것이다. 이를 다중 선형 회귀(y=wx+b 형태의 직선)를 적용하여 풀려고 하면, y값이 0과 1 사이에만 존재하는 것이 아니라 위아래로 무한대로 존재하게 된다. 합격(1)과 불합격(0)의 이진 분류 문제를 풀려면 무한대의 직선이 아니라, S자 형태로 표현할 수 있는 함수가 필요하다. 이를 위해 **시그모이드 함수(sigmoid function)** 를 이용할 수 있다. 시그모이드 함수는 $\\sigma(z)=\\dfrac{1}{1+e^{-z}}$ 로 나타나는 함수이며, 출력이 0과 1 사이로 나타나고, 뾰족한 개형이 아니라 부드럽게 이어지는 개형이다. 이 시그모이드 함수는 이진 분류 문제 풀기에 적합하다.\n",
    "\n",
    "#### (2) **결정 트리(Decision Tree)**\n",
    "* 데이터 균일도에 따른 규칙 기반의 분류 알고리즘.\n",
    "* **조건**에 따라 데이터를 분류하며, 최종적으로 데이터가 순수한 Label의 집합으로 구성될 때까지 **분류를 반복**하는 모델이다.\n",
    "* **CART (Classification And Regression Tree)**\n",
    "  * 가장 대표적인 Decision Tree 알고리즘\n",
    "  * 데이터셋을 **임계값**을 기준으로 **두 child로 나누는** 알고리즘\n",
    "    * 불순도(지니계수)가 낮아지는 방향으로 임계값을 나눔\n",
    "      * 불순도: 분류하려는 데이터 집합에서 서로 다른 클래스(범주)가 섞여 있는 정도. CART에서는 *지니 계수*를 사용함\n",
    "  * CART 알고리즘 주요 단계\n",
    "    * (1) 임계값 설정\n",
    "    * (2) 불순도 감소 알고리즘 => 불순도가 낮은 쪽으로 가지를 형성해 나감\n",
    "* 실제 학습 시 고려해야 할 것들\n",
    "  * Parameter 설정 => 과적합 방지 등\n",
    "  * 시각화 => 분류가 잘 이루어졌는지 확인\n",
    "  * Prunning(가지치기) => 불필요한 노드를 지움 => 깊이가 줄어들고 결과의 개수가 줄어듦 => 과적합 방지, 일반화 성능 높임\n",
    "\n",
    "#### (3) **서포트 벡터 머신(SVM)**\n",
    "* 개별 클래스 간의 최대 마진을 효과적으로 찾아 분류하는 알고리즘.\n",
    "* 클래스를 분류할 수 있는 **다양한 경계선 중 최적의 라인을 찾아내는** 알고리즘\n",
    "* 명확하게 분류할 수 있는 데이터 집단에서 뛰어난 성능을 보이며, 고차원 공간(다수의 feature)에서도 효과적으로 사용 가능\n",
    "* **SVM의 구성**\n",
    "  * Support vector: 구분하는 선과 가장 가까운 포인트\n",
    "  * Decision Boundary(결정 경계): 집단을 구분하는 선\n",
    "  * Margin: 선과 각 점 사이의 거리\n",
    "* Decision Boundary가 데이터로부터 가장 멀리 떨어져 있는 선이 좋은 선!! Margin이 가장 큰 경우를 선택함으로써 최적의 선을 찾음!!\n",
    "  \n",
    "#### (4) **최소 근접(Nearest Neighbor) 알고리즘 - KNN(K-Nearest Neighbor)**\n",
    "* 근접 거리 기준으로 분류하는 알고리즘. 비슷한 특성을 가진 데이터끼리 서로 가까이 있다는 점을 이용한 분류 알고리즘.\n",
    "* 데이터로부터 거리가 가까운 k개의 다른 데이터 Label을 참조하여 분류하는 알고리즘.\n",
    "* **별도의 모델 없이, 학습 없이, 데이터만을 이용해서** 새로운 데이터가 왔을 때 주변 데이터들을 이용하여 분류할 수 있음\n",
    "* **KNN 계산 단계**\n",
    "  * (1) 데이터 준비\n",
    "  * (2) K값 설정: k는 가장 가까운 이웃의 개수를 나타냄. 보통 홀수 개로 설정함.\n",
    "  * (3) 거리 계산: 새로운 데이터(예측하려는 데이터)가 주어지면 이 값과 기존의 모든 데이터 간의 거리를 계산함.\n",
    "  * (4) 가장 가까운 k개의 이웃 선택\n",
    "  * (5) 분류하기: K개의 이웃 중 가장 많이 등장하는 클래스가 예측 결과가 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 분류 평가 지표에는 무엇이 있는지 작성해주세요.\n",
    "#### (1) 혼동 행렬\n",
    "* **혼동 행렬**: 분류 모델의 예측 결과를 **정확한 예측**과 **잘못된 예측**으로 구분하여 나타낸 표(행렬)\n",
    "  * 예측값: Positive/Negative\n",
    "  * 예측 성공 여부: True/False\n",
    "* 4가지 경우의 수\n",
    "  * True Positive (TP): 실제로 참, 참으로 예측\n",
    "  * True Negative (TN): 실제로 거짓, 거짓으로 예측\n",
    "  * False Positive (FP): 실제로 거짓, 참으로 예측 (예측이 틀림. 위양성)\n",
    "  * False Negative (FN): 실제로 참, 거짓으로 예측 (예측이 틀림. 위음성)\n",
    "* **혼동 행렬을 이용한 분류 모델 평가 지표**\n",
    "  * **정확도(Accuracy)**: 모든 가능한 예측 중 참인 비율\n",
    "    * $\\dfrac{TP+TN}{TP+TN+FP+FN}$\n",
    "  * **정밀도(Precision)**: 참이라고 예측한 경우 중 실제 참의 비율\n",
    "    * $\\dfrac{TP}{TP+FP}$\n",
    "  * **재현도(Recall)**: 실제로 참인 경우 중 참으로 예측하는 비율\n",
    "    * $\\dfrac{TP}{TP+FN}$\n",
    "* Precision과 Recall은 Trade-off 관계에 있음.\n",
    "  * => 두 그래프의 교점을 threshold로 정하면 예측 오류를 최소화할 수 있음.\n",
    "* 모델의 종류와 역할에 따라 특정 평가 지표가 중요할 수 있음.\n",
    "#### (2) F1-Score\n",
    "* **F1-Score**: 정밀도(precision)와 재현율(recall)의 조화 평균\n",
    "  * 정밀도와 재현율 간의 균형을 효과적으로 평가하기 위해 조화평균을 사용함\n",
    "* $F1 \\ Score = \\dfrac{2}{\\dfrac{1}{Precision}+\\dfrac{1}{Recall}} = \\dfrac{2 \\times Precision \\times Recall}{Precision + Recall}$\n",
    "  \n",
    "#### (3) ROC/AUC Curve\n",
    "* **ROC Curve**: 얼마나 분류가 잘 되었는가를 보여주는 그래프\n",
    "  * TRR (True Positive Rate): 참인 것들 중에 참이라고 예측한 비율 (=Recall. 진양성)\n",
    "  * FPR (False Positive Rate): 거짓인 것들 중에 참이라고 잘못 예측한 비율 (위양성)\n",
    "  * 좌상단으로 붙어 있는 ROC Curve일수록 더 좋은 이진 분류기임.\n",
    "* **AUC Curve**: ROC와 x축 사이의 면적(적분값)\n",
    "  * 0과 1 사이의 값을 가짐\n",
    "  * 1에 가까울수록 (ROC Curve가 좌상단으로 붙어 있을수록) 분류 성능이 좋은 것임\n",
    "#### (4) 다중 분류 평가 지표\n",
    "* **Macro average**: 클래스별로 구한 평가 지표 평균\n",
    "* **Weighted average**: 클래스별로 구한 평가 지표 가중 평균\n",
    "* **Micro average**: 모든 클래스의 예측 결과를 더하여 전체적인 성능을 평가하는 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 하이퍼파라미터 최적화가 무엇인지 쓰세요.\n",
    "#### (1) 하이퍼파라미터 최적화\n",
    "* **하이퍼파라미터(hyper-parameter)** : 사용자가 직접 설정하는 변수\n",
    "* **하이퍼파라미터 최적화**: 적절한 하이퍼파라미터를 찾아 모델 성능을 향상시키는 것. 적절히 실험해서 튜닝하여 정확도 결과를 보고 가장 적절한 하이퍼파라미터를 찾을 수 있음.\n",
    "  \n",
    "#### (2) 하이퍼파라미터 최적화 방법\n",
    "##### 1️⃣ Grid Search\n",
    "* 정해진 범위에서 하이퍼파라미터를 모두 순회\n",
    "  * 장점: 정확성 높음\n",
    "  * 단점: 시간이 너무 오래 걸림\n",
    "  * 적용: 넓은 범위, 큰 step을 활용해 범위를 좁힌다.\n",
    "##### 2️⃣ Random Search\n",
    "* 정해진 범위에서 하이퍼파라미터를 무작위로 탐색\n",
    "  * 장점: 속도가 grid search보다는 빠름\n",
    "  * 단점: 정확성 떨어짐.\n",
    "##### 3️⃣ Bayesian Optimization\n",
    "* 사전 정보를 바탕으로 하이퍼파라미터 값을 확률적으로 추정하며 탐색\n",
    "  * 특징: 여러 개의 하이퍼파라미터들에 대해서 Acquisition Function을 적용했을 때 가장 큰 값이 나올 확률이 높은 지점을 찾아냄.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63b8bb87",
   "metadata": {},
   "source": [
    "# EDA & 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639bf7e",
   "metadata": {},
   "source": [
    "# 0. 데이터 분석 프로세스\n",
    "\n",
    "## 1️⃣단계: 데이터 수집\n",
    "## 2️⃣단계: 데이터 탐색(EDA)\n",
    "* 수집한 데이터를 여러 방식으로 파악하는 단계\n",
    "## 3️⃣단계: 데이터 전처리\n",
    "* 데이터 분석(모델링)을 위해 데이터를 적절한 방식으로 손질하는 과정\n",
    "* 결측치(값 없음)나 이상치(너무 튀는 값)가 있는 경우 적절히 처리해주어야 데이터 왜곡 방지 가능\n",
    "## 4️⃣단계: 데이터 모델링\n",
    "* 데이터로부터 유용한 정보를 추출하기 위해 모델을 구축하는 단계\n",
    "* 예측, 분류, 군집 등의 목적에 따라 모델을 선택하고 학습시키는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1d76d",
   "metadata": {},
   "source": [
    "# 1. EDA(Exploratory Data Analysis)의 개념\n",
    "* **EDA란?**\n",
    "    * 탐색적 데이터 분석 과정\n",
    "    * 데이터 분석 및 결과 도출 과정에서 데이터에 대한 '탐색과 이해'를 기본으로 가져야 한다는 것.\n",
    "* **EDA 과정**\n",
    "    * 시각화 등의 도구를 통해 패턴을 발견\n",
    "    * 데이터의 특이성을 확인\n",
    "    * 통계와 그래프(혹은 시각적 표현)으로 가설을 검정\n",
    "\n",
    "## 1-1. EDA 대상 (일변량/다변량)\n",
    "* 하나의 변수를 살펴볼 것인가, 여러 변수 간의 관계를 살펴볼 것인가?\n",
    "### **1️⃣ Univariate(일변량)**\n",
    "    * EDA를 통해 한 번에 파악하려는 변수가 **1개**\n",
    "    * **주요 목적**: **데이터 설명**하고 그 안에 **존재하는 패턴을 찾는 것**\n",
    "### **2️⃣ Multi-variate(다변량)**\n",
    "    * EDA를 통해 한 번에 파악하려는 변수가 **여러 개**\n",
    "    * **주요 목적**: **여러 변수들 간의 관계를 보는 것**\n",
    "    * 변수를 동시에 확인하기 전에, 개별 데이터를 먼저 파악하는 것이 오류에 대처하기 용이함.\n",
    "\n",
    "## 1-2. EDA의 종류 (시각화/비시각화)\n",
    "* 시각적으로 파악할 것인가, 수치적으로 파악할 것인가?\n",
    "### **1️⃣ Graphic(시각화)**\n",
    "    * 차트 혹은 그림 등을 이용하여 데이터를 확인하는 방법\n",
    "### **2️⃣ Non-Graphic(비시각화)**\n",
    "    * 그래픽적인 요소를 사용하지 않고 주로 Summary Statistics를 통해 데이터를 확인하는 방법\n",
    "* 데이터를 그래프로 표현하게 되면, 한눈에 데이터를 파악할 수 있으므로 **대략적 형태 파악**에 용이\n",
    "* 데이터를 통곗값으로 표현하게 되면, **정확한 값 파악**에 용이\n",
    "\n",
    "## 1-3. EDA의 유형\n",
    "* EDA 대상(일변량/다변량)과 EDA 종류(시각화/비시각화)에 따라 EDA 유형이 구분된다.\n",
    "    1. 데이터 변수 개수가 몇 개인가?\n",
    "    2. 결과를 어떻게 파악할 것인가?\n",
    "    3. 데이터의 유형은 무엇인가?\n",
    "||**일변량(Univariable)**|**다변량(Multivariable)**|\n",
    "|------|---|---|\n",
    "|**비시각화(Non-Graphic)**|빈도표 <br> 기술통계량|교차표<br>상관계수|\n",
    "|**시각화(Graphic)**|파이차트<br>막대그래프<br>히스토그램<br>박스플롯|모자이크플롯<br>박스플롯<br>평행좌표<br>산점도|\n",
    "### 1️⃣ Uni-Non Graphic (일변량 비시각화)\n",
    "* 주어진 데이터의 Distribution(분포)를 확인하는 것이 주목적\n",
    "* 빈도표, 기술통계량 등\n",
    "\n",
    "### 2️⃣ Uni-Graphic (일변량 시각화)\n",
    "* 주어진 데이터를 전체적으로 살펴보는 것이 주목적\n",
    "* 파이차트, 막대그래프, 히스토그램, 박스플롯 등\n",
    "\n",
    "### 3️⃣ Multi-Non Graphic (다변량 비시각화)\n",
    "* 주어진 둘 이상의 변수 간 관계를 확인하는 것이 주목적\n",
    "* 교차표, 상관계수 등\n",
    "\n",
    "### 4️⃣ Multi-Graphic (다변량 시각화)\n",
    "* 주어진 둘 이상의 변수 간 관계를 전체적으로 살펴보는 것이 주목적\n",
    "* 모자이크플롯, 박스플롯, 평행좌표, 산점도 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739822a9",
   "metadata": {},
   "source": [
    "# 2. 데이터 확인\n",
    "* 데이터 읽기: 작업 공간에 데이터를 불러오는 것\n",
    "* 데이터 쓰기: 새로운 데이터를 만드는 것\n",
    "\n",
    "## 2-1. 데이터 읽기와 쓰기\n",
    "\n",
    "### 2-1-1. 절대경로와 상대경로\n",
    "#### 1️⃣ 절대경로\n",
    "---\n",
    "```python\n",
    "pd.read_csv('/Users/hyeonseokim_macbookpro/Desktop/서강대학교/2025/INSIGHT/repos/insight-13th/code/neulbokim/session1/titanic.csv')\n",
    "\n",
    "```\n",
    "---\n",
    "#### 2️⃣ 상대경로\n",
    "* ./: 현재 디렉토리\n",
    "* ../: 상위 디렉토리\n",
    "* /: 최상위(루트) 디렉토리\n",
    "---\n",
    "```python\n",
    "pd.read_csv('./titanic.csv')\n",
    "```\n",
    "---\n",
    "### 2-1-2. 데이터 입출력\n",
    "* 데이터 파일의 형식에 따라 **데이터를 읽고(Reader) 쓰는(Writer) 함수가 다르다**.\n",
    "|**File Format**|**Reader**|**Writer**|\n",
    "|-----|---|---|\n",
    "|**CSV**|`read_csv`|`to_csv`|\n",
    "|**JSON**|`read_json`|`to_json`|\n",
    "|**HTML**|`read_html`|`to_html`|\n",
    "|**MS EXCEL**|`read_excel`|`to_excel`|\n",
    "|**SQL**|`read_sql`|`to_sql`|\n",
    "\n",
    "### 2-1-3. CSV와 EXCEL\n",
    "#### 1️⃣ CSV (Comma Separated Value) 파일\n",
    "* 데이터를 **쉼표(,)로 구분**하고 있는 텍스트 파일.\n",
    "* 데이터의 **크기가 작고 압축이 용이**하기에 **가장 널리 사용되는 데이터 형식**임.\n",
    "---\n",
    "```python\n",
    "# csv 파일 읽기\n",
    "pd.read_csv(\"파일경로/파일이름.csv\")\n",
    "```\n",
    "---\n",
    "#### 2️⃣ EXCEL 파일\n",
    "* 행과 열이 데이터프레임의 행, 열로 일대일 대응되는 파일.\n",
    "* 여러 개의 시트로 구성된 데이터를 읽을 때, 불러올 특정 시트를 설정할 수 있음\n",
    "    * ex) `sheet_name = 'Sheet 2'`\n",
    "* 여러 시트를 불러올 때는 list로 받으면 됨\n",
    "    * ex) `sheet_name = ['Sheet 1', 'Sheet 2']`\n",
    "---\n",
    "```python\n",
    "# excel 파일 읽기\n",
    "pd.read_excel(\"파일경로/파일이름.xlsx\", sheet_name=\"불러올 시트\")\n",
    "```\n",
    "---\n",
    "\n",
    "## 2-2. 데이터셋 파악하기\n",
    "### 2-2-1. 데이터 프레임 보기\n",
    "* `head(n)`: 데이터 프레임 상위 n개 데이터를 보여줌\n",
    "\n",
    "### 2-2-2. 데이터 변수 확인\n",
    "* `**변수**` == `데이터 프레임의 column` == `feature`\n",
    "#### 1️⃣ 변수 정의 확인\n",
    "* 어떤 정보를 가지는 변수인지 확인\n",
    "> ex) 타이타닉 데이터셋의 **변수 정의 확인**\n",
    "    >\n",
    "    ```\n",
    "    survived: 생존 여부\n",
    "    pclass:Passenger Class, 승객 등급\n",
    "    name: 승객 이름\n",
    "    sex: 승객 성별\n",
    "    age: 승객 나이\n",
    "    sibsp: 동승한 형제 또는 배우자 수\n",
    "    parch: 동승한 부모 또는 자녀 수\n",
    "    ticket: 티켓 번호\n",
    "    fare: 승객 지불 요금\n",
    "    cabin: 선실 이름\n",
    "    embarked: 승선항(C=쉘 부르크, Q=퀸즈타운, S=사우스 햄튼)\n",
    "    ```\n",
    "#### 2️⃣ 변수 유형 확인\n",
    "* **`질적/범주형(Categorical Data)` : 몇 개의 번주로 나누어진 데이터**\n",
    "    * **`명목형(Nominal)` : 성별, 성공여부, 혈액형 등 순서 없이 단순히 분류된 자료**\n",
    "        * ex) 성별(sex), 생존 여부(survived), 이름(name), 티켓(ticket), 선실이름(cabin), 승선항 항구(embarked)\n",
    "    * **`순서형(Ordinal)` : 범주형 데이터 중 그들 사이에 순서 관계가 존재하는 자료**\n",
    "        * ex) 승객 등급(pclass)\n",
    "* **`양적/수치형(Numerical Data)` : 숫자로 표현되는 데이터**\n",
    "    * **`이산형(Discrete)` : 이산적인 값으로, 정수 단위로 떨어져 셀 수 있는 데이터**\n",
    "        * ex) 동승 형제 및 배우자 수(sibsp), 부모 및 자녀 수(parch)\n",
    "    * **`연속형(Continuous)` : 신장, 체중 등 연속적인 값을 갖는 데이터**\n",
    "        * ex) 요금(fare), 나이(age)\n",
    "\n",
    "* ❓정수면 이산형, 소수면 연속형?\n",
    "    * 단순히 정수/소수로 나누는 것 X\n",
    "    * **일정 구간을 잘랐을 때 셀 수 있는지 여부**가 기준\n",
    "    \n",
    "        * ex) 타이타닉에서 나이(age)\n",
    "            * [0.67, 22, 25.5, 25.92] 등으로 나타남\n",
    "            * '23.22' 의 수치적인 의미가 **있음** (더 이상 나눌 수 있음)\n",
    "            * **⇒ 연속형**\n",
    "        * ex) 개설교과목 학점\n",
    "            * [1학점, 1.5학점, 2학점, 3학점] \n",
    "            * '1.2학점'의 수치적인 의미가 **없음** (더 이상 나눌 수 없음)\n",
    "            * **⇒ 이산형**  \n",
    "            \n",
    "\n",
    "#### 3️⃣ 변수 데이터 형식(자료형) 확인\n",
    "* `날짜`, `수치`, `텍스트`, `이미지` 등의 구분\n",
    "* **Pandas의 자료형 종류**\n",
    "    * Pandas는 NumPy를 기반으로 만들어졌기에 기본적으로 NumPy의 자료형을 사용할 수 있다.\n",
    "    |**Pandas 자료형**|**Python 자료형**|**비고**|\n",
    "    |---|---|---|\n",
    "    |int64|int|정수형 데이터|\n",
    "    |float64|float|실수형 데이터|\n",
    "    |object|string|문자열 데이터|\n",
    "    |datetime64, timedelta64|없음(datatime 라이브러리 활용)|시간 데이터|\n",
    "    \n",
    "    \n",
    "### 2-2-3. 데이터 분포 확인\n",
    "#### 단변수 분석\n",
    "* 원시 데이터(raw data)의 **평균값, 최빈값, 중간값** 등 **변수들의 분포**를 **산포도, 박스 플롯, 히스토그램** 등의 **그래프**를 통해 **하나의 데이터 분포를 확인**해 분석할 수 있는 방법\n",
    "* 원시 데이터 분포의 확인을 통해 **전처리 아이디어**를 얻을 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c60cd90",
   "metadata": {},
   "source": [
    "# 3. 전처리\n",
    "* **데이터 전처리**: 데이터 분석(모델링)을 위해 **데이터를 적절한 방식으로 손질**하는 과정\n",
    "* 데이터의 품질은 데이터 분석의 정확도에 매우 큰 영향을 미침.\n",
    "* 따라서 데이터 품질을 높이기 위한 작업(누락/중복 데이터 등 오류 수정, 분석 목적에 맞게 변형)이 중요함.\n",
    "\n",
    "### **데이터 전처리 과정**\n",
    "    1. 데이터 확인\n",
    "    2. 결측값 처리\n",
    "    3. 이상값 처리\n",
    "    4. 변수 가공\n",
    "    \n",
    "### **전처리의 여러 기술**\n",
    "    1. 데이터 정제(Cleansing)\n",
    "        * 결측값 보완\n",
    "        * 이상값 제거\n",
    "    2. 데이터 변환(Transformation)\n",
    "        * 데이터의 일관성 확보\n",
    "        * 데이터의 중복을 최소화\n",
    "    3. 데이터 필터링(Filtering)\n",
    "        * 오류 발견하여 삭제 및 보정\n",
    "    4. 데이터 통합(Integration)\n",
    "        * 유사한 성질의 데이터 연계하는 등 데이터를 통합\n",
    "        \n",
    "## 3-1. 결측값 처리\n",
    "* **결측값** == 데이터 수집 과정에서 측정되지 않거나 누락된 데이터 (NaN)\n",
    "* 결측값이 있는 상태로 모델을 만들면 변수 간의 관계가 왜곡될 수 있어 모델의 정확성이 떨어질 수 있음.\n",
    "\n",
    "### 3-1-1. 결측값 확인\n",
    "* DataFrame상에서 `NaN`, `?`, `0` 등의 값으로 나타나 있는 결측값을 확인하는 작업\n",
    "* 이때 `0`은 실제 zero인지, 결측되어 0으로 표기된 것인지 잘 살펴봐야 함\n",
    "#### 결측값 관련 Pandas 함수\n",
    "* `info()`: 데이터 프레임의 **요약 정보**를 출력. 각 열에 속하는 유효한 값(NaN 값이 아닌 non-null)의 개수를 보여줌.\n",
    "* `value_counts(dropna=False`: 각 열의 **결측값을 포함**한 **전체 데이터 확인** 가능\n",
    "* `isnull()`: 누락 데이터면 True, 유효한 데이터면 False 반환\n",
    "    * ⇒ `df.isnull().sum()`의 형식으로 자주 사용\n",
    "* `notnull()`: 유효 데이터면 True, 누락 데이터면 False 반환\n",
    "* `replace()`: 결측값이 'NaN'이 아니라 '0'이나 '?' 등으로 입력될 경우, replace를 활용하여 NaN으로 변환하여 처리할 수 있음\n",
    "\n",
    "### 3-1-2. 결측값 처리\n",
    "#### 1️⃣ 삭제\n",
    "* 데이터가 있는 행 또는 열을 삭제\n",
    "* `dropna()`: DataFrame 내의 결측값이 포함된 레이블을 제거하는 메서드\n",
    "---\n",
    "```python\n",
    "DataFrame.dropna(axis=0/1, how='any'/'all', thresh=None, subset=[col1, col2, ...], inplace=True/False)\n",
    "```\n",
    "---\n",
    "* **[삭제 기준]** `axis`: {0: index / 1: columns} 결측치 제거를 진행할 레이블\n",
    "* **[삭제 조건]** `how`: {'any': 존재하면 제거 /'all': 모두 결측치면 제거} 제거할 유형. 포함만 시켜도 제거할지, 전부 결측치여야 제거할지 정할 수 있음.\n",
    "* **[정상값의 수 보장]** `thresh`: 결측값이 아닌 값이 몇 개 미만일 경우에만 적용시키는 인수. thresh=3이라면, 결측값이 아닌 값이 3개 미만일 경우에만 dropna 메서드를 수행함.\n",
    "* **[특정 column(열) 기준으로 삭제]** `subset`: dropna메서드를 수행할 레이블을 지정함.\n",
    "* **[원본 데이터 변경 여부]** `inplace`: 원본을 변경할지 여부. False가 default. True면 원본 데이터프레임 자체를 변경.\n",
    "---\n",
    "* **데이터 삭제 시 주의할 점**\n",
    "    * 결측값이 무작위로 발생한 것이 아닌데 데이터 삭제하여 사용할 경우, 모델이 왜곡될 수 있음.\n",
    "    * 삭제는 **결측값이 무작위로 발생한 경우**에 사용하자!\n",
    "#### 2️⃣ 대체\n",
    "* 결측값을 다른 값으로 대체\n",
    "* **평균값, 최빈값** 등을 활용\n",
    "* `fillna()`: 결측값 대체하는 메서드\n",
    "    * **일괄 대체**: 모든 변수들을 일괄적으로 같은 값으로 대체\n",
    "        * ex) 모든 변수들의 평균값을 구해 일괄적으로 대체\n",
    "        ---    \n",
    "        ``` python\n",
    "        # 평균값으로 일괄 대체\n",
    "        a = df['column1'].mean(axis=0)\n",
    "        df['column1'].fillna(a, inplace=True) # 원본 객체를 변경(inplace=True)\n",
    "        ```\n",
    "        ---\n",
    "\n",
    "    * **유사 유형 대체**: 범주형 변수들을 활용해 **유사한 범주에 따라 다른 값**으로 대체\n",
    "        * ex) 범주형 변수들을 활용해 유사한 유형의 평균값으로 대체\n",
    "        ---    \n",
    "        ``` python\n",
    "        # 범주별로 그룹화하여 평균값 계산\n",
    "        category_means = df.groupby('Category')['Value'].mean()\n",
    "\n",
    "        # 결측값을 범주의 평균값으로 대체\n",
    "        df['Value'] = df.groupby('Category')['Value'].apply(lambda x: x.fillna(x.mean()))\n",
    "        ```\n",
    "        ---\n",
    "        \n",
    "    * (참고) 서로 이웃하고 있는 값으로 치환 가능 (method 옵션 이용)\n",
    "    ---    \n",
    "    ``` python\n",
    "    # NaN이 있는 바로 직전 행에 있는 값\n",
    "    df[\"열2\"].fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "    # NaN이 있는 바로 다음 행에 있는 값\n",
    "    df[\"열3\"].fillna(method=\"bfill\", inplace=True).\n",
    "    ```\n",
    "    ---\n",
    " \n",
    "\n",
    "## 3-2. 이상치 처리\n",
    "* **이상치(Outlier)** == 관측된 데이터의 범위에서 **많이 벗어난 값**을 말함.\n",
    "* 이상치를 처리해주지 않으면 데이터 분석에 큰 영향을 끼치게 되기 때문에 알맞은 처리를 진행해주어야 함.\n",
    "### 3-2-1. 이상치 확인\n",
    "#### 1️⃣ 통계를 통해 확인 : `describe()`\n",
    "#### 2️⃣ 시각화를 통해 확인: BoxPlot\n",
    "---\n",
    "```python\n",
    "for i in df.describe().columns:\n",
    "    df[[i]].boxplot()\n",
    "    plt.show()\n",
    "```\n",
    "---\n",
    "#### 3️⃣ Z-score을 통해 확인\n",
    "* 데이터를 **평균(0)과 표준편차(1)로 정규화**하여, **평균으로부터 얼마나 떨어져있는지** 나타냄\n",
    "* 평균에 가까울수록 0에 가깝고 멀어질수록 Z-score가 커짐\n",
    "* Z-score가 특정 기준값(일반적으로 2~3)을 넘어가는 데이터를 이상치로 간주함\n",
    "\n",
    "#### 4️⃣ Tukey Fences를 통해 확인\n",
    "* **사분위 범위(IQR, Interquartile Range)** 를 기반으로, 두 가지 경우에 이상치라고 판단함\n",
    "    * Q1 - (1.5*IQR) 미만\n",
    "    * Q3 - (1.5*IQR) 초과\n",
    "* **Tukey Fences(튜키 펜스)**: 이상치를 식별하는 통계적인 방법 중 하나\n",
    "    * 데이터의 **사분위 범위(IQR, Interquartile Range)** 를 기반으로, 두 가지 경우에 이상치라고 판단함\n",
    "        * Q1 - (1.5*IQR) 미만\n",
    "        * Q3 - (1.5*IQR) 초과\n",
    "    * **IQR**은 데이터의 **중간 50% 범위**를 측정함.\n",
    "        * 이는 데이터의 상위 25%와 하위 25%를 제외한 중간 범위를 의미함.\n",
    "    * 이상치 판단 기준이 될 수 있음.\n",
    "    \n",
    "### 3-2-2. 이상치 제거\n",
    "#### 1️⃣ 전체 삭제\n",
    "* 이상치가 **Human error에 의해 발생**한 경우: 해당 관측치를 **삭제**\n",
    "* 단순 오타, 주관식 설문에서의 비현실적인 응답, 데이터 처리 과정에서의 오류 등에 사용함.\n",
    "#### 2️⃣ 다른 값으로 대체\n",
    "* **절대적인 관측치의 양이 적은 경우**: 단순 삭제를 통해 이상치를 제거하면 관측치의 절대량이 작아져 신뢰성 문제가 발생함.\n",
    "    * 이런 경우, Human error에 의해 발생한 이상치라 하더라도, 관측치를 삭제하는 대신 다른 값(평균값 등)으로 **대체**하거나, 결측치 처리와 유사하게 **다른 변수들을 사용해서 예측 모델**을 만들고, 이상치를 **예측**한 후 해당 값으로 **대체**할 수 있음.\n",
    "#### 3️⃣ 변수화\n",
    "* 이상치가 **자연 발생**한 경우: 단순 삭제/대체는 모델이 설명하고자 하는 현상을 잘 설명하지 못할 수 있음.\n",
    "    * 바로 삭제하는 대신, 이상치에 대해 **파악**하는 것이 중요\n",
    "        * 새로운 구분 기준을 만들어 변수화하면 이상치를 삭제하지 않고 모델에 포함시킬 수 있음\n",
    "#### 4️⃣ 리샘플링\n",
    "* 자연발생한 이상치를 처리하는 처리하는 또 다른 방법\n",
    "* 해당 **이상값을 분리**해서 모델을 만들 수 있음\n",
    "    * 독립변수와 종속변수 모두 outlier인 경우\n",
    "    * 이상값을 포함한 모델, 이상값을 제외한 모델을 모두 만들고 각각의 모델에 대한 설명을 다는 것이 좋은 방법. (case 분리)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 3-3. 피처 엔지니어링 (Feature Engineering, 변수 가공)\n",
    "### 3-3-0. 피처 엔지니어링의 개념\n",
    "* 도메인 지식과 기존의 변수를 사용해서 **기존의 데이터에 정보를 추가하는 일련의 과정**\n",
    "    * 해결하고자 하는 문제를 컴퓨터가 잘 이해할 수 있도록 피처(변수)들의 형태를 변형하거나 적절하게 처리하는 과정\n",
    "* 데이터 전처리의 마지막 단계\n",
    "* 새로운 데이터 또는 변수의 추가 없이 기존의 데이터를 보다 유용하게 만드는 방법\n",
    "* 도메인 지식 여부에 따라 피처 엔지니어링의 결과와 그 유의성이 많이 달라지기도 함\n",
    "* cf) `피처(feature)` == `입력 변수` == `column`\n",
    "\n",
    "* **피처 엔지니어링 방식**\n",
    "    1. **레이블인코딩, 원핫인코딩**: **텍스트**로 주어지는 값을 **숫자**로 바꾸는 작업\n",
    "    2. **구간화**: 연속적인 값을 **일정한 구간으로 구분**\n",
    "    3. **변환**: 기존의 피처를 변환해 **새로운 피처 생성**\n",
    "    4. **스케일링**: 서로 다른 변수의 값 범위를 **일정한 수준으로 맞추는** 작업\n",
    "\n",
    "### 3-3-1. 레이블 인코딩(Label Encoding) vs 원핫인코딩(One-Hot Encoding)\n",
    "* 기계가 이해할 수 있도록 **텍스트**로 주어진 값을 **숫자**로 바꿔주어야 함.\n",
    "#### 1️⃣ 레이블 인코딩(Label Encoding)\n",
    "* 범주형 변수를 0부터 N-1까지의 숫자로 변환\n",
    "#### 2️⃣ 원핫인코딩(One-Hot Encoding)\n",
    "* 범주형 변수를 이진 벡터(0과 1)로 변환\n",
    "* `pd.get_dummies(데이터프레임, columns=[컬럼 리스트])`: 명목변수를 0과 1로 원-핫 인코딩\n",
    "\n",
    "### 3-3-2. 구간화(binning)\n",
    "* **연속 데이터**를 **일정한 구간으로 나누어 분석**할 때 효율적인 경우가 있음.\n",
    "* 분석 목적과 방법 등 필요한 영역에 따라, 분석가의 도메인 지식을 최대한 활용하여 수행.\n",
    "* `pd.cut(데이터프레임['컬럼명'], bins=[나누는 기준 리스트], labels=[지정할 label])`\n",
    "---\n",
    "```python\n",
    "#binning\n",
    "count, bin_dividers = np.histogram(df[\"카테고리\"], bins=3) #3개의 구간으로 나눔 \n",
    "bin_names = [\"상\", \"중\", \"하\"]\n",
    "df[\"new_bins\"] = pd.cut(x=df[\"카테고리\"],\n",
    "                        bins = bin_dividers, # 경계값 리스트\n",
    "                        labels = bin_names, # bin 이름\n",
    "                        include_lowest = True) # 첫 경계값 포함\n",
    "```\n",
    "---\n",
    "\n",
    "\n",
    "### 3-3-3. 변환\n",
    "* 기존의 피처를 다른 피처로 변환하여 변수를 추가함\n",
    "* 기존 데이터의 특성 또는 다른 정보를 이용하여 다른 데이터로 변환 및 분석하기 위한 작업\n",
    "* 분석 목적과 방법 등 필요한 영역에 따라, 분석가의 도메인 지식을 최대한 활용하여 수행.\n",
    "* ex) `검수일자` 피처를 변환 -> `검수요일` 피처 추가\n",
    "\n",
    "### 3-3-4. 스케일링\n",
    "* 서로 다른 **변수의 값 범위**를 **일정한 수준으로 맞추는** 작업\n",
    "* 숫자의 상대적인 크기 차이로 인한 결과의 왜고고 방지\n",
    "* **정규화(Normalization) 수행**: 각 열(변수)에 속하는 데이터 값을 동일한 크기 기준으로 나눈 비율로 나타냄\n",
    "* 스케일링 전, **이상치 제거가 선행**되어야 함.\n",
    "* `sklearn 라이브러리`에서 다양한 종류의 스케일러를 제공함.\n",
    "\n",
    "#### 1️⃣ StandardScaler (표준화)\n",
    "* 각 피처의 평균을 0, 분산을 1로 변경\n",
    "* 모든 피처들이 같은 스케일을 갖게 됨\n",
    "* 정규분포를 따른다고 가정하는 기술에 적합함\n",
    "\n",
    "#### 2️⃣ MinMaxScaler\n",
    "* 모든 피처가 0과 1 사이에 위치하게 만듦\n",
    "* 데이터가 2차원 셋일 경우, 모든 데이터는 x축의 0과 1 사이 그리고 y축의 0과 1 사이에 위치하게 됨\n",
    "* 데이터가 서로 다른 비율의 속성으로 구성되어 있을 때, 같은 비율로 속성을 맞춤\n",
    "* 연산 속도를 높이고 알고리즘을 최적화하는 데에 효과적임\n",
    "\n",
    "#### 3️⃣ MaxAbsScaler\n",
    "\n",
    "#### 4️⃣ RobustSclaer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea5189",
   "metadata": {},
   "source": [
    "# 4. 시각화(Visualization)\n",
    "## 4-1. 시각화의 개념\n",
    "* 데이터나 정보를 시각적인 형태로 표현하는 과정 또는 결과물\n",
    "* 데이터 패턴, 관계, 추세 등을 쉽게 파악할 수 있음\n",
    "* `matplotlib 라이브러리`, `seaborn 라이브러리`를 주로 사용함.\n",
    "    * `matplotlib`: NumPy 라이브러리를 활용한 플로팅(그래프를 그리기 위한) 라이브러리\n",
    "    * `seaborn`: matplotlib을 기반으로 만들어져 통계 데이터 시각화에 최적화된 라이브러리\n",
    "\n",
    "## 4-2. 파라미터\n",
    "* 컴퓨터 프로그래밍에서 **매개변수(parameter)**란?\n",
    "    * 프로그래밍된 함수의 **입력값**\n",
    "* 함수를 내가 원하는 조건에 맞춰서 이용하기 위해 `파라미터=인자` 형식으로 전달함\n",
    "* `countplot(data=data, x='Survived', hue='Sex')`\n",
    "    * `hue` 파라미터: 성별(Sex)과 같은 **범주형 변수**를 넣어, 내가 원하는 변수를 기준으로 데이터를 구분하여 그래프에 표시해줄 수 있음. (그룹화 느낌?)\n",
    "## 4-3. 다양한 그래프 톺아보기\n",
    "### 4-3-1. boxplot(상자 수염 그림)\n",
    "* **boxplot**: 사분위수와 이상치를 보여주는 그래프\n",
    "\n",
    "### 4-3-2. 빈도수 확인: countplot, histplot\n",
    "* **countplot**: 범주형 변수의 빈도수 확인\n",
    "* **histplot**: 수치형 변수의 구간별 빈도수 확인 (도수분포표를 그래프로 나타낸 것)\n",
    "\n",
    "### 4-3-3. displot, kdeplot(커널밀도추정 그래프)\n",
    "* 히스토그램을 연속적으로 곡선으로 연결한 그래프\n",
    "* displot에서는 kde 파라미터에 True를 전달하여 곡선을 표현함\n",
    "\n",
    "### 4-3-4. barplot, pointplot\n",
    "* **barplot**: 범주형 데이터 값 x에 따른 수치형 데이터 값 y의 평균 값을 제공함\n",
    "* **pointplot**: 막대 그래프와 모양만 다르고 동일한 정보를 제공함\n",
    "* cf) Seaborn barplot()의 검은 선은 신뢰구간(Confidnece Interval, CI)\n",
    "    * 신뢰구간(CI)란?\n",
    "        * 막대의 평균 값을 얼마나 신뢰할 수 있는지를 나타내는 구간\n",
    "        * Seaborn은 기본적으로 95% 신뢰구간이 사용됨\n",
    "        * 선이 짧으면 데이터의 변동이 적고, 길면 변동이 큼\n",
    "\n",
    "### 4-3-5. scatterplot(산점도 그래프), regplot(회귀선이 추가된 산점도 그래프)\n",
    "* **scatterplot**: 두 변수 간의 관계를 시각화\n",
    "    * 각각의 데이터 포인트는 **두 변수의 값**을 나타냄\n",
    "    * x축, y축에 데이터 포인트를 분산하여 그림\n",
    "    * 변수 간의 패턴, 상관관계, 분포 등을 쉽게 파악할 수 있음\n",
    "* **regplot**: 두 연속 변수 간의 산점도를 회귀선과 함께 나타냄\n",
    "\n",
    "\n",
    "### 4-3-6. catplot\n",
    "* **caplot**: category plot, 수치형 데이터와 범주형 데이터의 관계를 볼 때 주로 사용함.\n",
    "\n",
    "### 4-3-7. pieplot\n",
    "* **pieplot**: 데이터의 부분과 전체 간의 비율을 표현하는 그래프 (원형)\n",
    "    * 주로 비율을 강조하기 위해 사용됨\n",
    "    * 모든 데이터가 합쳐서 전체를 이루는 경우에 효과적으로 활용 가능\n",
    "    \n",
    "### 4-3-8. heatmap\n",
    "* **heatmap**: 변수간 상관계수를 직관적으로 볼 수 있는 그래프\n",
    "    * `corr()`메서드 => 변수 간의 상관계수를 구하고, 이를 히트맵에 표현할 수 있음\n",
    "    ---\n",
    "    ```python\n",
    "    sns.heatmap(df.corr(), annot=True)\n",
    "    ```\n",
    "    ---\n",
    "* **상관계수**란: 두 수치형 변수 사이의 상관 관계의 정도를 수치적으로 나타낸 계수\n",
    "    * 두 변수간 서로 영향을 주는 정도를 나타내는 값\n",
    "    * -1과 1 사이의 값을 가짐\n",
    "    * -1과 1에 가까울수록 큰 상관계수를 가진다고 판단함\n",
    "* **음의 상관계수**: 하나가 커지면 다른 하나가 작아짐\n",
    "* **양의 상관계수**: 하나가 커지면 다른 하나도 커짐\n",
    "\n",
    "### 4-3-9. violinplot\n",
    "* **violinplot**: boxplot, 커널밀도추정 그래프(displot, kdeplot)을 합쳐 놓은 그래프\n",
    "    * boxplot을 violinplot으로 시각화하면 분포를 좀 더 정확하게 파악 가능\n",
    "    ---\n",
    "    ```python\n",
    "    sns.violinplot(x='class', y='age', hue='sex', data=data, split=True)\n",
    "    ```\n",
    "    ---\n",
    "### 4-3-10. 여러 그래프 한 번에 찍기, pairplot\n",
    "* **여러 그래프 한 번에 찍기**\n",
    "    * 각 그래프를 `ax[i]`에 할당하여 원하는 위치에 출력 가능\n",
    "---\n",
    "```python\n",
    "f, ax = plt.subplots(1, 2, figsize=(12, 4)) #1행 2열의 서브플롯 생성\n",
    "sns.countplot(x='Pclass', data=data, ax=ax[0])\n",
    "sns.barplot(data=data, x='Sex', y='Age', hue='Survived', ax=ax[1])\n",
    "```\n",
    "---\n",
    "* **pairplot**: 여러 변수 간의 산점도를 한 번에 보여주는 그래프\n",
    "---\n",
    "```python\n",
    "sns.pairplot(data=data, hue=\"Survived\")\n",
    "```\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

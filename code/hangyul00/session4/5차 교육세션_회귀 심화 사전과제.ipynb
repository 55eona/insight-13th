{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ee1036c-1f01-4c6d-88a6-0949513c195a",
   "metadata": {},
   "source": [
    "# 회귀 심화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec3ec6d-6834-4619-9c1f-e7fc53dd2fd4",
   "metadata": {},
   "source": [
    "## 회귀 복습\n",
    "\n",
    "지도학습: 정답으로 간주할 데이터가 있는 경우\n",
    "비지도학습: 정답으로 간주할 데이터가 없는 경우\n",
    "\n",
    "회귀: 연속적인 데이터에서 패턴을 찾아내는 통계적 방법\n",
    "\n",
    "종류: 선형회귀, 비선형회귀, (로지스틱회귀), 릿지회귀, 라쏘회귀, 다항회귀, 엘라스틱넷회귀\n",
    "\n",
    "활용: 데이터를 요약하고, 앞으로의 데이터를 예측, 시계열 모델링과 변수 간 인과관계 확인 등에 사용\n",
    "\n",
    "평가지표: MSE, MAE, R-square, Adjusted R-square, AIC, BC\n",
    "\n",
    "단순선형회귀분석 -> 하나의 독립변수만 존재\n",
    "\n",
    "다중선형회귀분석 -> 독립변수가 2개 이상 (최소한 평면의 차원으로 회귀선이 나타남)\n",
    "\n",
    "OLS - 최소제곱법(최소자승법): (회귀선의 예측값 - 관측된 데이터값)^2의 합을 최소화 하는 회귀선을 찾는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a77752-731b-450a-90e5-6b23d7b7cb57",
   "metadata": {},
   "source": [
    "## 1. 선형회귀\n",
    "\n",
    "회귀 분석의 프로세스\n",
    "1. 사전검증\n",
    "- 데이터 탐색 및 전처리: 결측치 처리, 이상치 처리\n",
    "- 회귀 분석의 기본 가정 6가지 검토\n",
    "\n",
    "2. 모델 생성 및 모델 fit\n",
    "- 회귀 모델 생성, 모델 설정, 모델 학습\n",
    "- 모델의 유의성 검정: F-검정, T-검정\n",
    "\n",
    "3. 모델 성능 평가\n",
    "- R-squared\n",
    "- 회귀 분석 후 검증 가능한 가설 검토\n",
    "\n",
    "4. 모델 성능 개선\n",
    "- 필요 없는 변수 제거\n",
    "- 비선형 모델 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e7570f-7bdd-45f5-b243-2ad1425a5c4d",
   "metadata": {},
   "source": [
    "### 다중선형회귀의 수식적 이해\n",
    "\n",
    "yi = β0 + β1x1i + β2x2i + ⋯ + βkxki + ϵ\n",
    "\n",
    "yi: i번째 종속 변수 (우리가 관심 있는 값)\n",
    "\n",
    "x1i, x2i, x3i, ... , xki: i번째 y에 대한 여러 개의 설명변수(독립변수)\n",
    "\n",
    "β0: 절편, 설명변수가 모두 0일때의 y값\n",
    "\n",
    "β1, β2, .... , βk: 설명변수(독립변수)에 의한 회귀계수 (각 변수 x의 영향력)\n",
    "-> 예를들어, y가 학점, x1=중간고사, x2=기말고사, x3=과제일때, y = 40x1+40x2+20x3라고 하면, 각 비율은 40,40,20%이고, 해당 값이 β1, β2, β3이다.\n",
    "\n",
    "ϵ: 오차항\n",
    "\n",
    "여기서 상수항과 오차항을 제외하면,\n",
    "y= w0x0 + w1x1 + ⋯ + wmxm으로 표현할 수 있다.\n",
    "\n",
    "결국, 선형회귀식은 종속변수 y에 대한 설명변수의 가중평균이다. 따라서, 설명변수에 가중치를 곱해서 더함으로써 y를 얼마나 잘 설명하는지를 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a460d5-f5b8-491b-8c2c-f6d27904bd7d",
   "metadata": {},
   "source": [
    "### 다중선형회귀의 기본가정\n",
    "\n",
    "가정1: 선형성\n",
    "- 종속변수와 설명변수 간의 관계가 선형적이어야 한다.\n",
    "- 회귀분석 전에 검증이 가능하며, 분석 후에도 검증이 가능하다.\n",
    "\n",
    "가정2: 독립성\n",
    "- 각각의 설명변수가 서로 선형독립적이어야 한다.\n",
    "- 선형독립적이지 않은 경우, '다중공선성'이 있다고 말한다. (VIF 확인, 히트맵 확인 등..)\n",
    "- 변수를 제거하거나, 규제선형모델, PCA를 활용한다.\n",
    "- 회귀분석 전에 검증이 가능하며, 분석 후에도 검증이 가능하다.\n",
    "\n",
    "가정3: 오차항의 평균은 0이다 (0에 가까워야 한다.)\n",
    "- 오차항: 실제 값과 예측 값 사이의 차이를 말한다.\n",
    "- 만약 오차항의 평균이 3이라면, 회귀 모델이 항상 실제값보다 3만큼 부족하거나, 넘치게 예측하는 문제가 발생한다. 즉, 모델이 데이터의 패턴을 올바르게 반영하지 못한다.\n",
    "- np.mean(residuals)을 통해서 검증한다.\n",
    "- 회귀분석 전에 검증이 가능하지 않고, 분석 후에만 검증이 가능하다.\n",
    "\n",
    "가정4: 등분산성\n",
    "- 오차항의 분산이 일정해야 한다.\n",
    "- 오차항의 분산이 일정하지 않은 경우, 이분산성이 있다고 할 수 있는데, 이 경우 일부 구간에서는 매우 정확하지만, 일부 구간에서는 오차가 매우 커질 수 있다. 따라서 등분산성을 만족해야 한다.\n",
    "- 등분산성을 알아보기 위해서는 잔차를 도표화하거나, 검정 (Brown-Forsythe, Breusch-Pagan검정)\n",
    "- 회귀분석 전에 검증이 가능하지 않고, 분석 후에만 검증이 가능하다.\n",
    "\n",
    "가정5: 오차항은 자기상관되어 있지 않다\n",
    "- 오차항의 공분산은 항상 0이어야 한다. (두 변수 간의 상관된 정보를 나타내는 지표)\n",
    "- 즉, 두 변수가 독립적이어 한다.\n",
    "- 오차항의 공분산이 0이 아닌 경우, 자기상관이 있다고 하는데, 이는 한 변수의 현재 값이 과거 값과 상관관계를 가지는 현상으로, 시계열자료에서 많이 나타난다.\n",
    "- 이렇게 되면, 이전 데이터의 패턴을 학습하여 반복적인 오류를 만들 가능성이 높다.\n",
    "- Durbin-Watson 검정을 통해 검증할 수 있다.\n",
    "- 회귀 분석 전에는 간접적으로만 검증이 가능하며, 분석 후에 최종적으로 검증한다.\n",
    "\n",
    "가정6: 정규성\n",
    "- 오차항이 정규분포를 따른다.\n",
    "- 위배되어도 다중선형회귀분석의 결과에 큰 영향을 주지는 않는다.\n",
    "- 샤피로-월크 검정, 자퀴-베라 검정, Q-Q plot을 통해 정규성을 확인할 수 있다.\n",
    "- 회귀분석 전에 검증이 가능하지 않고, 분석 후에만 검증이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4288a7-64c3-46f9-a9ee-f922a79fb3b8",
   "metadata": {},
   "source": [
    "### 회귀분석 평가방법\n",
    "\n",
    "1. 시각화\n",
    "- 전반적인 모습을 볼 수는 있지만, 어느 회귀선이 데이터를 더 잘 요약하는지 객관적으로 비교하기는 어렵다.\n",
    "- 따라서 통계지표를 활용하는 것이 좋다.\n",
    "\n",
    "2. 통계지표 (R-square와 이를 보완한 지표)\n",
    "- R-square, Adj.R-square, F-statistic, Prob (F-statistic), AIC, BIC\n",
    "\n",
    "모델의 유의성 검정 (F검정과 T검정 비교)\n",
    "1) F검정\n",
    "전체 모델이 검정 대상이며, 회귀 모델이 유의미한지 검정하기 위한 목적을 지닌다. 또한, p < 0.05면 회귀 모델이 유의미하다고 판단한다.\n",
    "2) T검정\n",
    "개별 변수들이 검정 대상이며, 특정 독립 변수가 유의미한지를 검정하는 목적을 지닌다. F검정과 마찬가지로 p < 0.05면 회귀 모델이 유의미하다고 판단한다.\n",
    "\n",
    "* F-statistic, Prob(F-statistic)\n",
    "- F-statistic은 회귀 모델이 유의미한지 검정하는 지표이다. (종속 변수 y와 전체 독립 변수 X의 관계가 통계적으로 유의미한지)\n",
    "- F-statistic의 값이 클수록 모델이 통계적으로 유의미하다는 것을 의미한다.\n",
    "- Prob(F-statistic)은 F-statistic의 p-value 값으로, 0.05보다 작다면 귀무가설을 기각할 수 있다.\n",
    "- 적어도 하나의 독립 변수가 종속 변수와 유의미한 관계를 갖고 있다 (=회귀모델이 유의미하다)\n",
    "\n",
    "* T-statistic\n",
    "- T-statistic은 각 독립변수가 종속 변수 y에 유의미한 영향을 미치는지 판단하는 지표다.\n",
    "- p-value 값을 기준으로 가설 검정을 수행한다.\n",
    "- 각 독립변수의 값을 확인할 때, p-value (p>|t|)값이 0.05보다 작으면 해당 변수가 유의미한 영향을 미친다는 의미이다.\n",
    "\n",
    "모델의 성능 평가 (R-squared, Adjusted R-squared, AIC, BIC)\n",
    "1) 결정계수 (R-squared)\n",
    "- 회귀 분석에서 모델이 설명하는 데이터의 총 변동(평균과의 차이) 중에서 설명된 비율을 나타낸다.\n",
    "- 데이터의 평균을 예측값으로 사용할 때보다, 모델을 사용할 때 얼마나 더 정확한 에측인지에 대한 지표\n",
    "- SST: 총 편차 / SSR: 회귀선에 의해 설명되는 편차 / SSE: 회귀선에 의해 설명되지 않는 편차\n",
    "- R^2 = SSR/SST = 1-(SSE/SST)\n",
    "- 모델이 데이터를 얼마나 잘 설명하는지 측정하는 지표로 0과 1 사이의 값으로 나타난다.\n",
    "- 1에 가까울수록 SSR과 SST의 값이 비슷해지고, SSE는 0에 가까워지므로 데이터를 잘 설명한다고 볼 수 있다.\n",
    "- 값이 0이라면 모델이 데이터를 전혀 설명하지 못한다고 할 수 있다.\n",
    "\n",
    "2) 조정된 결정 계수 (Adjusted R-squared, Adjusted R^2)\n",
    "- R^2는 독립 변수의 개수가 증가하면 증가할수록 자연스레 증가하는데, 데이터와 큰 관련성이 없는 변수를 추가해도 커진다.\n",
    "- 따라서 변수의 개수 증가에 덜 민감하도록 조정한 지표가 조정된 결정 계수이다.\n",
    "- R^2 = (SSR/SST)*((n-1)/(n-k)) = 1 - (SSE/(n-k))/(SST/(n-1))\n",
    "- n: 샘플 수(데이터 개수) / k: 독립 변수의 개수\n",
    "- 여기서 k가 증가하면 전체 값은 감소하게 된다. 따라서 변수 개수에 따른 설명력의 추가부분을 상쇄할 수 있다.\n",
    "- 변수를 추가했을 때, SSE가 충분히 감소하면, 결국, (SSE/(n-k))의 값이 작아지므로 R^2의 값은 증가한다.\n",
    "- 변수를 추가했을 때, SSE가 그대로라면, (SSE/(n-k))에서 k만 증가하므로 분자 값이 커지고 R^2의 값은 감소한다.\n",
    "\n",
    "3) AIC, BIC(SC)\n",
    "- 두 지표 모두 정보기준이라고도 불리며, 값이 낮을수록 좋다고 평가한다.\n",
    "- AIC = Akaike information criterion\n",
    "- BIC에 비해 복잡성에 대한 페널티가 비교적 작다.\n",
    "- BIC(SC): SC = Schwarz Criterion, BIC = Bayesian Information Criterion\n",
    "- AIC보다 엄격한 기준으로, 데이터 양에 따라 더 강한 페널티를 부과한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75df699b-eb11-4cb9-a73e-1c556613583a",
   "metadata": {},
   "source": [
    "# 2. 비선형 회귀\n",
    "\n",
    "데이터셋의 분포가 선형적이지 않은 경우에는 비선형적인 식을 작성하면 된다.\n",
    "\n",
    "1) 다항식 회귀모델\n",
    "- 기존의 선형 회귀는 Y = a + bX이지만, 다항식 회귀 모델은 Y = a + bX + cX^2 + dX^3 + ...의 형태로, 독립변수에 거듭제곱 항을 추가하여 데이터의 곡선적(비선형적) 특성을 모델링한다.\n",
    "- 선형 모델에 비해 회귀선을 잘 fit하도록 그릴 수 있지만, 과적합 될 수 있다.\n",
    "- 관계가 직선적이지 않고, 곡선을 그리는 데잍어 패턴에서 유용하다 (성장률, 감소율 등이 시간에 따라 변화하는 속도가 다른 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f5819-d899-4537-9d41-e28c9f0bae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)   #기존의 변수를 다항식으로 만드는 코드\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_poly = sm.add_constant(X_poly)\n",
    "model = sm.OLS(Y, X_poly).fit()\n",
    "Y_pred = model.predict(X_poly)   # statsmodels의 sm을 활용하는 방법\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LInearRegression()\n",
    "model.fit(X_poly, Y)\n",
    "Y_pred = model.predict(X_poly)   # sklearn의 LinearREgression 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a089815-2556-4dc1-8a44-7f08016e3075",
   "metadata": {},
   "source": [
    "2. 지수 회귀모델\n",
    "- 종속변수가 지수적으로 변화하는 관계를 모델링할 때 사용\n",
    "- 지수함수 형태의 데이터는 Y = ae^bX의 수식을 따른다.\n",
    "- 이때, 양변에 로그를 취하면 ln Y = ln a + bX가 된다. 이때, ln Y를 Y'로, ln a를 a'로 보면, Y' = a'+bX가 되므로 선혀오히귀식과 비슷하게 생기게 된다. (즉, 지수 모델은 종속 변수 Y에 로그를 취한 후 선형회귀를 적용하면 된다.)\n",
    "- 따라서, 1) 종속 변수 Y에 로그함수 적용, 2) 로그 변환된 Y와 기존의 독립변수 X에 대해 선형회귀 적용, 3) Y값을 예측시, 모델이 예측한 Y값에 지수함수를 적용하여 로그변환하기 전 Y로 변환\n",
    "- 값이 시간에 따라 지수적으로 증가하거나, 감소하는 경우에 적합하다 (기술발전, 투자수익률 증가 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2065c-b685-4643-a174-360cf1ba3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.linspace(1, 10, 20). reshape(-1, 1)\n",
    "Y = 2 * np.exp(0.8 * X).flatten() + np.random.normal(0, 10, X.shape[0])\n",
    "\n",
    "log_Y = np.log(Y)  #종속변수 Y에 자연로그 변환\n",
    "\n",
    "X_const = sm.add_constant(X)\n",
    "model = sm.OLS(log_Y, X_const).fit()  #회귀모델 학습\n",
    "\n",
    "log_Y_pred = model.predict(X_const)\n",
    "Y_pred = np.exp(log_Y_pred)\n",
    "\n",
    "plt.scatter(X, Y, label=\"Actual Data\", color=\"blue\")\n",
    "plt.plot(X, Y_pred, label=\"exponential Fit\", color=\"red\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend()\n",
    "plt.title(\"Exponential Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e81dda-0a6b-42b6-b8af-88f57f467946",
   "metadata": {},
   "source": [
    "3. 로그 회귀모델\n",
    "- 종속변수와 독립변수 간의 관계가 로그함수를 통해 더 잘 표현될 때 사용할 수 있다.\n",
    "- 로그함수 형태의 데이터는 Y = a + b log(X)의 ㅜ식을 따른다. 이는 X 자리에 log(X)가 들어간 것이다. 따라서, 독립 변수 X에 로그 연산을 한 후, 나머지 과정은 선형회귀와 동일하다.\n",
    "- 이렇게 예측된 값은 Y값이므로, 예측값에 별도처리를 하지않고 그대로 사용할 수 있다.\n",
    "- 데이터가 초기에 빠르게 증가하고, 점차 증가율이 줄어드는 패턴을 보일 때 효과적이다. (연구 성장, 감염병의 확산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b3232-8def-453f-9acd-7839ade91d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.linspace(1, 10, 20).reshape(-1,1)\n",
    "Y = 5 + 3 *np.log(X).flatten() + np.random.normal(0, 0.5, X.shape[0])\n",
    "\n",
    "log_X = np.log(X)\n",
    "\n",
    "log_X_const = sm.add_constant(log_X)\n",
    "model = sm.OLS(Y, log_X_const).fit()\n",
    "\n",
    "Y_pred = model.predict(log_X_const)\n",
    "\n",
    "plt.scatter(X, Y, label=\"Actual Data\", color=\"blue\")\n",
    "plt.plot(X, Y_pred, label=\"Logarithmic Fit\", color=\"red\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Logarithmic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bbb873-6cf6-4f2b-98ea-7a3a7596c681",
   "metadata": {},
   "source": [
    "4. 스플라인 회귀\n",
    "- 데이터를 구간별로 나누고, 각 구간에서 다른 선형 또는 비선형 함수를 적용하여 예측하는 방식이다.\n",
    "- 전체 데이터 범위를 여러 구간으로 나누고, 각 구간에 대해 별도의 회귀모델을 적용한다.\n",
    "- 구간 경계에서 연속성을 유지하는 것이 중요!\n",
    "- 데이터 패턴에 여러 구간에서 서로 다르게 나타날 때 유용하다. (계절에 따라 판매량 변화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b4d4d7-687f-4128-b3b4-29356f8ba18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from patsy import dmatrix\n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(42)\n",
    "X - np.linspace(0, 10, 100)\n",
    "Y = np.sin(X) + np.random.normal(0, 0.2, size+X.shape)\n",
    "\n",
    "X_spline = dmatrix(\"bs(X, df=5, degree=3, include_intercept=False)\", (\"X\": X), return_type='dataframe')\n",
    "\n",
    "model_spline = sm.OLS(Y, X_spline).fit()\n",
    "Y_pred_spline = model_spline.predict(X_spline)\n",
    "\n",
    "plt.scatter(X, Y, label=\"Actual Data\", color=\"blue\", aplha=0.5)\n",
    "plt.plot(X, Y_pred_spline, label=\"Cubic Spline Regression\", color=\"red\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend()\n",
    "plt.title(\"Cubic Spline Regression Fit\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

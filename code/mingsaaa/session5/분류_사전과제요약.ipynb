{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9365e6b6-1b2d-46d9-8b66-26a734316210",
   "metadata": {},
   "source": [
    "# 분류란?\n",
    "\n",
    "## 1. 머신러닝: 지도 학습과 비지도 학습\n",
    "\n",
    "**머신러닝**은 인공지능의 한 분야로, 컴퓨터가 스스로 학습하여 데이터를 분석하고, 분석 결과를 기반으로 판단이나 예측을 하도록 돕는 기술입니다. 머신러닝의 종류는 다음과 같습니다:\n",
    "\n",
    "- **지도 학습**: 문제와 정답을 모두 알려주고 학습시키는 방법\n",
    "- **비지도 학습**: 정답을 알려주지 않고 패턴을 학습시키는 방법\n",
    "- **강화 학습**: 보상과 벌을 통해 최적의 결과를 찾아가는 방법\n",
    "\n",
    "| 정답 여부       | 방식                | 예시                                  |\n",
    "|-----------------|---------------------|---------------------------------------|\n",
    "| 지도 학습      | 정답(label)이 있는 데이터 사용 | 회귀, 분류                           |\n",
    "| 비지도 학습     | 정답(label)이 없는 데이터 사용 | 군집화                               |\n",
    "| 강화 학습       |                     | 알파고                               |\n",
    "\n",
    "## 2. 지도 학습: 회귀와 분류\n",
    "\n",
    "**지도 학습**은 입력값과 정답(label)을 함께 주고 학습시키는 방법입니다. 주어진 예측값(prediction)과 정답(label)이 최대한 같아지도록 학습합니다.\n",
    "\n",
    "### 과정\n",
    "- **labeled data**: **독립변수(feature)**와 **종속변수(target/label)**가 모두 존재하는 데이터. 입력 데이터와 그에 대응하는 출력값이 있는 데이터를 의미합니다.\n",
    "- 데이터를 **training set**과 **test set**으로 나누어 학습을 진행합니다.\n",
    "- **Training set**을 통해 모델을 학습하고, 기계가 예측한 값이 주어진 정답과 비슷하도록 지도(supervise)합니다.\n",
    "\n",
    "### 1) 회귀 (Regression)\n",
    "- **회귀**는 연속형 변수의 예측을 목표로 합니다.\n",
    "- 예시: 주택 가격 예측\n",
    "  - **종속변수**: 주택 가격\n",
    "  - **독립변수**: 주택 평수, 역까지의 거리, 지역의 평균 소득\n",
    "\n",
    "### 2) 분류 (Classification)\n",
    "- **분류**는 데이터를 특정 범주에 속하는지 판별하는 문제입니다.\n",
    "- 예시: 대출상환여부 예측\n",
    "  - **종속변수**: 대출상환여부 (0/1)\n",
    "  - **독립변수**: 고객 특성, 대출 특성\n",
    "  - 이메일 스팸 여부, 종양 악성 여부 등도 분류에 해당\n",
    "\n",
    "### 회귀와 분류의 차이\n",
    "\n",
    "- **회귀**: 연속형 변수를 예측할 때 사용됩니다.\n",
    "- **분류**: 범주형 변수를 예측할 때 사용됩니다.\n",
    "\n",
    "### 분류에 사용되는 대표적인 머신러닝 알고리즘\n",
    "1. **로지스틱 회귀 (Logistic Regression)**: 독립변수와 종속변수의 선형 관계 기반 분류\n",
    "2. **결정 트리 (Decision Tree)**: 데이터 균일도에 따른 규칙 기반 분류\n",
    "3. **서포트 벡터 머신 (SVM)**: 클래스 간의 최대 마진을 찾아 분류\n",
    "4. **최소 근접 (Nearest Neighbor)**: 근접 거리 기준으로 분류\n",
    "\n",
    "## 3. 이진 분류와 다중 분류\n",
    "\n",
    "- **이진 분류 (Binary Classification)**: 예측하려는 값이 두 개의 범주(참 또는 거짓)로 나누어지는 분류\n",
    "- **다중 분류 (Multiclass Classification)**: 예측하려는 값이 세 개 이상의 범주로 나누어지는 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a231b7fd-b889-4047-9b2d-c55afd3249ff",
   "metadata": {},
   "source": [
    "# 분류 모델\n",
    "\n",
    "## 1. 로지스틱 회귀 (Logistic Regression)\n",
    "\n",
    "**로지스틱 회귀**는 이진 분류 문제를 해결하는 대표적인 알고리즘입니다. 샘플이 특정 클래스에 속할 확률을 추정하는 것을 목표로 합니다.\n",
    "\n",
    "- **정의**: 독립 변수의 선형 조합에 로지스틱 함수를 적용하여 출력값을 0에서 1 사이로 변환합니다.\n",
    "- **시그모이드 함수**: 출력이 0과 1 사이의 값을 가지며 S자 형태로 그려집니다. 이를 통해 이진 분류 문제를 해결할 수 있습니다.\n",
    "\n",
    "**시그모이드 함수 수식**:\n",
    "$$ H(x) = \\frac{1}{1+e^{-(wx+b)}} = sigmoid(wx+b) $$\n",
    "\n",
    "로지스틱 회귀는 이메일 스팸 여부, 질병 유무 등의 이진 분류 문제에 적합합니다.\n",
    "\n",
    "## 2. 결정 나무 (Decision Tree)\n",
    "\n",
    "**결정 나무**는 조건에 따라 데이터를 분류하며, 최종적으로 순수한 label의 집합으로 분류가 완료될 때까지 분류를 반복합니다.\n",
    "\n",
    "### 용어 정리:\n",
    "- **Root Node**: 결정 나무의 시작 노드\n",
    "- **Edge**: 노드 간 연결\n",
    "- **Leaf Node**: 트리의 끝에 있는 노드, label을 가짐\n",
    "- **Height**: 트리의 깊이\n",
    "- **Level**: 노드의 절대적인 위계\n",
    "- **Parent/Child**: 상대적으로 높은/낮은 위계의 노드\n",
    "\n",
    "### CART (Classification And Regression Tree) 알고리즘:\n",
    "- **임계값 설정**: 데이터를 기준으로 두 자식 노드로 분할\n",
    "- **불순도 감소**: 불순도(지니 계수)를 최소화하는 방향으로 분할\n",
    "\n",
    "**Pruning**: 불필요한 노드를 제거하여 과적합을 방지하고 모델의 일반화 성능을 높입니다.\n",
    "\n",
    "## 3. 서포트 벡터 머신 (SVM)\n",
    "\n",
    "**서포트 벡터 머신(SVM)**은 클래스를 분류할 수 있는 최적의 경계선을 찾는 알고리즘입니다. 고차원 데이터에서 효과적으로 사용될 수 있습니다.\n",
    "\n",
    "- **구성 요소**:\n",
    "  - **Support Vector**: 분리선과 가장 가까운 포인트\n",
    "  - **Decision Boundary**: 집단을 구분하는 선\n",
    "  - **Margin**: 선과 데이터 점 사이의 거리\n",
    "\n",
    "SVM은 margin(거리)을 최대화하여 최적의 분리선을 찾습니다.\n",
    "\n",
    "## 4. KNN (K-Nearest Neighbor)\n",
    "\n",
    "**KNN**은 데이터의 거리를 기반으로 분류하는 알고리즘으로, 비슷한 특성을 가진 데이터가 가까이에 있다는 가정에 기반합니다.\n",
    "\n",
    "### 계산 순서:\n",
    "1. **데이터 준비**: 데이터는 특성 벡터와 레이블로 구성됩니다.\n",
    "2. **K 값 설정**: 가장 가까운 이웃의 개수를 설정합니다.\n",
    "3. **거리 계산**: 예측하려는 데이터와 기존 데이터를 비교하여 거리를 계산합니다.\n",
    "4. **K개의 이웃 선택**: 가장 가까운 K개의 데이터를 선택합니다.\n",
    "5. **분류하기**: K개의 이웃 중 가장 많이 등장하는 클래스를 예측 결과로 반환합니다.\n",
    "\n",
    "### 장단점:\n",
    "- **장점**:\n",
    "  - 훈련이 필요하지 않음\n",
    "  - 정보 손실 없음\n",
    "- **단점**:\n",
    "  - 계산 시간이 오래 걸릴 수 있음\n",
    "  - 이상치에 민감함\n",
    "\n",
    "KNN은 테스트 시점에서 연산이 적은 것이 유리합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d3109-b3c9-485e-89b4-2b85e5957792",
   "metadata": {},
   "source": [
    "# 분류 평가 지표\n",
    "\n",
    "## 1. 혼동 행렬 (Confusion Matrix)\n",
    "혼동 행렬은 분류 모델의 예측 결과를 정확한 예측과 잘못된 예측으로 구분하여 나타낸 표입니다.  \n",
    "- **True Positive (TP)**: 실제 참, 참으로 예측  \n",
    "- **True Negative (TN)**: 실제 거짓, 거짓으로 예측  \n",
    "- **False Positive (FP)**: 실제 거짓, 참으로 예측 (예측 오류)  \n",
    "- **False Negative (FN)**: 실제 참, 거짓으로 예측 (예측 오류)\n",
    "\n",
    "### 혼동 행렬 요약\n",
    "- T: 모델이 정답을 맞췄다\n",
    "- F: 모델이 정답을 맞추지 못했다.\n",
    "- P: 모델이 참(양성)으로 예측했다.\n",
    "- N: 모델이 거짓(음성)으로 예측했다.\n",
    "\n",
    "### 분류 모델 평가 지표\n",
    "1. **정확도 (Accuracy)**: 모델이 입력된 데이터에 대해 얼마나 정확하게 예측하는지를 나타냅니다.\n",
    "   - **공식**: (TP + TN) / (TP + TN + FP + FN)\n",
    "   - **단점**: 레이블 불균형 문제 시 정확도를 신뢰할 수 없음\n",
    "\n",
    "2. **정밀도 (Precision)**: 참이라고 예측한 경우 실제 참의 비율\n",
    "3. **재현도 (Recall)**: 실제로 참인 경우 중 참으로 예측하는 비율\n",
    "\n",
    "## 2. 정밀도와 재현도 예시\n",
    "- **암 환자 판단**: FN을 줄여야 하므로 재현율(Recall)을 높여야 함. → Threshold를 낮춤\n",
    "- **스팸 메일 분류기**: FP를 줄여야 하므로 정밀도(Precision)를 높여야 함. → Threshold를 높임\n",
    "\n",
    "### Precision과 Recall의 Trade-off\n",
    "- **Threshold 낮추면**: Positive 예측이 늘어남 → Recall 증가, Precision 감소\n",
    "- **Threshold 높이면**: Positive 예측이 줄어듬 → Recall 감소, Precision 증가\n",
    "\n",
    "## 3. F1-Score\n",
    "- **F1-Score**: 정밀도(Precision)와 재현율(Recall)의 조화 평균\n",
    "- F1-Score는 두 지표의 균형을 평가하여 모델 성능을 효과적으로 평가하는 주요 지표입니다.\n",
    "\n",
    "## 4. ROC / AUC Curve\n",
    "\n",
    "### ROC Curve\n",
    "- **ROC Curve**: 분류 성능을 평가하는 그래프\n",
    "  - **True Positive Rate (TPR)**: 참인 것들 중에 참이라고 예측한 비율 (= Recall)\n",
    "  - **False Positive Rate (FPR)**: 거짓인 것들 중에 참이라고 잘못 예측한 비율\n",
    "\n",
    "### AUC Curve\n",
    "- **AUC (Area Under the Curve)**: ROC Curve 아래의 면적(적분값)\n",
    "  - **AUC 값**: 0에서 1 사이의 값. 1에 가까울수록 성능이 좋음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8089dda5-6bca-4f4f-9da8-eb12cca36a60",
   "metadata": {},
   "source": [
    "# 하이퍼파라미터 최적화\n",
    "\n",
    "## 1. 하이퍼파라미터\n",
    "- **하이퍼파라미터**: 학습 시작 전에 사용자가 설정하는 변수\n",
    "- **하이퍼파라미터 최적화**: 적절한 하이퍼파라미터를 찾아 모델 성능을 향상시키는 과정\n",
    "- **예시**: \n",
    "  - Decision Tree의 `max_depth`\n",
    "  - Random Forest의 `n_estimators`\n",
    "\n",
    "### 하이퍼파라미터 최적화 과정\n",
    "1. **Hyperparameter 탐색 범위 설정**: 최적 값을 찾고 싶은 하이퍼파라미터의 범위 설정\n",
    "2. **평가 지표 계산 함수 정의**: 하이퍼파라미터를 인수로 받아 성능 평가 함수 정의\n",
    "3. **검증 데이터로 평가**: 샘플링한 하이퍼파라미터 값을 사용하여 정확도 평가\n",
    "4. **반복적으로 범위 좁힘**: 정확도 결과를 보고 하이퍼파라미터의 범위 좁힘\n",
    "\n",
    "## 2. 하이퍼파라미터 최적화 방법\n",
    "\n",
    "### 1) Grid Search\n",
    "- **설명**: 정해진 범위에서 모든 하이퍼파라미터를 순회하며 최적값을 찾는 기법\n",
    "- **장점**: 범위가 넓고 step이 작을수록 최적해를 정확히 찾을 수 있음\n",
    "- **단점**: 시간이 오래 걸림\n",
    "- **적용**: 넓은 범위, 큰 step을 활용해 범위를 좁힌다\n",
    "\n",
    "### 2) Random Search\n",
    "- **설명**: 정해진 범위에서 하이퍼파라미터를 무작위로 탐색하여 최적값을 찾는 기법\n",
    "- **장점**: Grid Search보다 빠름\n",
    "- **단점**: 무작위 탐색으로 인해 정확도가 떨어질 수 있음\n",
    "\n",
    "### 3) Bayesian Optimization\n",
    "- **설명**: 사전 정보를 바탕으로 하이퍼파라미터 값을 확률적으로 추정하며 탐색하는 기법\n",
    "- **특징**: \n",
    "  - **Gaussian Process** 기반\n",
    "  - **Acquisition Function**을 적용하여 최적값을 찾을 확률이 높은 지점 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e3d2cb-00f1-4d28-83d6-057f5194576e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

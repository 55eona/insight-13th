{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07770a5c-fa40-4302-a689-d1ced7a43981",
   "metadata": {},
   "source": [
    "# 1. 분류란?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96287dc5-3636-48e3-821e-aa9f8ccd369f",
   "metadata": {},
   "source": [
    "## 1.1 머신러닝\n",
    "\n",
    "### [머신러닝이란?]\n",
    "인공지능의 한 분야로, \n",
    "머신러닝에서 컴퓨터는 \n",
    "1) **알고리즘**을 이용하여 데이터를 분석\n",
    "2) 분석결과를 **스스로 학습**\n",
    "3) 학습 내용으로 기반으로 **판단이나 예측** 진행\n",
    "\n",
    "### [지도학습, 비지도학습]\n",
    "머신러닝 종류|정답 여부|방식|예시\n",
    "-------------|---------|----|-----\n",
    "**지도학습**|정답(label)이 **있는** 데이터 사용|예측값을 이미 존재하는 **정답과 같아지도록** 기계를 학습|회귀, 분류\n",
    "**비지도학습**|정답(label)이 **없는** 데이터 사용|데이터 속 **패턴**이나 데이터 간의 **유사도**를 기계가 학습|군집화\n",
    "**강화학습**| ~~ |시행착오를 반복하여 정답을 찾는 과정|알파고\n",
    "\n",
    "\n",
    "## 1.2 지도학습\n",
    "\n",
    "### [지도학습]\n",
    "입력값과 결과값을 같이 주고, **예측값(prediction)**과 **정답(label)**이 최대한 같아지도록 학습 진행<BR>\n",
    "반복학습을 통해 오류를 줄어나감\n",
    "\n",
    "### [회귀와 분석]\n",
    "\n",
    "#### 회귀\n",
    "  - 주어진 데이터(X)를 기반으로 정답(Y)을 잘 맞추는(fit) 함수를 찾는 방법\n",
    "  - 종속변수: **연속형**\n",
    "\n",
    "#### 분류\n",
    "  - 주어진 데이터가 **어떤 레이블에 속하는지 패턴**을 알고리즘으로 인지한 뒤, 새로운 데이터에 대한 **레이블을 판별**\n",
    "  - 종속변수: **범주형**\n",
    "\n",
    "## 1.3 이진 분류와 다중 분류\n",
    "- **이진 분류**: 종속변수가 True/False 값만 가짐\n",
    "- **다중 분류**: 종속변수가 3개 이상의 값을 가짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159ee004-71b6-4e4a-a72d-2bbb30fee2c3",
   "metadata": {},
   "source": [
    "# 2. 분류모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3b3387-2676-44b9-8417-8d1088d142cd",
   "metadata": {},
   "source": [
    "## 2.1 로지스틱 회귀\n",
    "- 특정 클래스에 속할 확률을 추정하는 알고리즘\n",
    "- 독립변수의 선형 조합에 대해 출력값을 0에서 1사이로 변환해줌 ==> 이진 분류 문제 해결\n",
    "- 이진 분류는 다중 선형 회귀로 풀 수 없음\n",
    "\n",
    "### [시그모이드 함수 (=로지스틱 함수)]\n",
    "$$H(x)=\\frac{1}{1+e^{-(wx+b)}}=sigmoid(wx+b)=\\sigma(wx+b)$$\n",
    "- 출력이 0과 1사이 값을 가지면서 S자 형태로 그려짐 ==> 이진 분류 문제 해결에 적합\n",
    "- 입력값이 커지면 1에 수렴, 입력값이 작아지면 0에 수렴\n",
    "- 인공지능은 주어진 데이터에 대한 적합한 가중치 $w$와 $b$를 구함\n",
    "\n",
    "\n",
    "## 2.2 결정 나무(Decision Tree)\n",
    "- 조건에 따라 데이터를 분류하는 모델\n",
    "- 순수한 label의 집합으로 구성될 때까지 분류를 반복\n",
    "- 용어 정리\n",
    "  - Root Node: 결정나무의 시작이 되는 노드\n",
    "  - Edge: 노드와 노드를 연결하는 길목\n",
    "  - Leaf Nodes: 결정나무의 마지막 노드, 모델에서 label에 해당\n",
    "  - Height(depth): 결정나무의 깊이, 클수록 구조가 복잡함\n",
    "  - Level: 노드의 절대적인 위계, Root Node의 level = 0, Leaf Node의 level = height - 1\n",
    "  - Parent: 상대적으로 높은 위계의 노드\n",
    "  - Child: 상대적으로 낮은 위계의 노드\n",
    "  - Binary Tree(이진 트리):Child가 최대 2개인 결정나무\n",
    " \n",
    "### [CART 알고리즘 (Classification And Regression Tree)]\n",
    "- 데이터셋을 **임계값**을 기준으로 **두 Child로 나누는** 알고리즘\n",
    "- 임계값은 불순도(지니계수)가 낮아지는 방향으로 나눔\n",
    "- **불순도**: 데이터 집합에 다른 클래스가 섞여 있는 정도\n",
    "- 주요 단계\n",
    "  1. 임계값 설정\n",
    "  2. 불순도 감소 알고리즘\n",
    "\n",
    "### [실제 학습 시 고려해야 할 것]\n",
    "\n",
    "#### Parameter 설정\n",
    "  - `min_samples_split`: 분할되기 위해 노드가 가져야 하는 최소 샘플 수\n",
    "  - `min_samples_leaf`: 리프 노드가 가지고 있어야 하는 최소 샘플 수\n",
    "  - `min_weight_fraction_leaf`: `min_samples_leaf`와 기능이 같지만, 가중치가 부여된 전체 샘플 수에서의 비율\n",
    "  - `max_leaf_nodes`: 리프 노드의 최대 개수\n",
    "  - `max_features`: 각 노드에서 분할에 사용되는 특성(feature)의 최대 수\n",
    "#### 시각화\n",
    "  - 시각화를 통해 분류가 일어난 정도를 확인 할 수 있음\n",
    "\n",
    "#### Prunning (가지치기)\n",
    "  - 불필요한 노드를 치우는 과정을 의미\n",
    "  - height를 줄이고, 결과의 개수가 줄어듦\n",
    "  - 노드가 너무 많아지면(height가 너무 커지면), 과적합 가능성이 존재 ==> purning을 통해 일반화 성능을 높일 수 있음\n",
    "\n",
    "## 2.3 서포트 벡터 머신 (SVM)\n",
    "- 클래스를 분류하는 최적의 경계선을 찾는 알고리즘\n",
    "- 구성\n",
    "  - Support vector: 구분하는 선과 가장 가까운 포인트\n",
    "  - Desicion Boundary(결정 경계): 집단을 구분하는 선\n",
    "  - Margin: 선과 각 점의 거리\n",
    "- **Margin이 가장 클 때** ==> 최적의 선!\n",
    "\n",
    "## 2.4 KNN (K-Nearest Neighbor)\n",
    "- 거리가 가까운 k개의 다른 데이터 레이블을 참조하여 분류하는 알고리즘\n",
    "- 계산 순서\n",
    "  1. 데이터 준비\n",
    "     - KNN은 미리 **학습하는 과정 X**\n",
    "  3. K값 설정\n",
    "     - K는 가장 가까운 이웃의 개수를 나타냄\n",
    "     - 보통 **홀수**개로 설정\n",
    "  5. 거리 계산\n",
    "     - 새로운 데이터와 기존 모든 데이터간의 거리 계산\n",
    "     - 유클리드, 맨해튼 거리 등 사용\n",
    "  7. 가장 가까운 K개의 이웃 선택\n",
    "     - 가장 작은 거리 값을 가진 K개의 데이터 선택\n",
    "  9. 분류하기\n",
    "      - K개의 이웃 중 가장 많이 등장하는 클래스가 예측결과\n",
    "- 장점\n",
    "  - 훈련 필요 X\n",
    "  - 정보 손실 X\n",
    "- 단점\n",
    "  - 쿼리 처리에 시간 오래 소요\n",
    " \n",
    "## 앙상블 (참고)\n",
    "- 여러개의 개별 분류모델들을 병렬 또는 직렬로 결합하여 실행하 머신러닝 기법\n",
    "- **보팅**: **다른** 알고리즘의 모델을 **병렬**로 사용\n",
    "- **배깅**: **동일** 알고리즘의 모델을 **병렬**로 사용\n",
    "- **부스팅**: **동일** 알고리즘의 모델을 **직렬(순차적)**로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365061f5-eff9-41d8-88b0-f41a39989d5d",
   "metadata": {},
   "source": [
    "# 3. 분류 평가 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81777daf-7186-4873-bc70-79e505974f23",
   "metadata": {},
   "source": [
    "## 3.1 혼동 행렬\n",
    "- 예측결과를 정확한 예측과 잘못된 예측으로 구분하여 나타낸 표\n",
    "- 경우의 수\n",
    "  - True Positive(TP): 실제로 참, 참으로 예측\n",
    "  - True Negative(NP): 실제로 거짓, 거짓으로 예측\n",
    "  - False Postive(FP): 실제로 거짓, 참으로 예측\n",
    "  - Fasle Negative(FN): 실제로 참, 거짓으로 예측\n",
    "  - True --> 예측 성공 / False --> 예측 실패\n",
    "  - Positive --> 참으로 예측 / Negative --> 거짓으로 예측\n",
    "\n",
    "### [혼동행렬 이용한 분류모델 평가 지표]\n",
    "\n",
    "#### **Accuracy (정확도)**\n",
    "$$\\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "- 얼마나 정확하게 예측하는지 평가\n",
    "\n",
    "#### **Recall (정밀도)**\n",
    "$$\\frac{TP}{TP+FP}$$\n",
    "- 참으로 예측한 경우 중, 실제 참의 비율 <=> 거짓을 참으로 판단한 정도 알 수 있음\n",
    "- 정밀도 높을수록, 거짓을 참으로 예측한 정도가 낮음\n",
    "\n",
    "#### **Precision (재현도)**\n",
    "$$\\frac{TP}{TP+FN}$$\n",
    "- 실제 참일 때, 참으로 예측한 비율 <=> 참으로 거짓으로 판단한 정도 알 수 있음\n",
    "- 재현도 높을수록, 참을 거짓으로 예측한 정도 낮\n",
    "\n",
    "#### Precision과 Recall의 Trade-off 관계\n",
    "- 경곗값(Threshold, 임계값): 분류를 할 때, Threshold가 넘으면 참, Threshold 미만이면 거짓으로 판단\n",
    "- 경곗값(Threshold) 조절을 통해 Precision과 Recall 조정할 수 있음\n",
    "  - 경곗값 Down --> Positive 예측 Up --> recall Up, precision Down\n",
    "  - 경곗값 Up --> Positive 예측 Down --> recall Down, precision Up\n",
    "- 모델의 종류와 역할에 따라, Precision과 Recall 중 중요한 지표가 달라짐\n",
    "\n",
    "#### 정밀도(Recall) & 재현도(Precision) 그래프\n",
    "- 정밀도&재현도 그래프에서 두 value값이 만나는 지점으로 Threshold로 정하면, 예측 오류를 최소화할 수 있음\n",
    "\n",
    "## 3.2 F1-Score\n",
    "$$F1 Score = \\frac{2}{{1/Precision}+{1/Recall}}=\\frac{2\\times Precision\\times Recall}{Precision+Recall}$$\n",
    "- precision(정밀도)와 recall(재현율)의 조화평균\n",
    "\n",
    "## 3.3 ROC/AUC Curve\n",
    "#### ROC Curve\n",
    "- 얼마나 잘 분류가 되었는지를 보여주는 그래프\n",
    "- True Positive Rate(TPR): 실제 참이고, 참으로 예측한 비율 (=Recall)\n",
    "- False Positive Rate(FPR): 실제 거짓이고, 참으로 잘못 예측한 비율\n",
    "- 좌상단으로 붙어있을 수록, 좋은 모델\n",
    "\n",
    "#### AUC Curve\n",
    "- ROC와 x축 사이의 면적(적분값)\n",
    "- 0 ~ 1 값을 가지고 1에 가까울수록, 분류 성능이 좋다고 판단\n",
    "\n",
    "## 3.4 다중 분류 평가 지표 (참고)\n",
    "- **Macro average**: 클래스별로 구한 평가 지표 **평균**\n",
    "- **Weighted average**: 클래스별로 구한 평가 지표 **가중평균**\n",
    "- **Micro average**: 모든 클래스의 예측 결과를 더하여 전체적인 성능을 평가하는 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815f3d4-3a13-4279-be75-7d20e5b23623",
   "metadata": {},
   "source": [
    "# 4. 하이퍼파라미터 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6ad601-9d09-4a51-8472-f9fa45d302e7",
   "metadata": {},
   "source": [
    "## 4.1 하이퍼파라미터 최적화\n",
    "### [하이퍼파라미터]\n",
    "- 하이퍼파라미터\n",
    "  - 모델 학습 전, 사용자가 직접 설정하는 변수\n",
    "  - EX. *결정나무의 `max_depth`, 랜덤포레스트의 `n_estimators`*\n",
    "- 하이퍼파라미터 최적화\n",
    "  - 적절한 하이퍼파라미터를 찾아 모델 성능을 향상시키는 것\n",
    "  - 과정\n",
    "    1. 하이퍼파라미터 탐색 범위 설정\n",
    "    2. 평가 지표 계산 함수 정의\n",
    "    3. 1단계에서 샘플링한 하이퍼파라미터 값을 사용하여 검증 데이터로 정확도 평가\n",
    "    4. 위 단계를 특정 횟수 반복하며, 정확도 결과를 보고 하이퍼파라미터 범위 좁힘\n",
    "\n",
    "## 4.2 하이퍼파라미터 최적화 방법\n",
    "\n",
    "### Grid Search\n",
    "- 정해진 범위에서 하이퍼파리미터 **모두** 순회\n",
    "- 장점: 최적해를 **정확히** 찾을 수 있음\n",
    "- 단점: 시간이 오래 걸림\n",
    "- 적용: 큰 step을 활용해 범위 좁히기\n",
    "\n",
    "### Random Search\n",
    "- 정해진 범위에서 하이퍼파리미터 **무작위** 순회\n",
    "- 장점: 속도가 빠르다\n",
    "- 단점: 정확도가 떨어짐\n",
    "\n",
    "### Bayesian Optimization\n",
    "- 사전정보 바탕으로 최적 하이퍼파라미터값을 확률적으로 추정하며 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d60878-bf9a-41a0-98c2-21e7bdb8520c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f50f49f-c5e9-4a2b-a261-36dceaefc1aa",
   "metadata": {},
   "source": [
    "# **1. 분류**\n",
    "## 머신러닝: 지도 학습과 비지도 학습\n",
    "머신러닝: 컴퓨터가 스스로 어떠한 판단 또는 예측을 할 수 있게 학습시키는 것\n",
    "\n",
    "1. **지도 학습**\n",
    "     - **정답이 있는 데이터**를 사용 **예측값**을 이미 만들어진 정답과 같아지도록 학습 \n",
    "     - ex) 회귀, 분류<Br/><Br/>\n",
    "   \n",
    "2. **비지도 학습**\n",
    "\n",
    "    - **정답이 없는 데이터**를 사용해 데이터의 **패턴** 혹은 **유사도**를 학습\n",
    "    -  ex) 군집화<Br/><Br/>\n",
    "   \n",
    "3. **강화 학습**\n",
    "\n",
    "   - **시행착오를 반복**하며 **보상**을 통해 학습\n",
    "   -  ex) 알파고<Br/><Br/>\n",
    "\n",
    "   \n",
    "\n",
    "## 지도 학습: 회귀와 분류\n",
    "1. **회귀**\n",
    "   - **연속형** 변수를 예측\n",
    "   - 주어진 데이터를 기반으로 정답을 맞추는 함수를 찾는 문제 <Br/><Br/>\n",
    "\n",
    "2. **분류**\n",
    "\n",
    "   - **범주형** 변수를 예측\n",
    "   - 기존 데이터가 속하는 레이블의 패턴 인지 후 새 데이터의 레이블을 판별<Br/><Br/>\n",
    "\n",
    "## 이진 분류와 다중 분류\n",
    "**이진 분류**: 예측하고자 하는 변수가 어떤 기준에 대하여 **참** 또는 **거짓**\n",
    "\n",
    "**다중 분류**: 예측하고자 하는 변수가 가질 수 있는 값이 **3개 이상**<Br/><Br/>\n",
    "\n",
    "# **2. 분류 모델**\n",
    "## 로지스틱 회귀\n",
    "- **이진 분류**를 푸는 대표적인 알고리즘.\n",
    "- 독립변수의 선형 조합에 로지스틱 함수(=시그모이드 함수)를 적용하여 출력값을 0과 1사이로 변환\n",
    "\n",
    "### 시그모이드 함수\n",
    "**출력이 0과 1사이이 값**을 가지는 **S형** 함수\n",
    "\n",
    "$H(x)=\\frac{1}{1+e^{-(wx+b)}}=sigmoid(wx+b)=\\sigma(wx+b)$\n",
    "\n",
    "적절한 $w$(그래프의 기울기)와 $b$(그래프의 위치)를 찾는다.<Br/><Br/>\n",
    "\n",
    "## 결정 나무\n",
    "데이터가 모두 **label**로 구성될 때까지 **조건에 따라 데이터를 분류**\n",
    "\n",
    "1. **CART 알고리즘**\n",
    "\n",
    "   - 데이터셋을 **임계값**을 기준으로 **두 child**로 나누는 알고리즘\n",
    "   - 주요 단계: **임계값 설정** 및 **불순도(지니 계수) 감소** 알고리즘<Br/><Br/>\n",
    "     \n",
    "2. **실제 학습 시 고려사항**\n",
    "\n",
    "   - Parameter 설정\n",
    "   - 시각화\n",
    "   - Prunning<Br/><Br/>\n",
    "     \n",
    "## 서포트 백터 머신 (SVM)\n",
    "- 분류 경계선 중 **최적의 라인**을 찾아내는 알고리즘\n",
    "- **Margin (거리)가 가장 큰 경우**가 최적의 선<Br/><Br/>\n",
    "\n",
    "\n",
    "## KNN (K-Nearest Neighbor)\n",
    "데이터로부터 **거리가 가까운 k개의 다른 데이터 레이블을 참조**하여 분류\n",
    "1. **데이터 준비**\n",
    "2. **K 값 설정**: 가장 가까운 이웃의 개수(K)를 설정, 홀수\n",
    "3. **거리 계산**: 새로운 데이터와 기존 모든 데이터 간의 거리 계산\n",
    "4. **가장 가까운 K개의 이웃 선택**\n",
    "5. **분류하기**: K개의 이웃 중 가장 많이 등장하는 클래스가 예측 결과\n",
    "\n",
    "장점: 훈련 필요 x, 정보 손실 x\n",
    "단점: 오랜 쿼리 처리 시간 <Br/><Br/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# **3. 분류 평가 지표**\n",
    "## 혼동 행렬\n",
    "**예측결과**(P/N)를 **정확한 예측과 잘못된 예측**(T/F)으로 구분\n",
    "\n",
    "**분류 모델 평가 지표**\n",
    "\n",
    "- 정확도 (Accuracy): 모든 가능한 예측 중 참인 비율\n",
    "- 정밀도 (precision): 참이라고 예측한 경우 실제 참의 비율\n",
    "- 재현도 (recall): 실제로 참인 경우 중 참으로 예측하는 비율<Br/><Br/>\n",
    "\n",
    "\n",
    "\n",
    "## F1-Score\n",
    "**정밀도(precision)와 재현율(recall)의 조화 평균**<Br/><Br/>\n",
    "\n",
    "## ROC/AUC Curve\n",
    "분류 모델의 성능 평가\n",
    "\n",
    "1. **ROC Curve**\n",
    "\n",
    "\n",
    "**얼마나 분류가 잘 되었는가**를 보여주는 그래프\n",
    "- True Positive Rate (TPR) : 참인 것들 중에 참이라고 예측한 비율 (=Recall)\n",
    "- False Positive Rate (FPR) : 거짓인 것들 중에 참이라고 잘못 예측한 비율<Br/><Br/>\n",
    "\n",
    "2. **AUC Curve**\n",
    "\n",
    "**ROC와 x축 사이의 면적**(적분값), **1에 가까울수록** 분류 성능 우수\n",
    "\n",
    "<Br/><Br/>\n",
    "\n",
    "\n",
    "# **4. 하이퍼파라미터 최적화**\n",
    "## 하이퍼파라미터 최적화\n",
    "**하이퍼파라미터**: 모델 학습 과정에 반영되는 값으로, **학습 시작 전에 사용자가 직접 설정**하는 변수<Br/><Br/>\n",
    "\n",
    "**하이퍼파라미터 최적화**:**적절한 하이퍼파라미터를 찾음**으로써 Model 성능을 향상\n",
    "\n",
    "1. Hyperparameter 탐색 범위 설정\n",
    "2. 평가 지표 계산 함수 정의\n",
    "3. 검증 데이터로 정확도 평가\n",
    "4. 위 단계를 반복하며 정확도 결과를 통해 하이퍼파라미터의 범위 좁힘\n",
    "\n",
    "\n",
    "<Br/><Br/>\n",
    "\n",
    "\n",
    "## 하이퍼파라미터 최적화 방법\n",
    "1. **Grid Search**: 정해진 범위에서 Hyperparameter를 **모두 순회**\n",
    "   - 장점: 정확도\n",
    "   - 단점: 시간 오래 걸림\n",
    "   - 적용: 넓은 범위, 큰 step\n",
    "     <Br/><Br/>\n",
    "2. **Random Search**: 정해진 범위에서 Hyperparameter를 **무작위로 탐색**\n",
    "   - 장점: 속도\n",
    "   - 단점: 정확도 떨어짐\n",
    " <Br/><Br/>\n",
    "3. **Bayesian Optimization**: 사전 정보를 바탕으로 최적 Hyperparameter 값을 **확률적으로 추정**\n",
    "   - \"Aquisition Fucntion\"을 적용했을 때 가장 큰 값이 나올 확률이 높은 지점을 찾는다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a69b5-2c03-45b0-a77b-626ce5c74581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ca254-6d44-483a-bf53-9b844e052b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
